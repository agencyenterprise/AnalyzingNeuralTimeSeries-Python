[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AnalyzingNeuralTimeSeries-Python",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "AnalyzingNeuralTimeSeries-Python",
    "section": "Install",
    "text": "Install\npip install AnalyzingNeuralTimeSeries_Python"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "AnalyzingNeuralTimeSeries-Python",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "foo\n\n foo ()"
  },
  {
    "objectID": "chapter02.html",
    "href": "chapter02.html",
    "title": "Chapter 2",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 2 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries (type `%pip install my_package` in a cell to install any missing packages)\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\nfrom scipy.signal import firls, filtfilt\n\n\n# Figure 2.1\n\n# Load the sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Set the number of trials to analyze\nnTrials = 6 # modifiable\n\n# Initialize data array\ndata = np.zeros((nTrials, EEG['pnts'][0][0]))\n\n# Define wavelet parameters\nwavetime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nn_conv = len(wavetime) + EEG['pnts'][0][0] - 1\nwaveletfft = fft(np.exp(2 * 1j * np.pi * 10 * wavetime) * np.exp(-wavetime**2 / (2 * (5 / (2 * np.pi * 10))**2)) / 10, n_conv)\ndata10hz = np.zeros((nTrials, EEG['pnts'][0][0]))\n\n# Plotting setup\nfig, axs = plt.subplots(nTrials, 3, figsize=(15, 10))\n\n# Loop over trials\nfor triali in range(nTrials):\n    \n    # Create single trial \"ERP\"\n    data[triali, :] = 0.5 * np.sin(2 * np.pi * 6 * EEG['times'][0] / 1000 + 2 * np.pi * triali / nTrials - np.pi) + np.random.randn(EEG['pnts'][0][0]) / 6\n    # Add non-phase-locked stimulus potential\n    data[triali, 259:360] = data[triali, 259:360] + np.sin(2 * np.pi * 10 * EEG['times'][0][259:360] / 1000 + 2 * np.pi * triali / nTrials - np.pi) + np.random.randn(101) / 5\n    \n    # Plot data from this trial\n    axs[triali, 0].plot(EEG['times'][0], data[triali, :])\n    axs[triali, 0].set_xlim([-250, 850])\n    axs[triali, 0].set_ylim([-2.2, 2.2])\n    \n    # Plot ERP from trial 1 to current\n    axs[triali, 1].plot(EEG['times'][0], np.mean(data[:triali+1, :], axis=0))\n    axs[triali, 1].set_xlim([-250, 850])\n    axs[triali, 1].set_ylim([-2.2, 2.2])\n    \n    # Convolve with 10 Hz wavelet\n    convolution_result_fft = ifft(waveletfft * fft(data[triali, :], n_conv)) * np.sqrt(5 / (2 * np.pi * 10))\n    convolution_result_fft = convolution_result_fft[int(np.floor(len(wavetime)/2)) : -int(np.floor(len(wavetime)/2))]\n    data10hz[triali, :] = np.abs(convolution_result_fft)**2\n    \n    # Plot 10 Hz power\n    axs[triali, 2].plot(EEG['times'][0], np.mean(data10hz[:triali+1, :], axis=0))\n    axs[triali, 2].set_xlim([-250, 850])\n    axs[triali, 2].set_ylim([-0.1, 0.8])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 2.2\n# (This code involves performing convolution with a complex Morlet wavelet, which you will learn about in Chapters 10-13.)\n\n# Define parameters for the time-frequency analysis\nsrate = 1000\ntime = np.arange(0, 10 + 1/srate, 1/srate)\nDCoffset = -0.5\n\n# Create multi-frequency signal\na = np.sin(2 * np.pi * 10 * time)  # High frequency part\nb = 0.1 * np.sin(2 * np.pi * 0.3 * time) + DCoffset  # Low frequency part\n\n# Combine signals\ndata = a * b\ndata += (2 * np.sin(2 * np.pi * 3 * time) * np.sin(2 * np.pi * 0.07 * time) * 0.1 + DCoffset)\n\n# Morlet wavelet convolution parameters\nnum_frex = 40\nmin_freq = 2\nmax_freq = 20\n\nLdata = len(data)\nLtapr = len(data)\nLconv1 = Ldata + Ltapr - 1\nLconv = 2**int(np.ceil(np.log2(Lconv1)))\n\nfrex = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\n\n# Initialize time-frequency representation matrix\ntf = np.zeros((num_frex, len(data)))\ndatspctra = fft(data, Lconv)\n\ns = 4 / (2 * np.pi * frex)\nt = np.arange(-((len(data) - 1) / 2) / srate, ((len(data) - 2) / 2) / srate + 1/srate, 1/srate)\n\n# Perform wavelet convolution\nfor fi in range(len(frex)):\n    wavelet = np.exp(2 * 1j * np.pi * frex[fi] * t) * np.exp(-t**2 / (2 * s[fi]**2))\n    m = ifft(datspctra * fft(wavelet, Lconv), Lconv)\n    m = m[:Lconv1]\n    m = m[int(np.floor((Ltapr - 1) / 2)) : -int(np.ceil((Ltapr - 1) / 2))]\n    tf[fi, :] = np.abs(m)**2\n\n# Plot the signals and time-frequency representation\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\n\naxs[0, 0].plot(a)\naxs[0, 0].set_xlim([1 * 1000, 8 * 1000])\naxs[0, 0].set_ylim([-1, 1])\naxs[0, 0].set_xticks(np.arange(1 * 1000, 9 * 1000, 1000))\naxs[0, 0].set_xticklabels(np.arange(1, 9))\naxs[0, 0].set_title('10 Hz signal, DC=0')\n\naxs[0, 1].plot(b)\naxs[0, 1].set_xlim([1 * 1000, 8 * 1000])\naxs[0, 1].set_ylim([-1, 1])\naxs[0, 1].set_xticks(np.arange(1 * 1000, 9 * 1000, 1000))\naxs[0, 1].set_xticklabels(np.arange(1, 9))\naxs[0, 1].set_title(f'.3 Hz signal, DC={DCoffset}')\n\naxs[1, 0].plot(data)\naxs[1, 0].set_xlim([1 * 1000, 8 * 1000])\naxs[1, 0].set_ylim([-1, 1])\naxs[1, 0].set_xticks(np.arange(1 * 1000, 9 * 1000, 1000))\naxs[1, 0].set_xticklabels(np.arange(1, 9))\naxs[1, 0].set_title('Time-domain signal')\n\nim = axs[1, 1].imshow(tf, aspect='auto', extent=[1, len(data), 0, num_frex], origin='lower')\naxs[1, 1].set_xlim([1 * 1000, 8 * 1000])\naxs[1, 1].set_yticks(np.arange(1, num_frex, 8))\naxs[1, 1].set_yticklabels(np.round(frex[::8]))\naxs[1, 1].set_xticks(np.arange(1 * 1000, 9 * 1000, 1000))\naxs[1, 1].set_xticklabels(np.arange(1, 9))\naxs[1, 1].set_title('Time-frequency representation')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 2.3\n\n# Select the channel to plot\nchan2plot = 'Pz' # you can pick any electrode (type `EEG['chanlocs'][0]['labels']` in a new cell for all electrodes)\n\n# Compute ERP (time-domain trial average from selected electrode)\nerp = np.squeeze(np.mean(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot, :, :], axis=2))\n\n# Low-pass filter parameters\nnyquist = EEG['srate'][0][0] / 2\nfilter_cutoff = 40  # Hz\ntrans_width = 0.1  # Transition width, in fraction of 1\n\n# Filter design\nffrequencies = [0, filter_cutoff, filter_cutoff * (1 + trans_width), nyquist] / nyquist\nidealresponse = [1, 1, 0, 0]\nfilterweights = firls(101, ffrequencies, idealresponse)\nfiltered_erp = filtfilt(filterweights, 1, erp)\n\n# Plotting the ERP\nplt.figure(figsize=(10, 5))\nplt.plot(EEG['times'][0], filtered_erp, 'k.-', label='256 Hz')\n\n# Down-sample and plot\ntimes2plot = np.arange(-200, 1001, 40)\ndownsampled_erp = filtered_erp[::5]\ndownsampled_times = EEG['times'][0][::5]\nplt.plot(downsampled_times, downsampled_erp, 'mo-', label='50 Hz')\n\nplt.xlim([-200, 1000])\nplt.ylim([-4, 10])\nplt.gca().invert_yaxis()\nplt.xlabel('Time (ms)')\nplt.ylabel('Voltage (µV)')\nplt.title('ERP from electrode {}'.format(chan2plot))\nplt.legend()\n\nplt.show()"
  },
  {
    "objectID": "chapter19.html",
    "href": "chapter19.html",
    "title": "Chapter 19",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 19 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import hilbert\nfrom scipy.io import loadmat\nfrom scipy.fftpack import fft, ifft\nfrom numpy.random import rand, randn, choice\n\n\n# Define a function to more easily plot multiple polar vectors\ndef plot_polar_vectors(angles, lengths=None, average_angle=None, average_length=None):\n    if lengths is None:\n        lengths = np.ones_like(angles)\n    for angle, length in zip(angles, lengths):\n        plt.polar([0, angle], [0, length])\n    if average_angle is not None and average_length is not None:\n        plt.polar([0, average_angle], [0, average_length])\n\n\n# Figure 19.1\n\n# Define angles\na = [0.2, 2*np.pi-.2]\n\n# Plot unit vectors defined by those angles\nplt.figure()\nplot_polar_vectors(a)\n# Plot a unit vector with the average angle\nplot_polar_vectors([np.mean(a)], [1])\n# Plot the average vector\nmean_vector = np.mean(np.exp(1j*np.array(a)))\nplot_polar_vectors([np.angle(mean_vector)], [np.abs(mean_vector)])\nplt.show()\n\n\n\n\n\n# Figure 19.2\n\n# Load sample scalp EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Center frequency\ncenterfreq = 12  # in Hz\nchan2plot = 'Pz'\ntimes2plot = [200, 800]  # in ms, from stimulus onset\n\n# Define convolution parameters\nn_wavelet = EEG['pnts'][0][0]\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\n\n# Create wavelet\ntime = np.arange(-(n_wavelet/EEG['srate'][0][0]/2), n_wavelet/EEG['srate'][0][0]/2, 1/EEG['srate'][0][0])\nwavelet = np.exp(2*1j*np.pi*centerfreq*time) * np.exp(-time**2 / (2 * ((4 / (2 * np.pi * centerfreq))**2))) / centerfreq\n\n# Get FFT of data\neegfft = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot, :, :].flatten('F'), n_conv_pow2)\n\n# Convolution\neegconv = ifft(fft(wavelet, n_conv_pow2) * eegfft)\neegconv = eegconv[:n_convolution]\neegconv = np.reshape(eegconv[int(np.floor((EEG['pnts'][0][0]-1)/2))-1:-int(np.ceil((EEG['pnts'][0][0]-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Plot\nfor subploti, timepoint in enumerate(times2plot):\n    plt.figure()\n    idx = np.argmin(np.abs(EEG['times'][0] - timepoint))\n    plot_polar_vectors(np.angle(eegconv[idx,:]), np.ones(EEG['trials'][0][0]))\n    plt.title(f'ITPC at {timepoint} ms = {np.round(np.abs(np.mean(np.exp(1j*np.angle(eegconv[idx,:])))), 3)}')\n    plt.show()\n    \n    plt.figure()\n    plt.hist(np.angle(eegconv[idx,:]), bins=20)\n    plt.ylim([0, 20])\n    plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi], ['-pi', '-pi/2', '0', 'pi/2', 'pi'])\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Figure 19.3\n\nvectors = [[0, np.pi/3], [0, np.pi/2], [0, 2*np.pi/3], [0, np.pi*.9]]\n\nfor i, vec in enumerate(vectors):\n    plt.figure()\n    # Plot individual unit vectors\n    plot_polar_vectors(vec)\n    # Plot mean vector\n    meanvect = np.mean(np.exp(1j*np.array(vec)))\n    plot_polar_vectors([np.angle(meanvect)], [np.abs(meanvect)])\n    plt.title(f'Mean vector length: {np.abs(meanvect):.5f}')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Figure 19.4\n\n# Get FFT of data\nchan2plot = 'Pz'\ncenterfreq = 12  # in Hz\neegfft = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot, :, :].flatten('F'), n_conv_pow2)\n\n# ITPC at one frequency band\nwavelet = np.exp(2*1j*np.pi*centerfreq*time) * np.exp(-time**2 / (2 * ((4 / (2 * np.pi * centerfreq))**2))) / centerfreq\n# Convolution\neegconv = ifft(fft(wavelet, n_conv_pow2) * eegfft)\neegconv = eegconv[:n_convolution]\neegconv = np.reshape(eegconv[int(np.floor((EEG['pnts'][0][0]-1)/2))-1:-int(np.ceil((EEG['pnts'][0][0]-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\nplt.figure()\nplt.plot(EEG['times'][0], np.abs(np.mean(np.exp(1j*np.angle(eegconv)), axis=1)))\nplt.xlim([-200, 1000])\nplt.ylim([0, 0.7])\nplt.xlabel('Time (ms)')\nplt.ylabel('ITPC')\nplt.show()\n\n# TF plot of ITPC\nfrequencies = np.logspace(np.log10(4), np.log10(40), 20)\ns = np.logspace(np.log10(3), np.log10(10), len(frequencies)) / (2 * np.pi * frequencies)\nitpc = np.zeros((len(frequencies), EEG['pnts'][0][0]))\n\nfor fi, freq in enumerate(frequencies):\n    # Create wavelet\n    wavelet = np.exp(2*1j*np.pi*freq*time) * np.exp(-time**2 / (2 * (s[fi]**2))) / freq\n\n    # Convolution\n    eegconv = ifft(fft(wavelet, n_conv_pow2) * eegfft)\n    eegconv = eegconv[:n_convolution]\n    eegconv = np.reshape(eegconv[int(np.floor((EEG['pnts'][0][0]-1)/2))-1:-int(np.ceil((EEG['pnts'][0][0]-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Extract ITPC\n    itpc[fi, :] = np.abs(np.mean(np.exp(1j*np.angle(eegconv)), axis=1))\n\nplt.figure()\nplt.contourf(EEG['times'][0], frequencies, itpc, 40, cmap='viridis')\nplt.clim([0, 0.6])\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequencies (Hz)')\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 19.5\n\nn_trials = 500\nitpcByNFake = np.zeros(n_trials)\n\nfor n in range(n_trials):\n    for iteri in range(50):\n        itpcByNFake[n] += np.abs(np.mean(np.exp(1j*(rand(n+1)*2*np.pi-np.pi))))\nitpcByNFake /= iteri+1\n\n# Z and P\nitpcByNFakeZ = np.arange(1, n_trials+1) * (itpcByNFake**2)\nitpcByNFakeP = np.exp(np.sqrt(1 + 4*np.arange(1, n_trials+1) + 4*((np.arange(1, n_trials+1)**2) - (np.arange(1, n_trials+1)*itpcByNFake)**2)) - (1 + 2*np.arange(1, n_trials+1)))\nitpcFakeCrit = np.sqrt(-np.log(0.01) / np.arange(1, n_trials+1))\n\nplt.figure()\nplt.plot(np.arange(1, n_trials+1), itpcByNFake)\nplt.plot(np.arange(1, n_trials+1), itpcFakeCrit, 'r')\nplt.xlim([0, 500])\nplt.ylim([0, 1])\nplt.legend(['ITPC_raw', 'ITPC_Crit'])\nplt.show()\n\n\n\n\n\n# Figure 19.6\n\n# Center frequency\ncenterfreq = 6  # Hz\nchan2plot = 'FCz'\n\n# Define convolution parameters\nn_wavelet = EEG['pnts'][0][0]\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\n\n# Create wavelet\ntime = np.arange(-(n_wavelet/EEG['srate'][0][0]/2), n_wavelet/EEG['srate'][0][0]/2, 1/EEG['srate'][0][0])\nwavelet = np.exp(2*1j*np.pi*centerfreq*time) * np.exp(-time**2 / (2 * ((4 / (2 * np.pi * centerfreq))**2))) / centerfreq\n\n# Get FFT of data\neegfft = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot, :, :].flatten('F'), n_conv_pow2)\n\n# Convolution\neegconv = ifft(fft(wavelet, n_conv_pow2) * eegfft)\neegconv = eegconv[:n_convolution]\neegconv = np.reshape(eegconv[int(np.floor((EEG['pnts'][0][0]-1)/2))-1:-int(np.ceil((EEG['pnts'][0][0]-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\nplt.figure()\n\n# Compute ITPC as function of N\nitpcByN = np.zeros(EEG['trials'][0][0])\nfor n in range(EEG['trials'][0][0]):\n    for iteri in range(50):\n        trials2use = choice(EEG['trials'][0][0], n+1, replace=False)\n        itpcByN[n] += np.mean(np.abs(np.mean(np.exp(1j*np.angle(eegconv[281:372, trials2use])), axis=1)))\nitpcByN /= (iteri+1)\n\n# Z and P\nitpcByNZ = np.arange(1, EEG['trials'][0][0]+1) * (itpcByN**2)\nitpcByNP = np.exp(np.sqrt(1 + 4*np.arange(1, EEG['trials'][0][0]+1) + 4*((np.arange(1, EEG['trials'][0][0]+1)**2) - (np.arange(1, EEG['trials'][0][0]+1)*itpcByN)**2)) - (1 + 2*np.arange(1, EEG['trials'][0][0]+1)))\nitpcCrit = np.sqrt(-np.log(0.01) / np.arange(1, EEG['trials'][0][0]+1))\n\nplt.subplot(211)\nplt.plot(itpcByN)\nplt.plot(itpcCrit, 'r')\nplt.xlim([0, 100])\nplt.xlabel('Number of trials in analysis')\nplt.ylabel('ITPC')\nplt.ylim([0.2, 1])\n\n# Note that this figure will look different than that in the book because trials are randomly selected.\nplt.subplot(212)\nplt.plot(EEG['times'][0], np.abs(np.mean(np.exp(1j*np.angle(eegconv)), axis=1)))\nrandomtrials2plot = np.random.permutation(EEG['trials'][0][0])\nplt.plot(EEG['times'][0], np.abs(np.mean(np.exp(1j*np.angle(eegconv[:, randomtrials2plot[:20]])), axis=1)), ':')\nplt.xlim([-1000, 1500])\nplt.xlabel('Time (ms)')\nplt.ylabel('ITPC')\nplt.legend(['99 trials', '20 trials'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.8: Statistical evaluation of ITPC values\n\n# This cell concerns statistical evaluation of ITPC values. It will be\n# discussed in depth in chapter 34, but the code is presented here because\n# it relies on calculations from the previous two figures. \n\n# p-values under assumption of von Mises distribution\napprox_pval_fake = np.exp(-itpcByNFakeZ)\napprox_pval_real = np.exp(-itpcByNZ)\n\nncutoff = 10\n\nplt.figure(figsize=(12, 6))\n\n# Plot p-values from fake data\nplt.subplot(121)\nplt.plot(itpcByNFakeP[ncutoff:], approx_pval_fake[ncutoff:], 'mo', markersize=8)\nplt.plot(itpcByNFakeP[:ncutoff], approx_pval_fake[:ncutoff], 'k.')\nplt.plot([0, 1], [0, 1], 'k')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.xticks(np.arange(0, 1.25, 0.25))\nplt.yticks(np.arange(0, 1.25, 0.25))\nplt.ylabel('approximate p')\nplt.xlabel('exact p')\nplt.title('P-values from fake data')\n\n# Plot p-values from real data\nplt.subplot(122)\nplt.plot(itpcByNP[ncutoff:], approx_pval_real[ncutoff:], 'mo', markersize=8)\nplt.plot(itpcByNP[:ncutoff], approx_pval_real[:ncutoff], 'k.')\nplt.plot([0.00001, 1], [0.00001, 1], 'k')\nplt.xlim([.0001, 1])\nplt.ylim([.0001, 1])\nplt.xscale('log')\nplt.yscale('log')\nplt.ylabel('approximate p')\nplt.xlabel('exact p')\nplt.title('P-values from real data')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 19.7\n# (This figure takes a while to generate. You could also reduce the number\n# of iterations to speed it up.)\n\n# Data for this cell are from figure 19.6. If you want to plot \n# results from a different channel, change the electrode in 19.6.\n\n# Center frequencies\nfrequencies = np.arange(1, 41)\n\nniterations = 50\n\n# Initialize\nitpcByNandF = np.zeros((len(frequencies), EEG['trials'][0][0]))\n\nfor fi, centerfreq in enumerate(frequencies):\n    wavelet = np.exp(2*1j*np.pi*centerfreq*time) * np.exp(-time**2 / (2 * ((4 / (2 * np.pi * centerfreq))**2))) / centerfreq\n    \n    # Convolution\n    eegconv = ifft(fft(wavelet, n_conv_pow2) * eegfft)\n    eegconv = eegconv[:n_convolution]\n    eegconv = np.reshape(eegconv[int(np.floor((EEG['pnts'][0][0]-1)/2))-1:-int(np.ceil((EEG['pnts'][0][0]-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    for n in range(EEG['trials'][0][0]):\n        for iteri in range(niterations):\n            trials2use = choice(EEG['trials'][0][0], n+1, replace=False)\n            itpcByNandF[fi, n] += np.mean(np.abs(np.mean(np.exp(1j*np.angle(eegconv[281:372, trials2use])), axis=1)))\n\nplt.figure()\nplt.contourf(np.arange(1, EEG['trials'][0][0]+1), frequencies, itpcByNandF / (iteri+1), 40, cmap='gray')\nplt.clim([0.1, 0.5])\nplt.xlabel('Trials')\nplt.ylabel('Frequency (Hz)')\nplt.show()\n\n\n\n\n\n# Figure 19.8\n\nplt.figure(figsize=(12, 6))\nplt.suptitle(\"Rayleigh's Z\")\n\nplt.subplot(121)\nplt.plot(itpcByN)\nplt.plot(itpcByNFake[:99], 'r')\nplt.xlim([0, 100])\nplt.ylim([0, 1])\nplt.xlabel('Trial count')\nplt.ylabel('ITPC')\n\nplt.subplot(122)\nplt.plot(itpcByNZ)\nplt.plot(itpcByNFakeZ[:99], 'r')\nplt.xlim([0, 100])\nplt.ylim([0, 12])\nplt.xlabel('Trial count')\nplt.ylabel('ITPC_Z')\nplt.legend(['real data', 'fake data'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 19.9\n\n# Pick electrode and frequencies\nchan2plot = 'FCz'\nfrequencies = np.arange(1, 41)\n\n# Define convolution parameters\ntime = np.arange(-(EEG['pnts'][0][0]/EEG['srate'][0][0]/2), EEG['pnts'][0][0]/EEG['srate'][0][0]/2, 1/EEG['srate'][0][0])\nn_wavelet = EEG['pnts'][0][0]\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\n\nplotlegends = ['without jitter', 'with jitter']\n\nplt.figure(figsize=(10, 8))\n\nbaselinetime = [-300, -100]\nbaseidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in baselinetime]\n\nfor simuli in range(1, 3):\n    # Add time jitter (or not)\n    tempdat = np.squeeze(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot, :, :])\n    if simuli == 2:\n        for ti in range(tempdat.shape[1]):\n            timejitter = int(np.ceil(rand() * 10))*(simuli-1)\n            tempdat[:, ti] = np.roll(tempdat[:, ti], timejitter)\n    \n    # Get FFT of data\n    eegfft = fft(tempdat.flatten('F'), n_conv_pow2)\n\n    # Initialize\n    itpc = np.zeros((len(frequencies), EEG['pnts'][0][0]))\n    powr = np.zeros((len(frequencies), EEG['pnts'][0][0]))\n    \n    for fi, centerfreq in enumerate(frequencies):\n        wavelet = np.exp(2*1j*np.pi*centerfreq*time) * np.exp(-time**2 / (2 * ((4 / (2 * np.pi * centerfreq))**2))) / centerfreq\n        \n        # Convolution\n        eegconv = ifft(fft(wavelet, n_conv_pow2) * eegfft)\n        eegconv = eegconv[:n_convolution]\n        eegconv = np.reshape(eegconv[int(np.floor((n_wavelet-1)/2))-1:-int(np.ceil((n_wavelet-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n        \n        # Compute and store ITPC and power\n        itpc[fi, :] = np.abs(np.mean(np.exp(1j*np.angle(eegconv)), axis=1))\n        powr[fi, :] = np.mean(np.abs(eegconv)**2, axis=1)\n        powr[fi, :] = 10 * np.log10(powr[fi, :] / np.mean(powr[fi, baseidx]))\n    \n    plt.subplot(2, 2, simuli)\n    plt.contourf(EEG['times'][0], frequencies, itpc, 40, cmap='viridis')\n    plt.clim([0.1, 0.5])\n    plt.xlim([-200, 1000])\n    plt.xlabel('Time (ms)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title(f'ITPC {plotlegends[simuli-1]}')\n    \n    plt.subplot(2, 2, simuli+2)\n    plt.contourf(EEG['times'][0], frequencies, powr, 40, cmap='viridis')\n    plt.clim([-3, 3])\n    plt.xlim([-200, 1000])\n    plt.xlabel('Time (ms)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title(f'DB-power {plotlegends[simuli-1]}')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 19.10\n\n# Initialize\ndata4test = np.zeros((2, len(time), EEG['trials'][0][0]))\nsensor2use = 'P7'\n\n# Amplitude modulation (modulate power by 1 Hz sine wave)\ntime = np.arange(-(EEG['pnts'][0][0]/EEG['srate'][0][0]/2), EEG['pnts'][0][0]/EEG['srate'][0][0]/2, 1/EEG['srate'][0][0])\namp_mod = (np.sin(2*np.pi*1.*time) + 2) - 1\n\nfor triali in range(EEG['trials'][0][0]):\n    # Each trial is a random channel and trial\n    trialdata = EEG['data'][EEG['chanlocs'][0]['labels']==sensor2use, :, triali]\n    \n    # Uncomment the next line of code for band-pass filtered data.\n    # This uses the eegfilt function, which is part of the eeglab toolbox.\n    # trialdata = eegfilt(double(trialdata), EEG['srate'][0][0], 10, 20)\n    \n    data4test[0, :, triali] = trialdata * amp_mod\n    data4test[1, :, triali] = trialdata\n\n# Compute ITPC\nitpc_mod = np.abs(np.mean(np.exp(1j*np.angle(np.reshape(hilbert(data4test[0, :, :].flatten('F')), (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F'))), axis=1))\nitpc_nomod = np.abs(np.mean(np.exp(1j*np.angle(hilbert(data4test[1, :, :]))), axis=1))\n\n# Plot!\nplt.figure(figsize=(10, 8))\n\nplt.subplot(311)\nplt.plot(EEG['times'][0], amp_mod)\nplt.xlim([-1000, 1500])\nplt.ylim([-.2, 2.2])\nplt.title('Amplitude modulator')\n\nplt.subplot(312)\nplt.plot(EEG['times'][0], data4test[0, :, 9])\nplt.plot(EEG['times'][0], data4test[1, :, 9], 'r')\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('Example trials')\n\nplt.subplot(313)\nplt.plot(EEG['times'][0], itpc_mod)\nplt.plot(EEG['times'][0], itpc_nomod, 'r')\nplt.legend(['amplitude modulation', 'no amp mod'])\nplt.xlim([-1000, 1500])\nplt.ylim([0, 1])\nplt.xlabel('Time (ms)')\nplt.ylabel('ITPC')\nplt.title('ITPC')\n\nplt.tight_layout()\nplt.show()\n\nplt.figure()\nplt.plot(amp_mod, itpc_mod, '.')\nplt.xlim([0, 2])\nplt.xlabel('Power modulation')\nplt.ylabel('ITPC')\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 19.11\n\nrandvects = rand(50) * 2 * np.pi - np.pi\nvectormod = (randvects + randn(len(randvects)))**2\nvectormod2 = vectormod - np.min(vectormod) + 1  # make sure no negative values\n\n\n# ITPC\nplt.figure()\nplot_polar_vectors(randvects, np.ones_like(randvects))\nplt.title(f'ITPC = {np.abs(np.mean(np.exp(1j*randvects)))}')\n\n# wITPC\nplt.figure()\nplot_polar_vectors(randvects, vectormod)\n\nwitpc = np.abs(np.mean(vectormod * np.exp(1j*randvects)))\nperm_witpc = np.zeros(1000)\n\nfor i in range(1000):\n    perm_witpc[i] = np.abs(np.mean(vectormod[np.random.permutation(len(vectormod))] * np.exp(1j*randvects)))\n\nwitpc_z = (witpc - np.mean(perm_witpc)) / np.std(perm_witpc)\nplt.title(f'_wITPC_z = {witpc_z}')\n\n# Example of one permutation\nplt.figure()\nplot_polar_vectors(randvects, vectormod[np.random.permutation(len(vectormod))])\nplt.title('One null hypothesis iteration')\n\n# Histogram of null-hypothesis WITPC\nplt.figure()\ny, x = np.histogram(perm_witpc, bins=50)\nplt.bar(x[:-1], y, width=np.diff(x), edgecolor='none')\nplt.plot([witpc, witpc], plt.gca().get_ylim(), 'm')\nplt.title('Histogram of null hypothesis wITPC')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Figure 19.12\n\ncenterfreq = 6\nchannel2use = 'PO7'\ntimes2save = np.arange(-200, 1250, 50)\n\n# Initialize matrix to store RTs\nrts = np.zeros(EEG['trials'][0][0])\n\nfor ei in range(EEG['trials'][0][0]):\n    # Find which event is time=0, and take the latency of the event thereafter.\n    time0event = np.where(np.array(EEG['epoch'][0][ei]['eventlatency'][0]) == 0)[0][0]\n    \n    # Use try-except in case of no response\n    try:\n        rts[ei] = EEG['epoch'][0][ei]['eventlatency'][0][time0event + 1]\n    except IndexError:\n        rts[ei] = np.nan\n\n# Define convolution parameters\ntime = np.arange(-(EEG['pnts'][0][0]/EEG['srate'][0][0]/2), EEG['pnts'][0][0]/EEG['srate'][0][0]/2, 1/EEG['srate'][0][0])\nn_wavelet = EEG['pnts'][0][0]\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\n\n# Get FFT of data and wavelet\neegfft = fft(EEG['data'][EEG['chanlocs'][0]['labels']==channel2use, :, :].flatten('F'), n_conv_pow2)\nwavefft = fft(np.exp(2*1j*np.pi*centerfreq*time) * np.exp(-time**2 / (2 * ((4 / (2 * np.pi * centerfreq))**2))), n_conv_pow2)\n\n# Convolution\neegconv = ifft(wavefft * eegfft)\neegconv = eegconv[:n_convolution]\neegconv = np.reshape(eegconv[int(np.floor((n_wavelet-1)/2))-1:-int(np.ceil((n_wavelet-1)/2))-1], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\nphase_angles = np.angle(eegconv)\n\n# Initialize\nitpc = np.zeros(len(times2save))\nwitpc = np.zeros(len(times2save))\nwitpc_z = np.zeros(len(times2save))\n\nfor ti, timepoint in enumerate(times2save):\n    # Find index for this time point\n    timeidx = np.argmin(np.abs(EEG['times'][0] - timepoint))\n    \n    # ITPC is unmodulated phase clustering\n    itpc[ti] = np.abs(np.mean(np.exp(1j*phase_angles[timeidx,:])))\n    \n    # wITPC is rts modulating the length of phase angles\n    witpc[ti] = np.abs(np.mean(rts * np.exp(1j*phase_angles[timeidx,:])))\n    \n    # Permutation testing\n    perm_witpc = np.zeros(1000)\n    for i in range(1000):\n        perm_witpc[i] = np.abs(np.mean(rts[np.random.permutation(EEG['trials'][0][0])] * np.exp(1j*phase_angles[timeidx,:])))\n    \n    witpc_z[ti] = (witpc[ti] - np.mean(perm_witpc)) / np.std(perm_witpc)\n\nplt.figure()\n\n# Plot ITPC\nax1 = plt.subplot(311)\nax1.plot(EEG['times'][0], np.abs(np.mean(np.exp(1j*phase_angles), axis=1)), label='ITPC')\nax2 = ax1.twinx()\nax2.plot(times2save, witpc, label='wITPC', color='orange')\nax1.tick_params(axis='y', labelcolor='b')\nax2.tick_params(axis='y', labelcolor='orange')\nax1.set_ylim([0, 0.8])\nax2.set_ylim([0, 400])\nplt.xlim([times2save[0], times2save[-1]])\nplt.title(f'ITPC and wITPC at {channel2use}')\nplt.legend()\n\n# Plot wITPCz\nplt.subplot(312)\nplt.plot(times2save, witpc_z)\nplt.plot([times2save[0], times2save[-1]], [0, 0], 'k')\nplt.xlim([times2save[0], times2save[-1]])\nplt.xlabel('Time (ms)')\nplt.ylabel('wITPCz')\nplt.title(f'wITPCz at {channel2use}')\n\nplt.subplot(325)\nplt.plot(itpc, witpc, '.')\nplt.xlabel('ITPC')\nplt.ylabel('wITPC')\n\nplt.subplot(326)\nplt.plot(itpc, witpc_z, '.')\nplt.xlabel('ITPC')\nplt.ylabel('wITPCz')\n\nplt.show()"
  },
  {
    "objectID": "chapter22.html",
    "href": "chapter22.html",
    "title": "Chapter 22",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 22 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fftpack import fft, ifft\nfrom mne import create_info, EvokedArray\nfrom mne.channels import make_dig_montage\nfrom laplacian_perrinX import laplacian_perrinX\nfrom laplacian_nola import laplacian_nola\nimport time\n\n\n# Figure 22.2\n\n# This figure was made by 'stepping-in' to the function laplacian_perrinX\n# and then creating topographical maps of the Legendre polynomial.\n# TODO: Python equivalent of 'stepping-in' to a function.\n\n\n# Figure 22.3\n\n# Load sample EEG dataset\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Compute inter-electrode distances\ninterelectrodedist = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor chani in range(EEG['nbchan'][0][0]):\n    for chanj in range(chani + 1, EEG['nbchan'][0][0]):\n        interelectrodedist[chani, chanj] = np.sqrt(\n            (EEG['chanlocs'][0][chani]['X'][0][0] - EEG['chanlocs'][0][chanj]['X'][0][0]) ** 2 +\n            (EEG['chanlocs'][0][chani]['Y'][0][0] - EEG['chanlocs'][0][chanj]['Y'][0][0]) ** 2 +\n            (EEG['chanlocs'][0][chani]['Z'][0][0] - EEG['chanlocs'][0][chanj]['Z'][0][0]) ** 2\n        )\n\nvalid_gridpoints = np.where(interelectrodedist &gt; 0)\n\n# Extract XYZ coordinates from EEG structure\nX = np.array([chan['X'][0][0] for chan in EEG['chanlocs'][0]])\nY = np.array([chan['Y'][0][0] for chan in EEG['chanlocs'][0]])\nZ = np.array([chan['Z'][0][0] for chan in EEG['chanlocs'][0]])\n\n# Crreate the G and H matrices\nsurf_lap, G, H = laplacian_perrinX(np.random.rand(len(X)), X, Y, Z, smoothing=1e-6)\n# Note we define the laplacian_perrinX function in the file laplacian_perrinX.py\n\n# Plot G and H matrices\nplt.figure(figsize=(10, 8))\nplt.subplot(221)\nplt.imshow(G, cmap='viridis')\nplt.title('G')\n\nplt.subplot(222)\nplt.imshow(H, cmap='viridis')\nplt.title('H')\n\nplt.subplot(223)\nplt.plot(interelectrodedist[valid_gridpoints], G[valid_gridpoints], 'r.')\nplt.plot(interelectrodedist[valid_gridpoints], H[valid_gridpoints], 'm.')\nplt.legend(['G', 'H'])\nplt.xlim([0, 200])\nplt.ylim([-0.065, 0.065])\nplt.xlabel('Inter-electrode distances (mm)')\nplt.ylabel('G or H')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 22.4\n\n# In the book, figure 4 uses chan1 as Pz. The book also mentions that tha\n# surface Laplacian will attenuate the impact of EOG artifacts. This can be\n# simulated here by setting chan1 to FPz. \n\nchan1 = 'Pz'\nchan2 = 'C4'\nchan3 = 'C3'\n\neucdist1 = np.zeros(EEG['nbchan'][0][0])\neucdist2 = np.zeros(EEG['nbchan'][0][0])\neucdist3 = np.zeros(EEG['nbchan'][0][0])\n\nchan1idx = EEG['chanlocs'][0]['labels']==chan1\nchan2idx = EEG['chanlocs'][0]['labels']==chan2\nchan3idx = EEG['chanlocs'][0]['labels']==chan3\n\n# Calculate the Euclidean distances\nfor chani in range(EEG['nbchan'][0][0]):\n    eucdist1[chani] = np.sqrt((EEG['chanlocs'][0][chani]['X'][0][0] - EEG['chanlocs'][0][chan1idx]['X'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Y'][0][0] - EEG['chanlocs'][0][chan1idx]['Y'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Z'][0][0] - EEG['chanlocs'][0][chan1idx]['Z'][0][0])**2)\n    eucdist2[chani] = np.sqrt((EEG['chanlocs'][0][chani]['X'][0][0] - EEG['chanlocs'][0][chan2idx]['X'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Y'][0][0] - EEG['chanlocs'][0][chan2idx]['Y'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Z'][0][0] - EEG['chanlocs'][0][chan2idx]['Z'][0][0])**2)\n    eucdist3[chani] = np.sqrt((EEG['chanlocs'][0][chani]['X'][0][0] - EEG['chanlocs'][0][chan3idx]['X'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Y'][0][0] - EEG['chanlocs'][0][chan3idx]['Y'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Z'][0][0] - EEG['chanlocs'][0][chan3idx]['Z'][0][0])**2)\n\n# Compute spatial frequencies\nhi_spatfreq = 2 * np.exp(-eucdist1 ** 2 / (2 * 95 ** 2))\nlo_spatfreq = np.exp(-eucdist2 ** 2 / (2 * 50 ** 2)) + np.exp(-eucdist3 ** 2 / (2 * 50 ** 2))\nsurf_lap_all, _, _ = laplacian_perrinX(hi_spatfreq + lo_spatfreq, X, Y, Z)\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\nhi_spatfreq = np.delete(hi_spatfreq, exclude_chans)\nlo_spatfreq = np.delete(lo_spatfreq, exclude_chans)\nsurf_lap_all = np.delete(surf_lap_all, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot the surface Laplacian\nfig, axs = plt.subplots(2, 2, figsize=(10, 5))\nevoked = EvokedArray(hi_spatfreq[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[0, 0], show=False, times=-1, time_format='', colorbar=False)\naxs[0, 0].set_title('Low spatial frequency features')\n\nevoked = EvokedArray(lo_spatfreq[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[0, 1], show=False, times=-1, time_format='', colorbar=False)\naxs[0, 1].set_title('High spatial frequency features')\n\nevoked = EvokedArray(hi_spatfreq[:, np.newaxis] + lo_spatfreq[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[1, 0], show=False, times=-1, time_format='', colorbar=False)\naxs[1, 0].set_title('Low+high features')\n\nevoked = EvokedArray(surf_lap_all[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[1, 1], show=False, times=-1, time_format='', colorbar=False)\naxs[1, 1].set_title('Laplacian of low+high features')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Another example similar to Figure 4\n\n# Define channels for analysis\nchan1 = 'Cz'\nchan2 = 'P5'\n\neucdist1 = np.zeros(EEG['nbchan'][0][0])\neucdist2 = np.zeros(EEG['nbchan'][0][0])\n\nchan1idx = EEG['chanlocs'][0]['labels']==chan1\nchan2idx = EEG['chanlocs'][0]['labels']==chan2\n\n# Calculate the Euclidean distances\nfor chani in range(EEG['nbchan'][0][0]):\n    eucdist1[chani] = np.sqrt((EEG['chanlocs'][0][chani]['X'][0][0] - EEG['chanlocs'][0][chan1idx]['X'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Y'][0][0] - EEG['chanlocs'][0][chan1idx]['Y'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Z'][0][0] - EEG['chanlocs'][0][chan1idx]['Z'][0][0])**2)\n    eucdist2[chani] = np.sqrt((EEG['chanlocs'][0][chani]['X'][0][0] - EEG['chanlocs'][0][chan2idx]['X'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Y'][0][0] - EEG['chanlocs'][0][chan2idx]['Y'][0][0])**2 +\n                               (EEG['chanlocs'][0][chani]['Z'][0][0] - EEG['chanlocs'][0][chan2idx]['Z'][0][0])**2)\n\n# Compute data to use\ndata2use = np.exp(-eucdist1 ** 2 / (2 * 65 ** 2)) + np.exp(-eucdist2 ** 2 / (2 * 50 ** 2))\n\n# Compute surface Laplacian\nsurf_lap, _, _ = laplacian_perrinX(data2use, X, Y, Z)\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\ndata2use = np.delete(data2use, exclude_chans)\nsurf_lap = np.delete(surf_lap, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot topographic maps using plot_topomap\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nevoked = EvokedArray(data2use[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[0], show=False, times=-1, time_format='', colorbar=False)\naxs[0].set_title('Low spatial frequency features')\n\nevoked = EvokedArray(surf_lap[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[1], show=False, times=-1, time_format='', colorbar=False)\naxs[1].set_title('High spatial frequency features')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 22.5\n\n# Use the mean of the EEG data at a specific time point\ndata2use = np.mean(EEG['data'][:, 320, :], axis=1)\n\n# Compute surface Laplacian using Nunez and Perrin methods\nsurf_lapN = laplacian_nola(X, Y, Z, data2use, smoothing=100)\nsurf_lapP, _, _ = laplacian_perrinX(data2use, X, Y, Z, smoothing=1e-5)\n# note: try changing the smoothing parameter above (last input argument) to\n# see the effects of the smoothing (lambda) parameter. Reasonable values\n# are 1e-4 to 1e-6, and the default parameter is 1e-5.\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\ndata2use = np.delete(data2use, exclude_chans)\nsurf_lapN = np.delete(surf_lapN, exclude_chans)\nsurf_lapP = np.delete(surf_lapP, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot topographic maps using plot_topomap\nfig, axs = plt.subplots(1, 3, figsize=(10, 5))\nevoked = EvokedArray(data2use[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[0], show=False, times=-1, time_format='', colorbar=False)\naxs[0].set_title('Raw data')\n\nevoked = EvokedArray(surf_lapN[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[1], show=False, times=-1, time_format='', colorbar=False)\naxs[1].set_title('Laplacian (Nunez book)')\n\nevoked = EvokedArray(surf_lapP[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[2], show=False, times=-1, time_format='', colorbar=False)\naxs[2].set_title('Laplacian (Perrin et al.)')\n\nplt.tight_layout()\nplt.show()\n\n# Display spatial correlation between the two Laplacian methods\nspatial_corr = np.corrcoef(surf_lapN, surf_lapP)[0, 1]\nprint(f\"Spatial correlation: r={spatial_corr}\")\n\n\n\n\nSpatial correlation: r=0.9814967637990577\n\n\n\n# Figure 22.6\n\n# Timing is included in case you want to test the Perrin and New Orleans methods\ntimetest = []\n\n# Start timing for the first laplacian function\nstart_time = time.time()\nlap_data, _, _ = laplacian_perrinX(EEG['data'], X, Y, Z)\n# Calculate elapsed time and store it\nelapsed_time = time.time() - start_time\ntimetest.append(elapsed_time)\n\n# Start timing for the second laplacian function\nstart_time = time.time()\nlap_data2 = laplacian_nola(X, Y, Z, EEG['data'])\n# Calculate elapsed time and store it\nelapsed_time = time.time() - start_time\ntimetest.append(elapsed_time)\n\n# Define times to plot\ntimes2plot = np.arange(-100, 900, 100)\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\neeg_data = np.delete(EEG['data'], exclude_chans, axis=0)\nXlp = np.delete(X, exclude_chans)\nYlp = np.delete(Y, exclude_chans)\nZlp = np.delete(Z, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot voltage and Laplacian maps at different time points\nfig, ax = plt.subplots(2, len(times2plot), figsize=(20, 10))\nfor i, time_point in enumerate(times2plot):\n    # Find time index\n    timeidx = np.argmin(np.abs(EEG['times'] - time_point))\n    \n    # Get the mean data at the specified time point\n    tempdata = np.mean(eeg_data[:, timeidx, :], axis=1)\n    \n    # Plot voltage map (spatially unfiltered)\n    evoked = EvokedArray(tempdata[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\n    evoked.set_montage(montage)\n    evoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(-10000000, 10000000), axes=ax[0, i], show=False, times=-1, time_format='', colorbar=False)\n    ax[0, i].set_title(f'Voltage, {time_point} ms')\n    \n    # Plot Laplacian map (spatially filtered)\n    evoked = EvokedArray(laplacian_perrinX(tempdata, Xlp, Ylp, Zlp)[0][:, np.newaxis], info, tmin=EEG['xmin'][0][0])\n    evoked.set_montage(montage)\n    evoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(-40000000, 40000000), axes=ax[1, i], show=False, times=-1, time_format='', colorbar=False)\n    ax[1, i].set_title(f'Laplacian, {time_point} ms')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Brief aside:\n\n# This figure shows that computing the Laplacian of the ERP is the same as\n# computing the Laplacian of single trials and then taking the ERP. This is\n# not surprising: the ERP is a linear transform of the single trials.\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\neeg_data = np.delete(EEG['data'], exclude_chans, axis=0)\nX_lp = np.delete(X, exclude_chans)\nY_lp = np.delete(Y, exclude_chans)\nZ_lp = np.delete(Z, exclude_chans)\nlap_data_lp = np.delete(lap_data, exclude_chans, axis=0)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot the comparison\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nevoked = EvokedArray(laplacian_perrinX(np.mean(eeg_data[:, 320, :], axis=1), X_lp, Y_lp, Z_lp)[0][:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(-40000000, 40000000), axes=axs[0], show=False, times=-1, time_format='', colorbar=False)\n\nevoked = EvokedArray(np.mean(lap_data_lp[:, 320, :], axis=1)[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(-40000000, 40000000), axes=axs[1], show=False, times=-1, time_format='', colorbar=False)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 22.7\n\n# Define frequency and time of interest\nfreq2use = 8  # Hz\ntime2use = 400  # ms\n\n# FFT parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv2 = int(2**np.ceil(np.log2(n_convolution)))\n\n# Create wavelet and get FFT\nwavelet_fft = fft(np.exp(2 * 1j * np.pi * freq2use * time) * np.exp(-time ** 2 / (2 * (4 / (2 * np.pi * freq2use)) ** 2)) / freq2use, n_conv2)\nhalf_of_wavelet_size = (len(time) - 1) // 2\n\n# Initialize\nallphases_pre = np.zeros(EEG['data'].shape, dtype=complex)\nallphases_lap = np.zeros(EEG['data'].shape, dtype=complex)\nispc_pre = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nispc_lap = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\ntimeidx = np.argmin(np.abs(EEG['times'] - time2use))\n\n# Get all phases\nfor chani in range(EEG['nbchan'][0][0]):\n    # First for nonspatially filtered data\n    fft_data = fft(EEG['data'][chani, :, :].flatten('F'), n_conv2)\n    conv_res = ifft(wavelet_fft * fft_data, n_conv2)\n    conv_res = conv_res[:n_convolution]\n    conv_res = conv_res[half_of_wavelet_size:-half_of_wavelet_size]\n    allphases_pre[chani, :, :] = np.reshape(conv_res, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Then for Laplacian filtered data\n    fft_data = fft(lap_data[chani, :, :].flatten('F'), n_conv2)\n    conv_res = ifft(wavelet_fft * fft_data, n_conv2)\n    conv_res = conv_res[:n_convolution]\n    conv_res = conv_res[half_of_wavelet_size:-half_of_wavelet_size]\n    allphases_lap[chani, :, :] = np.reshape(conv_res, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Compute synchrony\nfor chani in range(EEG['nbchan'][0][0]):\n    for chanj in range(chani + 1, EEG['nbchan'][0][0]):\n        # Cross-spectral density for nonspatially filtered data\n        cd_pre = allphases_pre[chani, timeidx, :] * np.conj(allphases_pre[chanj, timeidx, :])\n        ispc_pre[chani, chanj] = np.abs(np.mean(np.exp(1j * np.angle(cd_pre))))\n        \n        # Cross-spectral density for Laplacian filtered data\n        cd_lap = allphases_lap[chani, timeidx, :] * np.conj(allphases_lap[chanj, timeidx, :])\n        ispc_lap[chani, chanj] = np.abs(np.mean(np.exp(1j * np.angle(cd_lap))))\n\n# Mirror connectivity matrices\nispc_pre = ispc_pre + ispc_pre.T + np.eye(EEG['nbchan'][0][0])\nispc_lap = ispc_lap + ispc_lap.T + np.eye(EEG['nbchan'][0][0])\n\n# Plot ISPC as a function of electrode distances\nplt.figure(figsize=(10, 5))\nplt.subplot(121)\nplt.plot(interelectrodedist[valid_gridpoints], ispc_pre[valid_gridpoints], '.')\nplt.xlim([0, 200])\nplt.ylim([0, 1])\nplt.xlabel('Electrode distances (mm)')\nplt.ylabel('ISPC')\nplt.title(f'Spatially unfiltered ISPC at {freq2use} Hz')\nr_pre = np.corrcoef(interelectrodedist[valid_gridpoints], ispc_pre[valid_gridpoints])[0, 1]\nplt.legend([f'R^2 = {r_pre ** 2:.4f}'])\n\nplt.subplot(122)\nplt.plot(interelectrodedist[valid_gridpoints], ispc_lap[valid_gridpoints], '.')\nplt.xlim([0, 200])\nplt.ylim([0, 1])\nplt.xlabel('Electrode distances (mm)')\nplt.ylabel('ISPC')\nplt.title(f'Laplacian filtered ISPC at {freq2use} Hz')\nr_lap = np.corrcoef(interelectrodedist[valid_gridpoints], ispc_lap[valid_gridpoints])[0, 1]\nplt.legend([f'R^2 = {r_lap ** 2:.4f}'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 22.8\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\nispc_pre_lp = np.delete(ispc_pre, exclude_chans, axis=1)\nispc_lap_lp = np.delete(ispc_lap, exclude_chans, axis=1)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot topographic maps of ISPC for a specific channel (e.g., channel 48)\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nevoked = EvokedArray(ispc_pre_lp[47, :, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(0, 800000), axes=axs[0], show=False, times=-1, time_format='', colorbar=False)\naxs[0].set_title(f'ISPC_raw at {time2use} ms, {freq2use} Hz')\n\nevoked = EvokedArray(ispc_lap_lp[47, :, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(0, 800000), axes=axs[1], show=False, times=-1, time_format='', colorbar=False)\naxs[1].set_title(f'ISPC_lap at {time2use} ms, {freq2use} Hz')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter06.html",
    "href": "chapter06.html",
    "title": "Chapter 6",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 6 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Figure 6.2\n\n# Create sine wave\nsrate = 1000\ntime = np.arange(0, 1, 1/srate)\nfrequency = 3\n\nsinewave = np.sin(2 * np.pi * frequency * time)\n\n# Plot the continuous sine wave and sampled sine waves\nplt.figure(figsize=(10, 8))\n\n# Continuous sine wave\nplt.subplot(311)\nplt.plot(time, sinewave, 'r')\nplt.xlim([-.05, time[-1] * 1.05])\nplt.ylim([-1.1, 1.1])\nplt.title('continuous sine wave')\nsampling1 = np.round(np.linspace(0, len(time)-1, frequency*2)).astype(int)\nplt.plot(time[sampling1], sinewave[sampling1], 'o')\n\n# Sampled at 2*frequency\nplt.subplot(312)\nplt.plot(time[sampling1], sinewave[sampling1], '-o')\nplt.xlim([-.05, time[-1] * 1.05])\nplt.ylim([-1.1, 1.1])\nplt.title('sampled at 2*frequency')\n\n# Sampled at 20*frequency\nsampling2 = np.round(np.linspace(0, len(time)-1, frequency*20)).astype(int)\nplt.subplot(313)\nplt.plot(time[sampling2], sinewave[sampling2], '-+')\nplt.title('sampled at 20*frequency')\nplt.xlim([-.05, time[-1] * 1.05])\nplt.ylim([-1.1, 1.1])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter18.html",
    "href": "chapter18.html",
    "title": "Chapter 18",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 18 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fftpack import fft, ifft\nfrom scipy.stats import zscore\n\n\n## Figure 18.1\n\n# 1/f function\nc = 1\nx = 1\nplt.plot(c / np.arange(1, 101)**x)\nplt.xlim([0, 100])\nplt.ylim([0, 1])\nplt.show()\n\n\n\n\n\n## Figure 18.2\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Wavelet parameters\nmin_freq = 2\nmax_freq = 128\nnum_frex = 30\n\n# Other wavelet parameters\nfrequencies = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\ntime = np.arange(-1, 1 + 1/EEG['srate'], 1/EEG['srate'])\nhalf_of_wavelet_size = (len(time) - 1) // 2\n\n# FFT parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\nwavelet_cycles = 4\n\n# FFT of data (note: this doesn't change on frequency iteration)\nfft_data = fft(EEG['data'][22, :, 0], n_conv_pow2)\n\n# Initialize output time-frequency data\ntf_data = np.zeros((len(frequencies), EEG['pnts'][0][0]))\n\nfor fi in range(len(frequencies)):\n    # Create wavelet and get its FFT\n    wavelet = (np.pi * frequencies[fi] * np.sqrt(np.pi))**-0.5 * np.exp(2 * 1j * np.pi * frequencies[fi] * time) * np.exp(-time**2 / (2 * (wavelet_cycles / (2 * np.pi * frequencies[fi]))**2)) / frequencies[fi]\n    fft_wavelet = fft(wavelet, n_conv_pow2)\n    \n    # Run convolution\n    convolution_result_fft = ifft(fft_wavelet * fft_data, n_conv_pow2)\n    convolution_result_fft = convolution_result_fft[:n_convolution]\n    convolution_result_fft = convolution_result_fft[half_of_wavelet_size: -half_of_wavelet_size]\n    \n    # Put power data into time-frequency matrix\n    tf_data[fi, :] = np.abs(convolution_result_fft)**2\n\n# Plot results\nplt.figure(figsize=(10, 8))\nytickskip = np.arange(2, num_frex+4, 4)\n\n# Subplot 1\nplt.subplot(221)\nplt.imshow(tf_data, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(0, 5000)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.gca().invert_yaxis()\nplt.title('Color limit of 0 to 5000')\n\n# Subplot 2\nplt.subplot(222)\nplt.imshow(tf_data, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(0, 800)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('Color limit of 0 to 800')\n\n# Subplot 3\nplt.subplot(223)\nplt.imshow(tf_data, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(0, 25)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('Color limit of 0 to 25')\n\n# Subplot 4\nplt.subplot(224)\nplt.imshow(np.log10(tf_data), aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(-4, 4)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('Color limit of -4 to 4 (log10 units)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n## Figure 18.3\n\n# Define baseline period\nbaselinetime = [-500, -200]  # in ms\n\n# Convert baseline window time to indices\nbaselineidx = [np.argmin(np.abs(EEG['times'][0] - bt)) for bt in baselinetime]\n\n# dB-correct\nbaseline_power = np.mean(tf_data[:, baselineidx[0]:baselineidx[1]], axis=1)\ndbconverted = 10 * np.log10(tf_data / baseline_power[:, np.newaxis])\n\n# Plot\nplt.figure(figsize=(8, 6))\nplt.contourf(EEG['times'][0], frequencies, dbconverted, 40, cmap='viridis')\nplt.clim(-12, 12)\nplt.xlim([-500, 1500])\nplt.title('Color limit of -12 to +12 dB')\nplt.yscale('log')\nylabels = np.round(np.logspace(np.log10(frequencies[0]),np.log10(frequencies[-1]),10)*100)/100\nplt.yticks(ylabels, ylabels)\nplt.show()\n\n\n\n\n\n## Figure 18.4\n\n# Time to plot\ntime2plot = 300  # in ms\n\n# Find the index of the time to plot\ntimeidx = np.argmin(np.abs(EEG['times'][0] - time2plot))\n\n# Plot frequencies\nplt.figure(figsize=(10, 6))\n\n# Subplot 1: Raw power\nplt.subplot(211)\nplt.plot(frequencies, tf_data[:, timeidx])\nplt.title(f'Power spectrum at {EEG[\"times\"][0][timeidx]:.4f} ms')\nplt.xlim([0, 140])\nplt.ylim([0, 600])\nplt.ylabel('Raw power (uV^2)')\nplt.xlabel('Frequency (Hz)')\n\n# Subplot 2: Baseline-normalized power\nplt.subplot(212)\nplt.plot(frequencies, dbconverted[:, timeidx])\nplt.xlim([0, 140])\nplt.ylim([-20, 5])\nplt.ylabel('Baseline-normalized power (dB)')\nplt.xlabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n## Figure 18.5\n\n# This figure was created by changing the color limits of figure 18.3\n\n\n## Figure 18.6\n\n# Activity and baseline\nactivity = np.arange(1, 20.001, 0.01)\nbaseline = 10\n\n# Compute dB and percent change\ndb = 10 * np.log10(activity / baseline)\npc = 100 * (activity - baseline) / baseline\n\n# Plot\nplt.figure(figsize=(8, 6))\nplt.plot(db, pc)\nplt.xlim([-10, 4])\nplt.ylim([-100, 100])\nplt.xlabel('dB')\nplt.ylabel('Percent change')\n\n# Find indices where db is closest to -/+2\ndbOf2 = np.argmin(np.abs(db - 2))\ndbOfminus2 = np.argmin(np.abs(db - (-2)))\n\nprint(f'dB of -2 corresponds to {pc[dbOfminus2]:.1f}% change.')\nprint(f'dB of +2 corresponds to +{pc[dbOf2]:.1f}% change.')\n\nplt.axvline(x=db[dbOf2], color='k', linestyle='--')\nplt.axhline(y=pc[dbOf2], color='k', linestyle='--')\nplt.axvline(x=db[dbOfminus2], color='k', linestyle='--')\nplt.axhline(y=pc[dbOfminus2], color='k', linestyle='--')\n\nplt.title('Relationship between dB and Percent Change')\nplt.show()\n\n# Real data: percent change vs. baseline division\nplt.figure(figsize=(12, 10))\n\n# Baseline power and percent change\nbaseline_power = np.mean(tf_data[:, baselineidx[0]:baselineidx[1]], axis=1)\npctchange = 100 * (tf_data - baseline_power[:, np.newaxis]) / baseline_power[:, np.newaxis]\n\n# Subplot 1: Baseline division\nplt.subplot(221)\nbaselinediv = tf_data / baseline_power[:, np.newaxis]\nplt.plot(dbconverted.flatten('F')[::5], baselinediv.flatten('F')[::5], '.')\nplt.xlim([-40, 10])\nplt.ylim([0, 7])\nplt.xlabel('DB')\nplt.ylabel('Baseline division')\n\n# Subplot 2: dB vs. baseline division\nplt.subplot(222)\nplt.plot(pctchange.flatten('F')[::5], baselinediv.flatten('F')[::5], '.')\nplt.xlim([-200, 600])\nplt.ylim([0, 7])\nplt.xlabel('Percent change')\nplt.ylabel('Baseline division')\n\n# Subplot 3: Z-transform vs. percent change\nplt.subplot(223)\nbaselineZ = (tf_data - baseline_power[:, np.newaxis]) / np.std(tf_data[:, baselineidx[0]:baselineidx[1]], axis=1, ddof=1)[:, np.newaxis]\nplt.plot(baselineZ.flatten('F')[::5], pctchange.flatten('F')[::5], '.')\nplt.xlim([-40, 10])\nplt.ylim([-100, 600])\nplt.xlabel('Z-transform')\nplt.ylabel('Percent change')\n\n# Subplot 4: Z-transform vs. dB\nplt.subplot(224)\nplt.plot(baselineZ.flatten('F')[::5], dbconverted.flatten('F')[::5], '.')\nplt.xlim([-40, 10])\nplt.ylim([-40, 10])\nplt.xlabel('Z-transform')\nplt.ylabel('DB')\n\nplt.tight_layout()\nplt.show()\n\ndB of -2 corresponds to -36.9% change.\ndB of +2 corresponds to +58.5% change.\n\n\n\n\n\n\n\n\n\n## Figure 18.7\n\n# Plot dB-converted power, percent-change, divide by baseline, and z-transform\nplt.figure(figsize=(12, 10))\n\n# Subplot 1: dB change from baseline\nplt.subplot(221)\nplt.imshow(dbconverted, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(-10, 10)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('dB change from baseline')\n\n# Subplot 2: Percent change from baseline\nplt.subplot(222)\npctchange = 100 * (tf_data - baseline_power[:, np.newaxis]) / baseline_power[:, np.newaxis]\nplt.imshow(pctchange, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(-500, 500)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('Percent change from baseline')\n\n# Subplot 3: Divide by baseline\nplt.subplot(223)\nbaselinediv = tf_data / baseline_power[:, np.newaxis]\nplt.imshow(baselinediv, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(-7.5, 7.5)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('Divide by baseline')\n\n# Subplot 4: Z-transform\nplt.subplot(224)\nbaselineZ = zscore(tf_data, axis=1, ddof=1)\nplt.imshow(baselineZ, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], ytickskip[-1], ytickskip[0]])\nplt.clim(-3.5, 3.5)\nplt.xlim([-500, 1500])\nplt.yticks(ytickskip, np.round(frequencies[ytickskip-1]).astype(int))\nplt.gca().invert_yaxis()\nplt.title('Z-transform')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n## Figure 18.8\n\n# Define baseline period and channel to plot\nchan2plot = 'FCz'  # p1 for figure 18.11\nbaselinetime = [-500, -200]  # in ms\n\n# Convert baseline window time to indices\nbaselineidx = [np.argmin(np.abs(EEG['times'][0] - bt)) for bt in baselinetime]\n\n# Initialize time-frequency data\ntf_data = np.zeros((2, len(frequencies), EEG['pnts'][0][0]))\n\n# Update FFT parameters for multiple trials\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\n\n# FFT of data\nfft_data = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot].flatten('F'), n_conv_pow2)\n\n# Convolution for each frequency\nfor fi in range(len(frequencies)):\n    # Create wavelet and get its FFT\n    wavelet = (np.pi * frequencies[fi] * np.sqrt(np.pi))**-0.5 * np.exp(2 * 1j * np.pi * frequencies[fi] * time) * np.exp(-time**2 / (2 * (wavelet_cycles / (2 * np.pi * frequencies[fi]))**2)) / frequencies[fi]\n    fft_wavelet = fft(wavelet, n_conv_pow2)\n    \n    # Run convolution\n    convolution_result_fft = ifft(fft_wavelet * fft_data, n_conv_pow2)\n    convolution_result_fft = convolution_result_fft[:n_convolution]\n    convolution_result_fft = convolution_result_fft[half_of_wavelet_size: -half_of_wavelet_size]\n    convolution_result_fft = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Save single-trial data from one frequency band\n    if fi == 5:\n        convdat2keep = convolution_result_fft\n    \n    # Put power data into time-frequency matrix\n    tf_data[0, fi, :] = np.mean(np.abs(convolution_result_fft)**2, axis=1)\n    tf_data[1, fi, :] = np.median(np.abs(convolution_result_fft)**2, axis=1)\n\n# dB-correct and plot\nlabelz = ['mean', 'median']\nplt.figure(figsize=(12, 10))\nfor i in range(2):\n    baseline_power = np.mean(tf_data[i, :, baselineidx[0]:baselineidx[1]], axis=1)\n    dbconverted = 10 * np.log10(tf_data[i] / baseline_power[:, np.newaxis])\n    \n    # Plot\n    plt.subplot(2, 2, i + 1)\n    plt.contourf(EEG['times'][0], frequencies, dbconverted, 40, cmap='viridis')\n    plt.clim(-3, 3)\n    plt.xlim([-200, 1000])\n    plt.xlabel('Time (ms)')\n    plt.ylabel('Frequency (Hz)')\n    plt.yscale('log')\n    ylabels = np.round(np.logspace(np.log10(frequencies[0]),np.log10(frequencies[-1]),6), 1)\n    plt.yticks(ylabels, ylabels)\n    plt.title(labelz[i])\n\n# Plot relationship between mean and median\nplt.subplot(223)\ndb_mean = 10 * np.log10(tf_data[0] / np.mean(tf_data[0, :, baselineidx[0]:baselineidx[1]], axis=1)[:, np.newaxis])\ndb_medn = 10 * np.log10(tf_data[1] / np.mean(tf_data[1, :, baselineidx[0]:baselineidx[1]], axis=1)[:, np.newaxis])\nplt.plot(db_mean.flatten('F'), db_medn.flatten('F'), '.')\nr = np.corrcoef(db_mean.flatten('F'), db_medn.flatten('F'))[0, 1]\nplt.legend([f'R^2 = {r**2:.5f}'])\nplt.xlabel('dB from Mean')\nplt.ylabel('dB from Median')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n## Figure 18.9\n\n# Plot all trials, mean, and median\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: All trials\nplt.subplot(211)\nplt.plot(EEG['times'][0], np.abs(convdat2keep)**2)\nplt.xlim([-200, 1000])\nplt.ylim([0, 1400])\n\n# Subplot 2: Mean and median\nplt.subplot(212)\nplt.plot(EEG['times'][0], np.mean(np.abs(convdat2keep)**2, axis=1), label='Mean')\nplt.plot(EEG['times'][0], np.median(np.abs(convdat2keep)**2, axis=1), 'r', label='Median')\nplt.xlim([-200, 1000])\nplt.ylim([np.min(np.median(np.abs(convdat2keep)**2, axis=1)), 200])\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Add an outlier trial\nconvdat2keep1 = np.column_stack((convdat2keep, convdat2keep[:, 9] * 100))\n# Note we save to a new variable so the cell can be re-run without issue \n# The Matlab code does not do this and gives different plots when the single section is re-run\n\nplt.figure(figsize=(12, 10))\n\n# Subplot 3: Median with and without outlier\nplt.subplot(223)\nplt.plot(EEG['times'][0], np.median(np.abs(convdat2keep1)**2, axis=1), label='With outlier')\nplt.plot(EEG['times'][0], np.median(np.abs(convdat2keep1[:, :-1])**2, axis=1), 'r', label='Without outlier')\nplt.xlim([-200, 1000])\nplt.ylim([20, 140])\nplt.legend()\nplt.title('Median: insensitive to outlier trial')\n\n# Subplot 4: Mean with and without outlier\nplt.subplot(224)\nplt.plot(EEG['times'][0], np.mean(np.abs(convdat2keep1)**2, axis=1), label='With outlier')\nplt.plot(EEG['times'][0], np.mean(np.abs(convdat2keep1[:, :-1])**2, axis=1), 'r', label='Without outlier')\nplt.xlim([-200, 1000])\nplt.ylim([0, 100000])\nplt.legend()\nplt.title('Mean: sensitive to outlier trial')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n## Figure 18.10\n\n# Convenientize power\nconvdatPower = np.abs(convdat2keep1)**2\n\n# Single-trial linear baseline correction\nconvdat2keepB = convdatPower - np.mean(convdatPower[baselineidx[0]:baselineidx[1], :], axis=0)\n\n# Single-trial Z score\nconvdat2keepZ = (convdatPower - np.mean(convdatPower[baselineidx[0]:baselineidx[1], :], axis=0)) / np.std(convdatPower[baselineidx[0]:baselineidx[1], :], axis=0)\n\n# Single-trial log10\nconvdat2keepL = np.log10(convdatPower)\n\n# Plot\nplt.figure(figsize=(12, 10))\n\n# Subplot 1: Linear baseline subtraction\nplt.subplot(221)\nplt.plot(EEG['times'][0], np.mean(convdat2keepB, axis=1), 'r', label='Mean')\nplt.plot(EEG['times'][0], np.median(convdat2keepB, axis=1), 'b', label='Median')\nplt.xlim([-200, 1000])\nplt.ylim([-20000, 80000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Power')\nplt.legend()\nplt.title('Linear baseline subtraction')\n\n# Subplot 2: Z-transformation\nplt.subplot(222)\nplt.plot(EEG['times'][0], np.mean(convdat2keepZ, axis=1), 'r', label='Mean')\nplt.plot(EEG['times'][0], np.median(convdat2keepZ, axis=1), 'b', label='Median')\nplt.xlim([-200, 1000])\nplt.ylim([-2, 10])\nplt.xlabel('Time (ms)')\nplt.ylabel('Power_Z')\nplt.legend()\nplt.title('Z-transformation')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n## Figure 18.11\n\n# This figure was made by running the code for figure 18.8 but using P1\n# instead of FCz. (Fewer frequencies were also plotted.)\n\n\n## Figure 18.12\n\n# Initialize SNR and trial-averaged power arrays\nsnr_bs = np.zeros((len(frequencies), EEG['pnts'][0][0]))\nsnr_tf = np.zeros((len(frequencies), EEG['pnts'][0][0]))\ntf = np.zeros((len(frequencies), EEG['pnts'][0][0]))\n\n# Compute SNR and trial-averaged power for each frequency\nfor fi in range(len(frequencies)):\n    # Create wavelet and get its FFT\n    wavelet = np.exp(2 * 1j * np.pi * frequencies[fi] * time) * np.exp(-time**2 / (2 * (wavelet_cycles / (2 * np.pi * frequencies[fi]))**2)) / frequencies[fi]\n    fft_wavelet = fft(wavelet, n_conv_pow2)\n    \n    # Run convolution\n    convolution_result = ifft(fft_wavelet * fft_data, n_conv_pow2) * np.sqrt(wavelet_cycles /(2 * np.pi * frequencies[fi]))\n    convolution_result = convolution_result[:n_convolution]\n    convolution_result = convolution_result[half_of_wavelet_size: -half_of_wavelet_size]\n    convolution_result = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Extract SNR in two ways\n    snr_tf[fi, :] = np.mean(np.abs(convolution_result)**2, axis=1) / np.std(np.abs(convolution_result)**2, axis=1)\n    snr_bs[fi, :] = np.mean(np.abs(convolution_result)**2, axis=1) / np.std(np.mean(np.abs(convolution_result[baselineidx[0]:baselineidx[1], :])**2, axis=0))\n    \n    # Extract trial-averaged power\n    tf[fi, :] = np.mean(np.abs(convolution_result)**2, axis=1)\n\n# Plot SNR_baseline and SNR_tf\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: SNR_baseline (mean/std)\nplt.subplot(121)\nplt.contourf(EEG['times'][0], frequencies, snr_bs, 40, cmap='viridis')\n# plt.colorbar()\nplt.clim(0.5, 2)\nplt.xlim([-200, 1000])\nplt.ylim([frequencies[0], 40])\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.title('SNR_baseline (mean/std)')\n\n# Subplot 2: Relationship between SNR_baseline and Power/baseline\nplt.subplot(122)\nbaseline_power = np.mean(tf[:, baselineidx[0]:baselineidx[1]], axis=1)\nbaselinediv = tf / baseline_power[:, np.newaxis]\nplt.plot(snr_bs.flatten('F')[::3], baselinediv.flatten('F')[::3], '.')\nplt.xlim([0, 10])\nplt.ylim([0, 6])\nplt.xlabel('SNR_baseline')\nplt.ylabel('Power (/baseline)')\n\nplt.tight_layout()\nplt.show()\n\n# Plot SNR_tf\nplt.figure(figsize=(12, 6))\n\n# Subplot 1: SNR_tf (mean/std)\nplt.subplot(121)\nplt.contourf(EEG['times'][0], frequencies, snr_tf, 40, cmap='viridis')\n# plt.colorbar()\nplt.clim(0.5, 1.25)\nplt.xlim([-200, 1000])\nplt.ylim([frequencies[0], 40])\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.title('SNR_tf (mean/std)')\n\n# Subplot 2: Relationship between SNR_tf and Power/baseline\nplt.subplot(122)\nplt.plot(snr_tf.flatten('F')[::3], baselinediv.flatten('F')[::3], '.')\nplt.xlim([0, 1.4])\nplt.ylim([0, 6])\nplt.xlabel('SNR_tf')\nplt.ylabel('Power (/baseline)')\n\nplt.tight_layout()\nplt.show()\n\n# Time-series of SNR\nplt.figure(figsize=(8, 4))\nmean_data = np.mean(EEG['data'][46, :, :], axis=1)\nstd_data = np.std(EEG['data'][46, :, :], axis=1)\nplt.plot(EEG['times'][0], np.abs(mean_data / std_data))\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('SNR')\nplt.title('Time-domain SNR time series')\nplt.show()\n\n# Compute SNR of peak compared to prestim noise\nstimeidx = np.argmin(np.abs(EEG['times'][0] - 150))\netimeidx = np.argmin(np.abs(EEG['times'][0] - 400))\nerp_snr = np.max(mean_data[stimeidx:etimeidx]) / np.std(mean_data[baselineidx[0]:baselineidx[1]])\nprint(f'ERP SNR between 150 and 400 ms at FCz: {erp_snr}')\n\n\n\n\n\n\n\n\n\n\nERP SNR between 150 and 400 ms at FCz: 10.508532524108887\n\n\n\n## Figure 18.13\n\n# Initialize variables\niterations = 10\nchan2plot = 'P7'  # or FCz\ndbcorrect = False\n\npowerByTrialFreq = np.zeros((len(frequencies), EEG['trials'][0][0]))\n\n# Define time range\nstart_time = -200  # in ms\nend_time = 1200\n\n# FFT of data\nfft_data = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot].flatten('F'), n_conv_pow2)\ntimeidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in [start_time, end_time]]\n\n# Compute power by trial frequency\nfor fi in range(len(frequencies)):\n    # Create wavelet and get its FFT\n    wavelet = np.exp(2 * 1j * np.pi * frequencies[fi] * time) * np.exp(-time**2 / (2 * (wavelet_cycles / (2 * np.pi * frequencies[fi]))**2)) / frequencies[fi]\n    fft_wavelet = fft(wavelet, n_conv_pow2)\n    \n    # Run convolution\n    convolution_result = ifft(fft_wavelet * fft_data, n_conv_pow2) * np.sqrt(wavelet_cycles / (2 * np.pi * frequencies[fi]))\n    convolution_result = convolution_result[:n_convolution]\n    convolution_result = convolution_result[half_of_wavelet_size: -half_of_wavelet_size]\n    convolution_result = np.abs(np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F'))**2  # reshape and convert to power\n    \n    # \"Gold standard\" is average of all trials\n    if dbcorrect:\n        template = 10 * np.log10(np.mean(convolution_result, axis=1) / np.mean(np.mean(convolution_result[baselineidx[0]:baselineidx[1], :], axis=0)))\n        template = template[timeidx[0]:timeidx[1]]\n    else:\n        template = np.mean(convolution_result[timeidx[0]:timeidx[1]], axis=1)\n    template = (template - np.mean(template)) / np.std(template)\n    \n    for iteri in range(iterations):\n        for triali in range(5, EEG['trials'][0][0]):  # start at 5 trials...\n            trials2use = np.random.choice(EEG['trials'][0][0], triali, replace=False)\n            \n            # Compute power time series from the random selection of trials\n            if dbcorrect:\n                tempdat = 10 * np.log10(np.mean(convolution_result[:, trials2use], axis=1) / np.mean(np.mean(convolution_result[baselineidx[0]:baselineidx[1], trials2use])))\n                tempdat = tempdat[timeidx[0]:timeidx[1]]\n            else:\n                tempdat = np.mean(convolution_result[timeidx[0]:timeidx[1], trials2use], axis=1)\n            tempdat = (tempdat - np.mean(tempdat)) / np.std(tempdat)\n            \n            # Compute Pearson correlation\n            powerByTrialFreq[fi, triali] += np.dot(tempdat, template) / np.dot(tempdat, tempdat)\n\npowerByTrialFreq /= iterations\n\n# Plot\nplt.figure(figsize=(10, 8))\nplt.plot(np.arange(5, EEG['trials'][0][0] + 1), powerByTrialFreq[:, 4:].T)\nplt.xlabel('Number of trials')\nplt.ylabel('Power')\nplt.ylim([-0.1, 1.1])\nplt.title('Each line is a frequency band')\n\nplt.figure(figsize=(10, 8))\nplt.contourf(np.arange(5, EEG['trials'][0][0] + 1), frequencies, powerByTrialFreq[:, 4:], 40, cmap='viridis')\nplt.clim(0.6, 1)\nplt.xlabel('Number of trials')\nplt.ylabel('Frequency (Hz)')\nplt.title('DB normalized' if dbcorrect else 'Not dB normalized')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter04c.html",
    "href": "chapter04c.html",
    "title": "Chapter 4c",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 4 script C – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nfrom tkinter import filedialog\nfrom tkinter import Tk\nimport csv\n\n\n# Clearing variables in Python are most often done by simply overwriting them, but they can also be deleted.\n# Here's an example of deleting a variable:\n\nleave_me_alone = 10\nremove_me_please = 20\ndel remove_me_please\n\n# To see the list of variables currently in the namespace, you can use:\n\n\n# Trying to print a deleted variable will raise an error in Python.\n# Uncommenting the following line will raise a NameError:\n# print(remove_me_please)\n\nVariable         Type      Data/Info\n------------------------------------\nTk               type      &lt;class 'tkinter.Tk'&gt;\ncsv              module    &lt;module 'csv' from '/User&lt;...&gt;2/lib/python3.10/csv.py'&gt;\nfiledialog       module    &lt;module 'tkinter.filedial&lt;...&gt;0/tkinter/filedialog.py'&gt;\nleave_me_alone   int       10\nnp               module    &lt;module 'numpy' from '/Us&lt;...&gt;kages/numpy/__init__.py'&gt;\n\n\n\n# Basic importing text data\n\n# In Python, you can load numeric data from a text file using numpy.\n\n# Loading data from a text file:\ndata = np.loadtxt('../data/chapter04_datafile.txt')\n\n# For a more interactive approach, you can use a file dialog to select a file:\nroot = Tk()\nroot.withdraw()  # we don't want a full GUI, so keep the root window from appearing\nfile_path = filedialog.askopenfilename(filetypes=[(\"Text files\", \"*.txt\")])\ndata = np.loadtxt(file_path)\n\n# Reading data from an Excel file can be done using pandas:\nimport pandas as pd\n\n# Read data from an Excel file:\nexcel_data = pd.read_excel('../data/chapter04_excel_data.xls')\nnumberdata = excel_data.to_numpy()\ntextdata = excel_data.columns.values\nraw_data = excel_data.values\n\n2023-12-06 13:04:11.321 python[29248:42197023] +[CATransaction synchronize] called within transaction\n\n\n\n# Advanced importing text data\n\n# In Python, you can use the csv module for more complex data import scenarios.\n\nbehavioral_data = []  # Initialize an empty list to store the data.\n\n# Open the file and read line by line.\nwith open('../data/chapter04_headache_data.txt', 'r') as fid:\n    reader = csv.reader(fid, delimiter='\\t')\n    \n    datarow = 0\n    for row in reader:\n        if 'trial' not in [element.lower() for element in row]:\n            continue  # Skip to the next iteration if 'trial' is not in the row.\n        \n        # Find the column indices for the relevant data.\n        trial_column = row.index('trial')\n        choice_column = row.index('choice')\n        rt_column = row.index('rt')\n        accuracy_column = row.index('accuracy')\n        \n        # Extract and convert the data, then append to the behavioral_data list.\n        behavioral_data.append([\n            float(row[trial_column + 1]),\n            float(row[choice_column + 1]),\n            float(row[rt_column + 1]),\n            float(row[accuracy_column + 1])\n        ])\n        \n        datarow += 1  # Increment the row counter.\n\n\n# Initializing variables\n\nnum_rows = 10\nnum_cols = 35\n\n# Initialize with zeros (typical approach in Python)\nlargematrix = np.zeros((num_rows, num_cols))\n\n# Example of processing in a nested loop\nfor rowi in range(num_rows):\n    for coli in range(num_cols):\n        # Processing here...\n        pass\n\n# Note that in Python, you can dynamically resize numpy arrays, but it's not efficient.\nlargematrix = np.pad(largematrix, ((0, 1), (0, 0)), mode='constant', constant_values=10) # Add a new row.\nlargematrix = np.reshape(largematrix, (largematrix.shape[0], largematrix.shape[1], 1)) # Add a dimension.\nlargematrix = np.pad(largematrix, ((0, 0), (0, 0), (0, 2)), mode='constant', constant_values=0)\nlargematrix[0, num_cols // 2, 2] = 100\n\n# Decrease dimensions by re-assignment:\nlargematrix = largematrix[:, :, 0]  # Remove the last dimension.\n\n# You can also decrease the size of arrays by slicing:\nprint(largematrix.shape)\nlargematrix = largematrix[:, :-5]  # Remove the last 5 columns.\nprint(largematrix.shape)\n\n# Again, changing matrix sizes and dimensions should be avoided when\n# possible, and done carefully when necessary.\n\n(11, 35)\n(11, 30)\n\n\n\n# Basic saving data\n\n# Save as a .npy file (Python's binary format, readable with numpy):\nnp.save('../data/my_python_variables.npy', data)\n\n# Save as a text file with a specific delimiter:\nnp.savetxt('../data/data_written_from_python.txt', data, delimiter='\\t')\n\n\n# Advanced saving data\n\n# Writing data to a text file in a format that can be imported into SPSS or Excel.\nwith open('../data/data_output_SPSS_format.txt', 'w', newline='') as fid:\n    writer = csv.writer(fid, delimiter='\\t')\n    \n    # Variable labels\n    variable_labels = ['Name', 'trial', 'choice', 'rt', 'accuracy']\n    \n    # Subject names\n    subject_names = ['billy', 'bob']\n    \n    # Write variable labels\n    writer.writerow(variable_labels)\n    \n    # Write data rows\n    for datarowi, data_row in enumerate(behavioral_data):\n        # Write subject name and data\n        writer.writerow([subject_names[datarowi % len(subject_names)]] + data_row)\n        print(f'Finished writing line {datarowi + 1} of {len(behavioral_data)}')\n\nFinished writing line 1 of 2\nFinished writing line 2 of 2"
  },
  {
    "objectID": "chapter05.html",
    "href": "chapter05.html",
    "title": "Chapter 5",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 5 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, ifft\nfrom scipy.io import loadmat\n\n\n# Time-locked and non-phase-locked analysis\n\n# Load sample data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\nnTrials = 4\ndata = np.zeros((nTrials, EEG['pnts'][0][0]))\n\n# Wavelet parameters\nwavetime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nn_conv = len(wavetime) + EEG['pnts'][0][0] - 1\nwaveletfft = fft(np.exp(2 * 1j * np.pi * 10 * wavetime) * np.exp(-wavetime ** 2 / (2 * (5 / (2 * np.pi * 10)) ** 2)) / 10, n_conv)\ndata10hz = np.zeros((nTrials, EEG['pnts'][0][0]))\n\nplt.figure(figsize=(15, 10))\n\nfor triali in range(nTrials):\n    # Create single trial ERP as sine wave plus noise\n    data[triali, :] = 0.15 * np.sin(2 * np.pi * 6 * EEG['times'][0] / 1000 + 2 * np.pi * (triali + 1) / nTrials - np.pi) + np.random.randn(EEG['pnts'][0][0]) / 6\n    # Add non-phase-locked stimulus potential\n    data[triali, 259:360] = data[triali, 259:360] + np.sin(2 * np.pi * 10 * EEG['times'][0][259:360] / 1000 + 2 * np.pi * (triali + 1) / nTrials - np.pi) + np.random.randn(101) / 5\n    \n    # Convolve with 10Hz wavelet\n    convolution_result_fft = ifft(waveletfft * fft(data[triali, :], n_conv)) * np.sqrt(5 / (2 * np.pi * 10))\n    convolution_result_fft = convolution_result_fft[int(np.floor(len(wavetime) / 2)) : -int(np.floor(len(wavetime) / 2))]\n    data10hz[triali, :] = np.abs(convolution_result_fft)*2\n    \n    # Plot single trials\n    plt.subplot(nTrials, 3, (triali) * 3 + 1)\n    plt.plot(EEG['times'][0], data[triali, :])\n    plt.plot(EEG['times'][0], data10hz[triali, :], 'r')\n    plt.xlim([-250, 850])\n    plt.ylim([-2.2, 2.2])\n\n# Plot the mean over trials\nplt.subplot(nTrials, 3, (triali) * 3 + 2)\nplt.plot(EEG['times'][0], np.mean(data, axis=0))\nplt.plot(EEG['times'][0], np.mean(data10hz, axis=0), 'r')\nplt.xlim([-250, 850])\nplt.ylim([-2.2, 2.2])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Time-locked and phase-locked analysis\n\nnTrials = 4\ndata = np.zeros((nTrials, EEG['pnts'][0][0]))\n\n# Wavelet parameters\nwavetime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nn_conv = len(wavetime) + EEG['pnts'][0][0] - 1\nwaveletfft = fft(np.exp(2 * 1j * np.pi * 10 * wavetime) * np.exp(-wavetime ** 2 / (2 * (5 / (2 * np.pi * 10)) ** 2)) / 10, n_conv)\ndata10hz = np.zeros((nTrials, EEG['pnts'][0][0]))\n\nplt.figure(figsize=(15, 10))\n\nfor triali in range(nTrials):\n    # Create single trial ERP as sine wave plus noise\n    data[triali, :] = 0.15 * np.sin(2 * np.pi * 6 * EEG['times'][0] / 1000 + 2 * np.pi * (triali + 1) / nTrials - np.pi) + np.random.randn(EEG['pnts'][0][0]) / 6\n    # Add phase-locked stimulus potential\n    data[triali, 259:360] = data[triali, 259:360] + np.sin(2 * np.pi * 10 * EEG['times'][0][259:360] / 1000) + np.random.randn(101) / 5\n    \n    # Convolve with 10Hz wavelet\n    convolution_result_fft = ifft(waveletfft * fft(data[triali, :], n_conv)) * np.sqrt(5 / (2 * np.pi * 10))\n    convolution_result_fft = convolution_result_fft[int(np.floor(len(wavetime) / 2)) : -int(np.floor(len(wavetime) / 2))]\n    data10hz[triali, :] = np.abs(convolution_result_fft)*2\n    \n    # Plot single trials\n    plt.subplot(nTrials, 3, (triali) * 3 + 1)\n    plt.plot(EEG['times'][0], data[triali, :])\n    plt.plot(EEG['times'][0], data10hz[triali, :], 'r')\n    plt.xlim([-250, 850])\n    plt.ylim([-2.2, 2.2])\n\n# Plot the mean over trials\nplt.subplot(nTrials, 3, (triali) * 3 + 2)\nplt.plot(EEG['times'][0], np.mean(data, axis=0))\nplt.plot(EEG['times'][0], np.mean(data10hz, axis=0), 'r')\nplt.xlim([-250, 850])\nplt.ylim([-2.2, 2.2])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Non-time-locked and phase-locked analysis\n\nnTrials = 4\ndata = np.zeros((nTrials, EEG['pnts'][0][0]))\n\n# Wavelet parameters\nwavetime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nn_conv = len(wavetime) + EEG['pnts'][0][0] - 1\nwaveletfft = fft(np.exp(2 * 1j * np.pi * 10 * wavetime) * np.exp(-wavetime ** 2 / (2 * (5 / (2 * np.pi * 10)) ** 2)) / 10, n_conv)\ndata10hz = np.zeros((nTrials, EEG['pnts'][0][0]))\n\nplt.figure(figsize=(15, 10))\n\nfor triali in range(nTrials):\n    # Create single trial ERP as sine wave plus noise\n    data[triali, :] = 0.15 * np.sin(2 * np.pi * 6 * EEG['times'][0] / 1000 + 2 * np.pi * (triali + 1) / nTrials - np.pi) + np.random.randn(EEG['pnts'][0][0]) / 6\n    # Add non-time-locked, phase-locked stimulus potential\n    eventtime = np.random.permutation(80) + 240\n    eventtime = range(eventtime[0], eventtime[0] + 81)\n    data[triali, eventtime] = data[triali, eventtime] + np.sin(2 * np.pi * 10 * EEG['times'][0][eventtime] / 1000 + 2 * np.pi * (triali + 1) / nTrials - np.pi) + np.random.randn(len(eventtime)) / 5\n    \n    # Convolve with 10Hz wavelet\n    convolution_result_fft = ifft(waveletfft * fft(data[triali, :], n_conv)) * np.sqrt(5 / (2 * np.pi * 10))\n    convolution_result_fft = convolution_result_fft[int(np.floor(len(wavetime) / 2)) : -int(np.floor(len(wavetime) / 2))]\n    data10hz[triali, :] = np.abs(convolution_result_fft)*2\n    \n    # Plot single trials\n    plt.subplot(nTrials, 3, (triali) * 3 + 1)\n    plt.plot(EEG['times'][0], data[triali, :])\n    plt.plot(EEG['times'][0], data10hz[triali, :], 'r')\n    plt.xlim([-250, 850])\n    plt.ylim([-2.2, 2.2])\n\n# Plot the mean over trials\nplt.subplot(nTrials, 3, (triali) * 3 + 2)\nplt.plot(EEG['times'][0], np.mean(data, axis=0))\nplt.plot(EEG['times'][0], np.mean(data10hz, axis=0), 'r')\nplt.xlim([-250, 850])\nplt.ylim([-2.2, 2.2])\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter10.html",
    "href": "chapter10.html",
    "title": "Chapter 10",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 10 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Dot products\n\n# two vectors of random numbers\na = np.random.randn(10, 1)\nb = np.random.randn(10, 1)\n\n# initialize temporary matrix.\npointwise_result = np.zeros(a.shape)\n\nfor i in range(len(a)):\n    pointwise_result[i] = a[i] * b[i]\ndotproduct = np.sum(pointwise_result)\n\n# The above code is useful if you are unfamiliar with \n# how a dot product works. Following is a bit more elegant: \ndotproduct = np.sum(a * b)\n\n# The most elegant way to compute the dot product, \n# however, is to use numpy's dot function: \ndotproduct = np.dot(a.T, b)\n\n\n# Figure 10.2\n\n# impulse function (all zeros; 1 in the middle)\nimpfun = np.zeros(100)\nimpfun[49] = 1\n# the figure in the book actually uses the following line, which creates a\n# wider boxcar function rather than strictly an impulse function.\nimpfun[44:55] = 1\n\nkernel = np.array([1, 0.8, 0.6, 0.4, 0.2])\n\n# numpy's convolution function\nnumpy_conv_result = np.convolve(impfun, kernel, 'same')\n\nplt.figure()\n\n# plot the signal (impulse or boxcar)\nplt.subplot(311)\nplt.plot(impfun)\nplt.ylim([-.1, 1.1])\n\n# plot the kernel\nplt.subplot(312)\nplt.plot(kernel, '.-')\nplt.xlim([0, 100])\nplt.ylim([-.1, 1.1])\n\n# plot the result of convolution\nplt.subplot(313)\nplt.plot(numpy_conv_result)\nplt.xlim([0, 100])\nplt.ylim([-.1, 3.6])\n\nplt.show()\n\n\n\n\n\n# Figure 10.4\n\n# data that we'll use for convolution (must be zero-padded).\ndat4conv = np.concatenate((np.zeros(len(kernel) - 1), impfun, np.zeros(len(kernel) - 1)))\n\n# used for cutting the result of convolution\nhalf_of_kernel_size = int(np.ceil((len(kernel) - 1) / 2))\n\n# initialize convolution output\nconvolution_result = np.zeros(len(impfun) + len(kernel) - 1)\n\n# run convolution (note that kernel is flipped backwards)\nfor ti in range(len(convolution_result) - half_of_kernel_size):\n    convolution_result[ti] = np.sum(dat4conv[ti:ti + len(kernel)] * kernel[::-1])\n\n# cut off edges\nconvolution_result = convolution_result[half_of_kernel_size:-half_of_kernel_size]\n\nplt.figure()\nplt.plot(impfun)\nplt.plot(convolution_result, 'g')\nplt.plot(convolution_result / np.sum(kernel), 'r')\nplt.plot(numpy_conv_result / np.sum(kernel), 'ko')\nplt.xlim([0, 100])\nplt.ylim([-.1, 3.1])\nplt.legend(['original timeseries', 'unscaled convolution', 'manual wavelet convolution', 'numpy conv function'])\nplt.show()"
  },
  {
    "objectID": "chapter34.html",
    "href": "chapter34.html",
    "title": "Chapter 34",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 34 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fftpack import fft, ifft\nfrom scipy.stats import norm, t, rankdata, zscore\nfrom scipy.ndimage import label\n\n\n# Extract TF power (create data that are used for the rest of this chapter)\n\n# Load sample data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Definitions, selections...\nchan2use = 'FCz'\n\nmin_freq = 3\nmax_freq = 30\nnum_frex = 20\n\n# Define wavelet parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nfrex = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\ns = np.logspace(np.log10(3), np.log10(10), num_frex) / (2 * np.pi * frex)\n\n# Define convolution parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2 ** np.ceil(np.log2(n_convolution)))\nhalf_of_wavelet_size = (n_wavelet - 1) // 2\n\n# Note that you don't need the wavelet itself, you need the FFT of the wavelet\nwavelets = np.zeros((num_frex, n_conv_pow2), dtype=complex)\nfor fi in range(num_frex):\n    wavelets[fi, :] = fft(np.sqrt(1 / (s[fi] * np.sqrt(np.pi))) * np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time ** 2 / (2 * (s[fi] ** 2))), n_conv_pow2)\n\n# Get FFT of data\neegfft = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2use, :, :].flatten('F'), n_conv_pow2)\n\n# Initialize\neegpower = np.zeros((num_frex, EEG['pnts'][0, 0], EEG['trials'][0, 0]))  # frequencies X time X trials\neegphase = np.zeros((num_frex, EEG['pnts'][0, 0], EEG['trials'][0, 0]), dtype=complex)  # frequencies X time X trials\n\n# Loop through frequencies and compute synchronization\nfor fi in range(num_frex):\n    # Convolution\n    eegconv = ifft(wavelets[fi, :] * eegfft)\n    eegconv = eegconv[:n_convolution]\n    eegconv = eegconv[half_of_wavelet_size: -half_of_wavelet_size]\n    \n    # Reshape to time X trials\n    eegpower[fi, :, :] = np.abs(np.reshape(eegconv, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n    eegphase[fi, :, :] = np.exp(1j * np.angle(np.reshape(eegconv, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')))\n\n# Remove edge artifacts\ntime_s = np.argmin(np.abs(EEG['times'][0] - (-500)))\ntime_e = np.argmin(np.abs(EEG['times'][0] - 1200))\n\neegpower = eegpower[:, time_s:time_e+1, :]\ntftimes = EEG['times'][0][time_s:time_e+1]\nnTimepoints = len(tftimes)\n\n\n# Figure 34.1\n\nvoxel_pval = 0.01\ncluster_pval = 0.05\n\n# Note: try to use 1000 or more permutations for real data\nn_permutes = 1000\n\nbaseidx = [np.argmin(np.abs(tftimes - t)) for t in [-500, -100]]\n\n# Compute actual t-test of difference\nrealbaselines = np.mean(eegpower[:, baseidx[0]:baseidx[1]+1, :], axis=1)\nrealmean = 10 * np.log10(np.mean(eegpower, axis=2) / np.mean(realbaselines, axis=1)[:, None])  # Normalize power\n\n# Initialize null hypothesis matrices\npermuted_maxvals = np.zeros((n_permutes, 2, num_frex))\npermuted_vals = np.zeros((n_permutes, num_frex, len(tftimes)))\nmax_clust_info = np.zeros(n_permutes)\n\n# Correcting the cutpoint calculation\nfor permi in range(n_permutes):\n    cutpoint = np.random.choice(range(2, nTimepoints - np.diff(baseidx)[0] - 1))\n    permuted_vals[permi, :, :] = 10 * np.log10(np.mean(np.roll(eegpower, cutpoint, axis=1), axis=2) / np.mean(realbaselines, axis=1)[:, None])\n\nzmap = (realmean - np.mean(permuted_vals, axis=0)) / np.std(permuted_vals, axis=0)\nthreshmean = realmean.copy()\nthreshmean[np.abs(zmap) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n# Plotting the figures\nfig, axs = plt.subplots(2, 2, figsize=(10, 8))\n\n# Power map\nax = axs[0, 0]\ncf = ax.contourf(tftimes, frex, realmean, 40, cmap='viridis', levels=256, vmin=-3, vmax=3)\nax.set_title('Power map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Unthresholded Z map\nax = axs[0, 1]\ncf = ax.contourf(tftimes, frex, zmap, 40, cmap='viridis', levels=256, vmin=-3, vmax=3)\nax.set_title('Unthresholded Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Uncorrected power map\nax = axs[1, 0]\ncf = ax.contourf(tftimes, frex, threshmean, 40, cmap='viridis', levels=256, vmin=-3, vmax=3)\nax.set_title('Uncorrected power map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nfor permi in range(n_permutes):\n\n    # Cluster correction\n    fakecorrsz = (permuted_vals[permi, :, :] - np.mean(permuted_vals, axis=0)) / np.std(permuted_vals, axis=0)\n    fakecorrsz[np.abs(fakecorrsz) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n    # Get number of elements in largest supra-threshold cluster\n    labeled_array, num_features = label(fakecorrsz)\n    max_clust_info[permi] = np.max([0] + [np.sum(labeled_array == i) for i in range(1, num_features + 1)])\n\n# Apply cluster-level corrected threshold\nzmapthresh = zmap.copy()\n# Uncorrected pixel-level threshold\nzmapthresh[np.abs(zmapthresh) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n# Find islands and remove those smaller than cluster size threshold\nlabeled_array, num_features = label(zmapthresh)\ncluster_sizes = np.array([np.sum(labeled_array == i) for i in range(1, num_features + 1)])\nclust_threshold = np.percentile(max_clust_info, 100 - cluster_pval * 100)\n\n# Identify clusters to remove\nwhichclusters2remove = np.where(cluster_sizes &lt; clust_threshold)[0] + 1  # +1 for 1-based indexing\n\n# Remove clusters\nfor clust in whichclusters2remove:\n    zmapthresh[labeled_array == clust] = 0\n\n# Plotting the cluster-corrected Z map\nax = axs[1, 1]\ncf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256, vmin=-3, vmax=3)\nax.set_title('Cluster-corrected Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.3\n\nvoxel_pval = 0.05\nmcc_voxel_pval = 0.05  # mcc = multiple comparisons correction\nmcc_cluster_pval = 0.05\n\n# Note: try to use 1000 or more permutations for real data\nn_permutes = 1000\n\nreal_condition_mapping = np.concatenate((-np.ones(int(np.floor(EEG['trials'][0, 0] / 2))), np.ones(int(np.ceil(EEG['trials'][0, 0] / 2)))))\n\n# Compute actual t-test of difference (using unequal N and std)\ntnum = np.mean(eegpower[:, :, real_condition_mapping == -1], axis=2) - np.mean(eegpower[:, :, real_condition_mapping == 1], axis=2)\ntdenom = np.sqrt((np.std(eegpower[:, :, real_condition_mapping == -1], axis=2, ddof=1) ** 2) / np.sum(real_condition_mapping == -1) +\n                 (np.std(eegpower[:, :, real_condition_mapping == 1], axis=2, ddof=1) ** 2) / np.sum(real_condition_mapping == 1))\nreal_t = tnum / tdenom\n\n# Initialize null hypothesis matrices\npermuted_tvals = np.zeros((n_permutes, num_frex, nTimepoints))\nmax_pixel_pvals = np.zeros((n_permutes, 2))\nmax_clust_info = np.zeros(n_permutes)\n\n# Generate pixel-specific null hypothesis parameter distributions\nfor permi in range(n_permutes):\n    fake_condition_mapping = np.sign(np.random.randn(EEG['trials'][0, 0]))\n    \n    # Compute t-map of null hypothesis\n    tnum = np.mean(eegpower[:, :, fake_condition_mapping == -1], axis=2) - np.mean(eegpower[:, :, fake_condition_mapping == 1], axis=2)\n    tdenom = np.sqrt((np.std(eegpower[:, :, fake_condition_mapping == -1], axis=2, ddof=1) ** 2) / np.sum(fake_condition_mapping == -1) +\n                     (np.std(eegpower[:, :, fake_condition_mapping == 1], axis=2, ddof=1) ** 2) / np.sum(fake_condition_mapping == 1))\n    tmap = tnum / tdenom\n    \n    # Save all permuted values\n    permuted_tvals[permi, :, :] = tmap\n    \n    # Save maximum pixel values\n    max_pixel_pvals[permi, :] = [np.min(tmap), np.max(tmap)]\n    \n    # For cluster correction, apply uncorrected threshold and get maximum cluster sizes\n    tmap[np.abs(tmap) &lt; t.ppf(1 - voxel_pval, EEG['trials'][0, 0] - 1)] = 0\n    \n    # Get number of elements in largest supra-threshold cluster\n    labeled_array, num_features = label(tmap)\n    max_clust_info[permi] = np.max([0] + [np.sum(labeled_array == i) for i in range(1, num_features + 1)])\n\n# Now compute Z-map\nzmap = (real_t - np.mean(permuted_tvals, axis=0)) / np.std(permuted_tvals, axis=0)\n\nfig, axs = plt.subplots(2, 2, figsize=(10, 8))\n\n# Unthresholded Z map\nax = axs[0, 0]\ncf = ax.contourf(tftimes, frex, zmap, 40, cmap='viridis', levels=256)\nax.set_title('Unthresholded Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nzmapthresh_uncorr = zmap.copy()\nt_thresh_uncorr = norm.ppf(1 - voxel_pval)\nzmapthresh_uncorr[np.abs(zmapthresh_uncorr) &lt; t_thresh_uncorr] = 0\n\n# Uncorrected thresholded Z map\nax = axs[0, 1]\ncf = ax.contourf(tftimes, frex, zmap, 40, cmap='viridis', levels=256)\nax.contour(tftimes, frex, zmapthresh_uncorr, levels=[-t_thresh_uncorr, t_thresh_uncorr], colors='k', linewidths=1)\nax.set_title('Unthresholded Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Apply pixel-level corrected threshold\nlower_threshold = np.percentile(max_pixel_pvals[:, 0], mcc_voxel_pval * 100 / 2)\nupper_threshold = np.percentile(max_pixel_pvals[:, 1], 100 - mcc_voxel_pval * 100 / 2)\n\nzmapthresh = zmap.copy()\nzmapthresh[(zmap &gt; lower_threshold) & (zmap &lt; upper_threshold)] = 0\n\n# Pixel-corrected Z map\nax = axs[1, 0]\ncf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256)\nax.set_title('Pixel-corrected Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Apply cluster-level corrected threshold\nzmapthresh = zmap.copy()\nzmapthresh[np.abs(zmapthresh) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n# Find islands and remove those smaller than cluster size threshold\nlabeled_array, num_features = label(zmapthresh)\ncluster_sizes = np.array([np.sum(labeled_array == i) for i in range(1, num_features + 1)])\nclust_threshold = np.percentile(max_clust_info, 100 - mcc_cluster_pval * 100)\n\n# Identify clusters to remove\nwhichclusters2remove = np.where(cluster_sizes &lt; clust_threshold)[0] + 1  # +1 for 1-based indexing\n\n# Remove clusters\nfor clust in whichclusters2remove:\n    zmapthresh[labeled_array == clust] = 0\n\n# Cluster-corrected Z map\nax = axs[1, 1]\ncf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256)\nax.set_title('Cluster-corrected Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.4\n\nvoxel_pval = 0.01\nmcc_voxel_pval = 0.05  # mcc = multiple comparisons correction\nmcc_cluster_pval = 0.05\n\n# Note: try to use 1000 or more permutations for real data\nn_permutes = 1000\n\n# Define covariates (RT and trial number)\nrts = np.zeros(EEG['trials'][0][0])\nfor ei in range(EEG['trials'][0][0]):\n    # In this task, the button press always followed the stimulus at\n    # time=0. Thus, finding the RT involves finding the latency of the\n    # event that occurs after the time=0 event.\n    # If you follow a procedure like this in your data, you may need to\n    # include special exceptions, e.g., if there was no response or if\n    # a non-response marker could have occurred between stimulus and response.\n    time0event = np.where(np.array(EEG['epoch'][0][ei]['eventlatency'][0]) == 0)[0][0]\n    rts[ei] = EEG['epoch'][0][ei]['eventlatency'][0][time0event + 1]\n\n# Rank-transform RTs\nrtsrank = rankdata(rts)\n\n# Rank-transform power data (must be transformed)\neegpowerreshaped = np.reshape(eegpower, (num_frex * nTimepoints, EEG['trials'][0][0]), 'F').T\neegpowerrank = rankdata(eegpowerreshaped, axis=0).T\n\n# Perform the matrix regression\nrealcorrs = np.linalg.lstsq((rtsrank.T @ rtsrank)[np.newaxis, np.newaxis], (rtsrank.T @ eegpowerrank.T)[np.newaxis, :], rcond=None)[0]\n# Reshape the result to match the dimensions of frequency by time points\nrealcorrs = np.reshape(realcorrs, (num_frex, nTimepoints), 'F')\n\n# Initialize null hypothesis matrices\npermuted_corrs = np.zeros((n_permutes, num_frex, nTimepoints))\nmax_pixel_pvals = np.zeros((n_permutes, 2))\nmax_clust_info = np.zeros(n_permutes)\n\n# Generate pixel-specific null hypothesis parameter distributions\nfor permi in range(n_permutes):\n    fake_rt_mapping = rtsrank[np.random.permutation(EEG['trials'][0][0])]\n\n    # Compute t-map of null hypothesis\n    fakecorrs = np.linalg.lstsq((fake_rt_mapping.T @ fake_rt_mapping)[np.newaxis, np.newaxis], (fake_rt_mapping.T @ eegpowerrank.T)[np.newaxis, :], rcond=None)[0]\n\n    # Reshape the result to match the dimensions of frequency by time pointsq\n    fakecorrs = np.reshape(fakecorrs, (num_frex, nTimepoints), 'F')\n\n    # Save all permuted values\n    permuted_corrs[permi, :, :] = fakecorrs\n\n    # Save maximum pixel values\n    max_pixel_pvals[permi, :] = [np.min(fakecorrs), np.max(fakecorrs)]\n\n# this time, the cluster correction will be done on the permuted data, thus\n# making no assumptions about parameters for p-values\nfor permi in range(n_permutes):\n    \n    # Indices of permutations to include in this iteration\n    perms2use4distribution = np.ones(n_permutes, dtype=bool)\n    perms2use4distribution[permi] = False\n\n    # For cluster correction, apply uncorrected threshold and get maximum cluster sizes\n    fakecorrsz = (permuted_corrs[permi, :, :] - np.mean(permuted_corrs[perms2use4distribution, :, :], axis=0)) / np.std(permuted_corrs[perms2use4distribution, :, :], axis=0)\n    fakecorrsz[np.abs(fakecorrsz) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n    # Get number of elements in largest supra-threshold cluster\n    labeled_array, num_features = label(fakecorrsz)\n    max_clust_info[permi] = np.max([0] + [np.sum(labeled_array == i) for i in range(1, num_features + 1)])\n\n# Now compute Z-map\nzmap = (realcorrs - np.mean(permuted_corrs, axis=0)) / np.std(permuted_corrs, axis=0)\n\nfig, axs = plt.subplots(2, 2, figsize=(10, 8))\n\n# Unthresholded Z map\nax = axs[0, 0]\ncf = ax.contourf(tftimes, frex, zmap, 40, cmap='viridis', levels=256)\nax.set_title('Unthresholded Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nzmapthresh_uncorr = zmap.copy()\nz_thresh_uncorr = norm.ppf(1 - voxel_pval)\nzmapthresh_uncorr[np.abs(zmapthresh_uncorr) &lt; z_thresh_uncorr] = 0\n\n# Uncorrected thresholded Z map\nax = axs[0, 1]\ncf = ax.contourf(tftimes, frex, zmap, 40, cmap='viridis', levels=256)\nax.contour(tftimes, frex, zmapthresh_uncorr, levels=[-z_thresh_uncorr, z_thresh_uncorr], colors='k', linewidths=1)\nax.set_title('Uncorrected thresholded Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Apply pixel-level corrected threshold\nlower_threshold = np.percentile(max_pixel_pvals[:, 0], mcc_voxel_pval * 100 / 2)\nupper_threshold = np.percentile(max_pixel_pvals[:, 1], 100 - mcc_voxel_pval * 100 / 2)\n\nzmapthresh = zmap.copy()\nzmapthresh[(realcorrs &gt; lower_threshold) & (realcorrs &lt; upper_threshold)] = 0\n\n# Pixel-corrected Z map\nax = axs[1, 0]\ncf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256)\nax.set_title('Pixel-corrected Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Apply cluster-level corrected threshold\nzmapthresh = zmap.copy()\nzmapthresh[np.abs(zmapthresh) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n# Find islands and remove those smaller than cluster size threshold\nlabeled_array, num_features = label(zmapthresh)\ncluster_sizes = np.array([np.sum(labeled_array == i) for i in range(1, num_features + 1)])\nclust_threshold = np.percentile(max_clust_info, 100 - mcc_cluster_pval * 100)\n\n# Identify clusters to remove\nwhichclusters2remove = np.where(cluster_sizes &lt; clust_threshold)[0] + 1  # +1 for 1-based indexing\n\n# Remove clusters\nfor clust in whichclusters2remove:\n    zmapthresh[labeled_array == clust] = 0\n\n# Cluster-corrected Z map\nax = axs[1, 1]\ncf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256)\nax.set_title('Cluster-corrected Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.5\n\nchan2use = 'O1'\ntime2use = [np.argmin(np.abs(EEG['times'][0] - t)) for t in [0, 250]]\nfreq2use = np.argmin(np.abs(frex - 10))\n\neegfft = fft(EEG['data'][EEG['chanlocs'][0]['labels']==chan2use, :, :].flatten('F'), n_conv_pow2)\neegconv = ifft(wavelets[freq2use, :] * eegfft)\neegconv = eegconv[:n_convolution]\neegconv = eegconv[half_of_wavelet_size: -half_of_wavelet_size]\n\n# Reshape to time X trials\ntemp = np.abs(np.reshape(eegconv, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\no1power = zscore(np.mean(temp[time2use[0]:time2use[1]+1, :], axis=0))\n\n# Define covariates (RT and trial number)\nX = np.vstack((zscore(rtsrank), o1power))\neegpowerrank = rankdata(eegpowerreshaped, axis=0).T\n\n# Plotting the covariate matrix and rank-transformed power data\nfig, axs = plt.subplots(2, 1, figsize=(10, 8))\n\n# Covariate matrix\nax = axs[0]\ncax = ax.imshow(X, aspect='auto', cmap='viridis')\n\n# Rank-transformed power data\nax = axs[1]\ncax = ax.imshow(eegpowerrank, aspect='auto', cmap='viridis', interpolation='none')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.6\n\nvoxel_pval = 0.01\nmcc_cluster_pval = 0.05\n\n# Note: try to use 1000 or more permutations for real data\nn_permutes = 1000\n\n# Perform the regression using np.linalg.lstsq\nrealbeta = np.linalg.lstsq(X @ X.T, X @ eegpowerrank.T, rcond=None)[0]\nrealbeta = np.reshape(realbeta, (2, num_frex, nTimepoints), order='F')\n\n# Initialize null hypothesis matrices\npermuted_bvals = np.zeros((n_permutes, 2, num_frex, nTimepoints))\nmax_clust_info = np.zeros((n_permutes, 2))\n\n# Generate pixel-specific null hypothesis parameter distributions\nfor permi in range(n_permutes):\n    # Randomly shuffle trial order\n    fakeX = X[:, np.random.permutation(EEG['trials'][0][0])]\n    \n    # Compute beta-map of null hypothesis\n    fakebeta = np.linalg.lstsq(fakeX @ fakeX.T, fakeX @ eegpowerrank.T, rcond=None)[0]\n    fakebeta = np.reshape(fakebeta, (2, num_frex, nTimepoints), order='F')\n    \n    # Save all permuted values\n    permuted_bvals[permi, :, :, :] = fakebeta\n\n# Cluster correction will be done on the permuted data\nfor permi in range(n_permutes):\n    for testi in range(2):\n        # Apply uncorrected threshold and get maximum cluster sizes\n        fakecorrsz = (permuted_bvals[permi, testi, :, :] - np.mean(permuted_bvals[:, testi, :, :], axis=0)) / np.std(permuted_bvals[:, testi, :, :], axis=0)\n        fakecorrsz[np.abs(fakecorrsz) &lt; norm.ppf(1 - voxel_pval)] = 0\n        \n        # Get number of elements in largest supra-threshold cluster\n        labeled_array, num_features = label(fakecorrsz)\n        max_clust_info[permi, testi] = np.max([0] + [np.sum(labeled_array == i) for i in range(1, num_features + 1)])\n\n# Plotting the figures for Figure 34.6\nfig, axs = plt.subplots(2, 3, figsize=(15, 10))\n\nfor testi in range(2):\n    \n    # Now compute Z-map\n    zmap = (realbeta[testi, :, :] - np.mean(permuted_bvals[:, testi, :, :], axis=0)) / np.std(permuted_bvals[:, testi, :, :], axis=0)\n\n    # Unthresholded Z map\n    ax = axs[testi, 0]\n    cf = ax.contourf(tftimes, frex, zmap, 40, cmap='viridis', levels=256)\n    ax.set_title(f'Unthresholded Z map')\n    ax.set_xlabel('Time (ms)')\n    ax.set_ylabel('Frequency (Hz)')\n    \n    # Apply uncorrected threshold\n    zmapthresh = zmap.copy()\n    zmapthresh[np.abs(zmapthresh) &lt; norm.ppf(1 - voxel_pval)] = 0\n    \n    # Uncorrected thresholded Z map\n    ax = axs[testi, 1]\n    cf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256)\n    ax.set_title(f'Uncorrected thresholded Z map')\n    ax.set_xlabel('Time (ms)')\n    ax.set_ylabel('Frequency (Hz)')\n    \n    # Apply cluster-level corrected threshold\n    clust_threshold = np.percentile(max_clust_info[:, testi], 100 - mcc_cluster_pval * 100)\n    \n    # Find islands and remove those smaller than cluster size threshold\n    labeled_array, num_features = label(zmapthresh)\n    cluster_sizes = np.array([np.sum(labeled_array == i) for i in range(1, num_features + 1)])\n    \n    # Identify clusters to remove\n    whichclusters2remove = np.where(cluster_sizes &lt; clust_threshold)[0] + 1  # +1 for 1-based indexing\n    \n    # Remove clusters\n    for clust in whichclusters2remove:\n        zmapthresh[labeled_array == clust] = 0\n    \n    # Cluster-corrected Z map\n    ax = axs[testi, 2]\n    cf = ax.contourf(tftimes, frex, zmapthresh, 40, cmap='viridis', levels=256)\n    ax.set_title(f'Cluster-corrected Z map')\n    ax.set_xlabel('Time (ms)')\n    ax.set_ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.7\n\n# Generate random data\na = np.random.rand(10000, 1)\nb = np.random.rand(10000, 1)\n\n# Create figure and axes\nplt.figure(figsize=(12, 8))\n\n# Histogram of 'a'\nax = plt.subplot(221)\nax.hist(a, bins=50, color='k', alpha=0.75)\nax.set_xlim([-.05, 1.05])\n\n# Histogram of 'b'\nax = plt.subplot(222)\nax.hist(b, bins=50, color='k', alpha=0.75)\nax.set_xlim([-.05, 1.05])\n\n# Histogram of the differences (using Fisher's Z transformation)\nax = plt.subplot(212)\nax.hist(np.arctanh(a - b), bins=50, color='k', alpha=0.75)\nax.set_xlim([-2, 2])\nax.set_title('ITPC differences')\nax.set_xlabel('Difference value')\nax.set_ylabel('Count')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 34.8\n\n# The code to produce this figure is presented in chapter19.m, between the\n# cells for figures 19.6 and 19.7. To generate figure 34.8, you will need to run\n# the code for figures 19.2-6.\n\n\n# Figure 34.9\n\nvoxel_pval = 0.01\ncluster_pval = 0.05\n\n# Note: try to use 1000 or more permutations for real data\nn_permutes = 1000\n\n# Compute actual ITPC\nrealitpc = np.abs(np.mean(eegphase, axis=2))\n\n# Initialize null hypothesis matrices\npermuted_maxvals = np.zeros((n_permutes, 2, num_frex))\npermuted_vals = np.zeros((n_permutes, num_frex, EEG['pnts'][0][0]))\nmax_clust_info = np.zeros(n_permutes)\neegtemp = np.zeros(eegphase.shape, dtype=complex)\n\nfor permi in range(n_permutes):\n    for triali in range(EEG['trials'][0][0]):\n        cutpoint = np.random.choice(range(2, nTimepoints - 1))\n        # Permute phase values\n        eegtemp[:, :, triali] = np.roll(eegphase[:, :, triali], cutpoint, axis=1)\n    permuted_vals[permi, :, :] = np.abs(np.mean(eegtemp, axis=2))\n\nzmap = (realitpc - np.mean(permuted_vals, axis=0)) / np.std(permuted_vals, axis=0)\nthreshmean = realitpc.copy()\nthreshmean[np.abs(zmap) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n# Plotting the figures for Figure 34.9\nfig, axs = plt.subplots(2, 2, figsize=(10, 8))\n\n# Power map\nax = axs[0, 0]\ncf = ax.contourf(EEG['times'][0], frex, realitpc, 40, cmap='viridis', levels=256)\nax.set_xlim([-200, 1000])\nax.set_title('Power map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Unthresholded Z map\nax = axs[0, 1]\ncf = ax.contourf(EEG['times'][0], frex, zmap, 40, cmap='viridis', levels=256)\nax.set_xlim([-200, 1000])\nax.set_title('Unthresholded Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# Uncorrected power map\nax = axs[1, 0]\ncf = ax.contourf(EEG['times'][0], frex, threshmean, 40, cmap='viridis', levels=256)\nax.set_xlim([-200, 1000])\nax.set_title('Uncorrected power map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\n# this time, the cluster correction will be done on the permuted data, thus\n# making no assumptions about parameters for p-values\nfor permi in range(n_permutes):\n\n    # Cluster correction\n    fakecorrsz = (permuted_vals[permi, :, :] - np.mean(permuted_vals, axis=0)) / np.std(permuted_vals, axis=0)\n    fakecorrsz[np.abs(fakecorrsz) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n    # Get number of elements in largest supra-threshold cluster\n    labeled_array, num_features = label(fakecorrsz)\n    max_clust_info[permi] = np.max([0] + [np.sum(labeled_array == i) for i in range(1, num_features + 1)])\n\n# Cluster-corrected Z map\n# Apply cluster-level corrected threshold\nzmapthresh = realitpc.copy()\nzmapthresh[np.abs(zmap) &lt; norm.ppf(1 - voxel_pval)] = 0\n\n# Find islands and remove those smaller than cluster size threshold\nlabeled_array, num_features = label(zmapthresh)\ncluster_sizes = np.array([np.sum(labeled_array == i) for i in range(1, num_features + 1)])\nclust_threshold = np.percentile(max_clust_info, 100 - cluster_pval * 100)\n\n# Identify clusters to remove\nwhichclusters2remove = np.where(cluster_sizes &lt; clust_threshold)[0] + 1  # +1 for 1-based indexing\n\n# Remove clusters\nfor clust in whichclusters2remove:\n    zmapthresh[labeled_array == clust] = 0\n\nax = axs[1, 1]\ncf = ax.contourf(EEG['times'][0], frex, zmapthresh, 40, cmap='viridis', levels=256)\nax.set_xlim([-200, 1000])\nax.set_title('Cluster-corrected Z map')\nax.set_xlabel('Time (ms)')\nax.set_ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 33.5\n\n# The code for figures 33.5/6 are presented here and in the next cell. You\n# will need first to run the code for figure 34.3 to run this code.\n\n# Compute actual t-test of difference (using unequal N and std)\ntnum = np.mean(eegpower[3, 399, real_condition_mapping == -1]) - np.mean(eegpower[3, 399, real_condition_mapping == 1])\ntdenom = np.sqrt((np.std(eegpower[3, 399, real_condition_mapping == -1], ddof=1) ** 2) / np.sum(real_condition_mapping == -1) +\n                 (np.std(eegpower[3, 399, real_condition_mapping == 1], ddof=1) ** 2) / np.sum(real_condition_mapping == 1))\nreal_t = tnum / tdenom\n\n# Set up the range of permutations to test\nn_permutes_range = np.round(np.linspace(100, 3000, 200)).astype(int)\nzvals = np.zeros(len(n_permutes_range))\n\n# Perform the permutation test for different numbers of permutations\nfor idx, n_permutes in enumerate(n_permutes_range):\n    permuted_tvals = np.zeros(n_permutes)\n    \n    # Generate null hypothesis parameter distributions\n    for permi in range(n_permutes):\n        fake_condition_mapping = np.sign(np.random.randn(EEG['trials'][0][0]))\n        tnum = np.mean(eegpower[3, 399, fake_condition_mapping == -1]) - np.mean(eegpower[3, 399, fake_condition_mapping == 1])\n        tdenom = np.sqrt((np.std(eegpower[3, 399, fake_condition_mapping == -1], ddof=1) ** 2) / np.sum(fake_condition_mapping == -1) +\n                         (np.std(eegpower[3, 399, fake_condition_mapping == 1], ddof=1) ** 2) / np.sum(fake_condition_mapping == 1))\n        permuted_tvals[permi] = tnum / tdenom\n    \n    zvals[idx] = (real_t - np.mean(permuted_tvals)) / np.std(permuted_tvals)\n\n# Plot the stability of Z-value as a function of the number of permutations\nfig, axs = plt.subplots(2, 1, figsize=(8, 8))\n\n# Plot Z-values\nax = axs[0]\nax.plot(n_permutes_range, zvals, marker='o', linestyle='-')\nax.set_xlabel('Number of permutations')\nax.set_ylabel('Z-value')\nax.set_title('Stability of Z-value')\n\n# Histogram of Z-values\nax = axs[1]\nax.hist(zvals, bins=30, color='k', alpha=0.75)\nax.set_xlabel('Z-value')\nax.set_ylabel('Count')\nax.set_title('Histogram of Z-values at different runs of permutation test')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\ntnum / tdenom\n\narray([[ 0.6900473 ,  0.69906177,  0.70821306, ...,  1.51976739,\n         1.50579183,  1.48970955],\n       [ 1.13221693,  1.14380985,  1.1557384 , ...,  1.39210632,\n         1.38067992,  1.36761409],\n       [ 1.4598731 ,  1.47179132,  1.48407068, ...,  1.09183971,\n         1.10015209,  1.10712079],\n       ...,\n       [-1.05518666, -1.03844323, -1.00849262, ...,  1.99556023,\n         1.88482516,  1.78384207],\n       [-1.61870042, -1.59936762, -1.56654329, ...,  1.79811917,\n         1.66377941,  1.53064692],\n       [-1.43522339, -1.44002911, -1.43904482, ...,  0.08468227,\n         0.09266911,  0.08359325]])\n\n\n\nreal_t\n\narray([[ 1.92409318,  1.93799449,  1.95104155, ..., -0.88392747,\n        -0.88830475, -0.89335801],\n       [ 2.08568485,  2.09873798,  2.11051953, ..., -0.7674469 ,\n        -0.75174094, -0.73673116],\n       [ 1.87780796,  1.87858681,  1.87730406, ..., -0.29878025,\n        -0.28154403, -0.26507296],\n       ...,\n       [-1.16226796, -1.09787529, -1.03706577, ..., -1.98438195,\n        -2.05500952, -2.11943243],\n       [-1.02458395, -0.91130896, -0.81098154, ..., -1.61005073,\n        -1.60534137, -1.59837314],\n       [-0.05420381, -0.04360291, -0.04128698, ..., -1.76290619,\n        -1.82481761, -1.88206451]])\n\n\n\n# Figure 33.6\n\n# Compute actual t-test of difference (using unequal N and std)\ntnum = np.mean(eegpower[:, :, real_condition_mapping == -1], axis=2) - np.mean(eegpower[:, :, real_condition_mapping == 1], axis=2)\ntdenom = np.sqrt((np.std(eegpower[:, :, real_condition_mapping == -1], axis=2, ddof=1) ** 2) / np.sum(real_condition_mapping == -1) +\n                 (np.std(eegpower[:, :, real_condition_mapping == 1], axis=2, ddof=1) ** 2) / np.sum(real_condition_mapping == 1))\nreal_t = tnum / tdenom\n\n# Set up the range of permutations to test\nn_permutes_range = np.round(np.linspace(100, 3000, 200)).astype(int)\nzvals = np.zeros((len(n_permutes_range), tnum.shape[0], tnum.shape[1]))\n\n# Perform the permutation test for different numbers of permutations\nfor grandpermi, n_permutes in enumerate(n_permutes_range):\n    permuted_tvals = np.zeros((n_permutes, tnum.shape[0], tnum.shape[1]))\n    \n    # Generate null hypothesis parameter distributions\n    for permi in range(n_permutes):\n        fake_condition_mapping = np.sign(np.random.randn(EEG['trials'][0][0]))\n        tnum = np.mean(eegpower[:, :, fake_condition_mapping == -1], axis=2) - np.mean(eegpower[:, :, fake_condition_mapping == 1], axis=2)\n        tdenom = np.sqrt((np.std(eegpower[:, :, fake_condition_mapping == -1], axis=2, ddof=1) ** 2) / np.sum(fake_condition_mapping == -1) +\n                         (np.std(eegpower[:, :, fake_condition_mapping == 1], axis=2, ddof=1) ** 2) / np.sum(fake_condition_mapping == 1))\n        permuted_tvals[permi, :, :] = tnum / tdenom\n    \n    zvals[grandpermi, :, :] = (real_t - np.mean(permuted_tvals, axis=0)) / np.std(permuted_tvals, axis=0)\n\n# Plot the stability of Z-value as a function of the number of permutations for the selected time-frequency point\nfig, axs = plt.subplots(2, 1, figsize=(8, 8))\n\n# Plot Z-values for the selected time-frequency point\nax = axs[0]\nax.plot(n_permutes_range, zvals[:, 3, 399], linestyle='-')\n\n# Histogram of Z-values for the selected time-frequency point\nax = axs[1]\nax.hist(zvals[:, 3, 399], bins=30, alpha=0.75)\n\nplt.tight_layout()\nplt.show()\n\n# Plot the average and standard deviation of Z-statistics across all time-frequency points\nzvals_all = zvals.reshape(len(n_permutes_range), num_frex * nTimepoints)\nfig, ax = plt.subplots(figsize=(8, 6))\nax.plot(np.mean(zvals_all, axis=0), np.std(zvals_all, axis=0), 'o')\nax.set_xlim([-3.5, 3.5])\nax.set_ylim([0, 0.12])\nax.set_xlabel('Average Z-statistic')\nax.set_ylabel('Standard deviation of Z-statistics')\nplt.show()\n\nplt.figure()\n\nz0 = np.argmin(np.abs(np.mean(zvals_all, axis=0)))\nx0, y0 = np.unravel_index(z0, tnum.shape)\nyy, xx = np.histogram(zvals[:, x0, y0], bins=30)\nwidth = np.diff(xx)  # Calculate the width of each bin\ncenter = (xx[:-1] + xx[1:]) / 2  # Calculate the center of each bin\nh = plt.bar(center, yy, width=width, align='center')\n\nz2 = np.argmin(np.abs(np.mean(zvals_all, axis=0)-2))\nx2, y2 = np.unravel_index(z2, tnum.shape)\nyy, xx = np.histogram(zvals[:, x2, y2], bins=30)\nwidth = np.diff(xx)  # Calculate the width of each bin\ncenter = (xx[:-1] + xx[1:]) / 2  # Calculate the center of each bin\nh = plt.bar(center, yy, width=width, align='center')\n\nz3 = np.argmin(np.abs(np.mean(zvals_all, axis=0)+3))\nx3, y3 = np.unravel_index(z3, tnum.shape)\nyy, xx = np.histogram(zvals[:, x3, y3], bins=30)\nwidth = np.diff(xx)  # Calculate the width of each bin\ncenter = (xx[:-1] + xx[1:]) / 2  # Calculate the center of each bin\nh = plt.bar(center, yy, width=width, align='center')\n\nplt.xlim([-3.5, 3.5])\nplt.xlabel('Z-value')\nplt.ylabel('Count of possible z-values')\n\nplt.show()"
  },
  {
    "objectID": "chapter16.html",
    "href": "chapter16.html",
    "title": "Chapter 16",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 16 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import detrend\nfrom scipy.signal.windows import dpss\nfrom scipy.fft import fft\nfrom scipy.io import loadmat\n\n\n# Figure 16.1\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define parameters\nchannel2plot = 'O1'\ntimewin = 400  # in ms\n\n# Calculate the number of indices that correspond to the time window\ntimewinidx = round(timewin / (1000 / EEG['srate'][0][0]))\ntapers = dpss(timewinidx, 5, 5)\n\n# Extract a bit of EEG data\nd = detrend(np.squeeze(EEG['data'][EEG['chanlocs'][0]['labels']==channel2plot, 199:199 + timewinidx, 9]))\n\n# Plot EEG data snippet\nplt.figure(figsize=(10, 10))\nplt.subplot(5, 2, 1)\nplt.plot(d)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.axis('off')\n\n# Plot tapers\nfor i in range(5):\n    plt.subplot(5, 2, (2 * (i)) + 2)\n    plt.plot(tapers[i, :])\n    plt.gca().autoscale(enable=True, axis='both', tight=True)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Plot taper.*data\nplt.figure(figsize=(10, 10))\nfor i in range(5):\n    plt.subplot(5, 2, (2 * (i)) + 1)\n    plt.plot(tapers[i, :] * d)\n    plt.gca().autoscale(enable=True, axis='both', tight=True)\n    plt.axis('off')\n\n# Plot fft of taper.*data\nf = np.zeros((5, timewinidx)) * 1j\nfor i in range(5):\n    plt.subplot(5, 2, (2 * (i)) + 2)\n    f[i, :] = fft(tapers[i, :] * d)\n    plt.plot(np.abs(f[i, :timewinidx // 2]) ** 2)\n    plt.gca().autoscale(enable=True, axis='both', tight=True)\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(10, 10))\nplt.subplot(5, 2, 2)\nplt.plot(np.mean(np.abs(f[:, :timewinidx // 2]) ** 2, axis=0))\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.axis('off')\n\nplt.subplot(5, 2, 3)\nhann = 0.5 * (1 - np.cos(2 * np.pi * np.arange(1, timewinidx + 1) / (timewinidx - 1)))\nplt.plot(hann)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.axis('off')\n\nplt.subplot(5, 2, 5)\nplt.plot(hann * d)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.axis('off')\n\nplt.subplot(5, 2, 6)\nff = fft(hann * d)\nplt.plot(np.abs(ff[:timewinidx // 2]) ** 2)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# Figure 16.2\n\n# Define parameters\nchannel2plot = 'P7'\nfrequency2plot = 15  # in Hz\ntimepoint2plot = 200  # ms\n\nnw_product = 3  # determines the frequency smoothing, given a specified time window\ntimes2save = np.arange(-300, 1050, 50)\nbaseline_range = [-200, 0]\ntimewin = 400  # in ms\n\n# Convert time points to indices\ntimes2saveidx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save])\ntimewinidx = round(timewin / (1000 / EEG['srate'][0][0]))\n\n# Find baseline time points\nbaseidx = [np.argmin(np.abs(times2save - br)) for br in baseline_range]\n\n# Define tapers\ntapers = dpss(timewinidx, nw_product, 6)\n# Define frequencies for FFT\nf = np.linspace(0, EEG['srate'][0][0] / 2, int(np.floor(timewinidx / 2)) + 1)\n\n# Find logical channel index\nchanidx = EEG['chanlocs'][0]['labels']==channel2plot\n\n# Initialize output matrix\nmultitaper_tf = np.zeros((int(np.floor(timewinidx / 2) + 1), len(times2save)))\n\n# Loop through time bins\nfor ti, idx in enumerate(times2saveidx):\n    # Initialize power vector (over tapers)\n    taperpow = np.zeros(int(np.floor(timewinidx / 2) + 1)) * 1j\n    \n    # Loop through tapers\n    for tapi in range(tapers.shape[0] - 1):\n        # Window and taper data, and get power spectrum\n        data = np.squeeze(EEG['data'][chanidx, idx - int(np.floor(timewinidx / 2)) + 1:idx + int(np.ceil(timewinidx / 2)) + 1, :]) * tapers[tapi, :][:, np.newaxis]\n        pow = fft(data, timewinidx, axis=0) / timewinidx\n        pow = pow[:int(np.floor(timewinidx / 2) + 1), :]\n        taperpow += np.mean(pow * np.conj(pow), axis=1)\n    \n    # Finally, get power from closest frequency\n    multitaper_tf[:, ti] = np.real(taperpow / (tapi + 1))\n\n# dB-correct\ndb_multitaper_tf = 10 * np.log10(multitaper_tf / np.mean(multitaper_tf[:, baseidx[0]:baseidx[1]], axis=1)[:, np.newaxis])\n\n# Plot time courses at one frequency band\nplt.figure(figsize=(12, 6))\nplt.subplot(121)\nfreq2plotidx = np.argmin(np.abs(f - frequency2plot)) + 1\nplt.plot(times2save, np.mean(np.log10(multitaper_tf[freq2plotidx - 3:freq2plotidx + 2, :]), axis=0))\nplt.title(f'Sensor {channel2plot}, {frequency2plot} Hz')\nplt.xlim(times2save[0], times2save[-1])\n\nplt.subplot(122)\ntime2plotidx = np.argmin(np.abs(times2save - timepoint2plot))\nplt.plot(f, np.log10(multitaper_tf[:, time2plotidx]))\nplt.title(f'Sensor {channel2plot}, {timepoint2plot} ms')\nplt.xlim(f[0], 40)\n\n# Plot full TF map\nplt.figure(figsize=(8, 6))\nplt.contourf(times2save, f, db_multitaper_tf, 40, cmap='viridis')\nplt.clim(-2, 2)\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.title(f'Power via multitaper from channel {channel2plot}')\nplt.show()"
  },
  {
    "objectID": "chapter14.html",
    "href": "chapter14.html",
    "title": "Chapter 14",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 14 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import hilbert, firls, firwin, filtfilt, lfilter, butter\nfrom scipy.signal.windows import hamming\nfrom scipy.fft import fft, ifft\nfrom scipy.io import loadmat\nimport time as time_module\n\n\n# Figure 14.1\n\n# Create cosine\ntime = np.arange(0, 1.001, 0.001)\ncosine = np.cos(2 * np.pi * 5 * time)\n\n# Plot cosine and its Hilbert transform components\nplt.figure()\nplt.plot(time, cosine, label='cosine')\nplt.plot(time[::5], np.real(hilbert(cosine[::5])), 'ko', label='real part')  # plot every 5th point\nplt.plot(time, np.imag(hilbert(cosine)), 'r', label='imag part')\nplt.plot(time, np.angle(hilbert(cosine)), 'm', label='angle')\nplt.xlim([0, 1])\nplt.ylabel('Angle or amplitude')\nplt.legend()\nplt.show()\n\n\n\n\n\n# The FFT-based Hilbert transform\n\n# Generate random numbers\nn = 21\nrandomnumbers = np.random.randn(n)\n\n# Take FFT\nf = fft(randomnumbers)\n\n# Create a copy that is multiplied by the complex operator\ncomplexf = 1j * f\n\n# Find indices of positive and negative frequencies\nposF = np.arange(1, np.floor(n / 2) + np.mod(n, 2)).astype(int)\nnegF = np.arange(np.ceil(n / 2) + 1 - np.mod(n, 2), n).astype(int)\n\n# Rotate Fourier coefficients\nf[posF] = f[posF] + -1j * complexf[posF]\nf[negF] = f[negF] + 1j * complexf[negF]\n\n# The next two lines are an alternative and slightly faster method. \n# The book explains why this is equivalent to the previous two lines.\n# f[posF] = f[posF]*2\n# f[negF] = f[negF]*0\n\n# Take inverse FFT\nhilbertx = ifft(f)\n\n# Compare with scipy.signal.hilbert function\nhilbertm = hilbert(randomnumbers, axis=0)\n\n# Plot results\nplt.figure()\nplt.subplot(211)\nplt.plot(np.abs(hilbertm), label='scipy.signal.hilbert function')\nplt.plot(np.abs(hilbertx), 'ro', label='\"manual\" Hilbert')\nplt.legend()\nplt.title('magnitude of Hilbert transform')\n\nplt.subplot(212)\nplt.plot(np.angle(hilbertm), label='scipy.signal.hilbert function')\nplt.plot(np.angle(hilbertx), 'ro', label='\"manual\" Hilbert')\nplt.legend()\nplt.title('phase of Hilbert transform')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 14.2\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Filter parameters\nnyquist = EEG['srate'][0][0] / 2\nlower_filter_bound = 4  # Hz\nupper_filter_bound = 10  # Hz\ntransition_width = 0.2\nfilter_order = round(3 * (EEG['srate'][0][0] / lower_filter_bound)) + 1\n\n# Create the filter shape\nffrequencies = [0, (1 - transition_width) * lower_filter_bound, lower_filter_bound,\n                upper_filter_bound, (1 + transition_width) * upper_filter_bound, nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(filter_order, ffrequencies, idealresponse)\n\n# Apply the filter kernel to the data to obtain the band-pass filtered signal\nfiltered_data = np.zeros((EEG['nbchan'][0][0], EEG['pnts'][0][0]))\nfor chani in range(EEG['nbchan'][0][0]):\n    filtered_data[chani, :] = filtfilt(filterweights, 1, EEG['data'][chani, :, 0])\n\n# Apply Hilbert transform in correct and incorrect orientations\nhilbert_oops = hilbert(filtered_data.T).T\nhilbert_yes = hilbert(filtered_data)\n# note these are opposite from Matlab\n\n# Plot results\nplt.figure()\nplt.subplot(221)\nplt.plot(EEG['times'][0], np.angle(hilbert_yes[0, :].T), 'b')\nplt.title('correct matrix orientation')\nplt.xlabel('Time (ms)')\nplt.ylabel('Phase angle (rad.)')\nplt.xlim([-1000, 1500])\n\nplt.subplot(222)\nplt.plot(EEG['times'][0], np.angle(hilbert_oops[0, :]), 'r')\nplt.title('incorrect matrix orientation')\nplt.xlabel('Time (ms)')\nplt.ylabel('Phase angle (rad.)')\nplt.xlim([-1000, 1500])\n\nplt.subplot(223)\nplt.plot(EEG['times'][0], np.real(hilbert_yes[0, :]), 'b')\nplt.title('correct matrix orientation')\nplt.xlabel('Time (ms)')\nplt.ylabel('Amplitude')\nplt.xlim([-1000, 1500])\n\nplt.subplot(224)\nplt.plot(EEG['times'][0], np.real(hilbert_oops[0, :]), 'r')\nplt.title('incorrect matrix orientation')\nplt.xlabel('Time (ms)')\nplt.ylabel('Amplitude')\nplt.xlim([-1000, 1500])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 14.3\n\n# Define parameters\ncenter_freq = 20  # in Hz\nfilter_frequency_spread = 6  # Hz +/- the center frequency\nwavelet_frequency_spread = 4  # number of wavelet cycles\n\n# Create wavelet\ntime = np.arange(-1000 / EEG['srate'][0][0] / 10, 1000 / EEG['srate'][0][0] / 10 + 1 / EEG['srate'][0][0], 1 / EEG['srate'][0][0])\nwavelet = np.exp(2 * 1j * np.pi * center_freq * time) * np.exp(-time**2 / (2 * (wavelet_frequency_spread / (2 * np.pi * center_freq))**2))\nwavelet = (wavelet - np.mean(wavelet)) / np.std(wavelet)  # z-score\n\n# Compute its power spectrum\nfft_wavelet = np.abs(fft(wavelet))\nfft_wavelet = fft_wavelet / np.max(fft_wavelet)  # normalized to 1.0 for visual comparison ease\nhz_wavelet = np.linspace(0, nyquist, int(len(time) / 2) + 1)\n\n# Construct filter kernel\ntransition_width = 0.2\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread),\n                center_freq - filter_frequency_spread, center_freq + filter_frequency_spread,\n                (1 + transition_width) * (center_freq + filter_frequency_spread), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(201, ffrequencies, idealresponse)\nfilterweights = (filterweights - np.mean(filterweights)) / np.std(filterweights)  # z-score\n# Also compute weights using firwin\nfilterweights1 = firwin(201, [center_freq - filter_frequency_spread, center_freq + filter_frequency_spread] / nyquist, pass_zero=False)\nfilterweights1 = (filterweights1 - np.mean(filterweights1)) / np.std(filterweights1)  # z-score\n\n# Compute power spectrum of filter kernel\nfft_filtkern = np.abs(fft(filterweights))\nfft_filtkern = fft_filtkern / np.max(fft_filtkern)  # normalized to 1.0 for visual comparison ease\nfft_filtkern1 = np.abs(fft(filterweights1))\nfft_filtkern1 = fft_filtkern1 / np.max(fft_filtkern1)  # normalized to 1.0 for visual comparison ease\n\nhz_filtkern = np.linspace(0, nyquist, 101)  # list of frequencies in Hz corresponding to filter kernel\n\n# Plot wavelet and filter kernel\nplt.figure()\nplt.subplot(211)\nplt.plot(np.real(wavelet), label='wavelet')\nplt.plot(filterweights, 'r', label='filter kernel')\nplt.xlim([0, 200])\nplt.ylim([-5, 5])\nplt.xlabel('Time')\nplt.legend()\n\n# Plot power spectra\nplt.subplot(212)\nplt.plot(hz_wavelet, fft_wavelet[:int(np.ceil(len(fft_wavelet) / 2))], label='wavelet')\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))], 'r', label='filter kernel')\nplt.xlim([0, 140])\nplt.ylim([-.1, 1.1])\nplt.xlabel('Frequency (Hz)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 14.4\n\n# Define parameters\ncenter_freq = 20  # in Hz\nfilter_frequency_spread_wide = 10  # Hz +/- the center frequency\n\n# Construct filter kernel\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_wide),\n                center_freq - filter_frequency_spread_wide, center_freq + filter_frequency_spread_wide,\n                (1 + transition_width) * (center_freq + filter_frequency_spread_wide), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweightsW = firls(201, ffrequencies, idealresponse)\nfilterweightsW = (filterweightsW - np.mean(filterweightsW)) / np.std(filterweightsW)  # z-score\n\n# Compute power spectrum of filter kernel\nfft_filtkern = np.abs(fft(filterweightsW))\nfft_filtkern = fft_filtkern / np.max(fft_filtkern)  # normalized to 1.0 for visual comparison ease\n\n# Plot ideal response and best fit\nplt.figure()\nplt.plot(ffrequencies * nyquist, idealresponse, 'r', label='ideal')\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))], 'b', label='best fit')\nplt.ylim([-.1, 1.1])\nplt.xlim([0, nyquist])\nplt.legend()\nplt.show()\n\n\n\n\n\n# Figure 14.5\n\n# Define parameters\ncenter_freq = 20  # in Hz\nfilter_frequency_spread_wide = 10  # Hz +/- the center frequency\nfilter_frequency_spread_naro = 2   # Hz +/- the center frequency\n\n# Construct wide filter kernel\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_wide),\n                 center_freq - filter_frequency_spread_wide, center_freq + filter_frequency_spread_wide,\n                 (1 + transition_width) * (center_freq + filter_frequency_spread_wide), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweightsW = firls(201, ffrequencies, idealresponse)\nfilterweightsW = (filterweightsW - np.mean(filterweightsW)) / np.std(filterweightsW)  # z-score\n\n# Construct narrow filter kernel\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_naro),\n                 center_freq - filter_frequency_spread_naro, center_freq + filter_frequency_spread_naro,\n                 (1 + transition_width) * (center_freq + filter_frequency_spread_naro), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweightsN = firls(201, ffrequencies, idealresponse)\nfilterweightsN = (filterweightsN - np.mean(filterweightsN)) / np.std(filterweightsN)  # z-score\n\n# Plot filter kernels and their Hilbert transforms\nplt.figure()\nplt.subplot(211)\nfft_filtkern = np.abs(fft(filterweightsW))\nfft_filtkern = fft_filtkern / np.max(fft_filtkern)  # normalized to 1.0 for visual comparison ease\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))])\n\nfft_filtkern = np.abs(fft(filterweightsN))\nfft_filtkern = fft_filtkern / np.max(fft_filtkern)  # normalized to 1.0 for visual comparison ease\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))], 'r')\nplt.xlim([0, 140])\nplt.ylim([-.1, 1.1])\nplt.legend(['10 Hz width', '2 Hz width'])\n\nplt.subplot(223)\nplt.plot(filterweightsW)\nplt.plot(filterweightsN, 'r')\nplt.xlim([0, 200])\nplt.ylim([-4, 7])\nplt.legend(['10 Hz spread', '2 Hz spread'])\nplt.xlabel('Time')\n\nplt.subplot(224)\nplt.plot(np.abs(hilbert(filterweightsW)), 'b')\nplt.plot(np.abs(hilbert(filterweightsN)), 'r')\nplt.xlim([0, 200])\nplt.ylim([-4, 7])\nplt.legend(['10 Hz spread', '2 Hz spread'])\nplt.xlabel('Time')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 14.6\n\n# Plot filter kernels and their power spectra\nplt.figure()\nplt.subplot(211)\nplt.plot(filterweights1, label='firwin')\nplt.plot(filterweights, 'r', label='firls')\nplt.xlim([0, 200])\nplt.xlabel('Time')\nplt.legend()\n\nplt.subplot(212)\nplt.plot(hz_filtkern, fft_filtkern1[:int(np.ceil(len(fft_filtkern1) / 2))], label='firwin')\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))], 'r', label='firls')\nplt.xlim([0, 140])\nplt.ylim([-.1, 1.1])\nplt.xlabel('Frequency (Hz)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# This next figure shows that the filter kernel computed by firwin is the same as\n# that produced by firls if you set the transition zone to zero and then\n# smooth the filter kernel with a Hamming window. In the plot, the red and magenta\n# lines overlap, which is why you don't see the firwin filter kernel. You can\n# subtract them and show that the difference (which is due to re-scaling \n# of the kernel after windowing) is 3-4 orders of magnitude smaller than\n# the kernel itself, hence, nearly identical.\n\nfreqL = center_freq - filter_frequency_spread\nfreqU = center_freq + filter_frequency_spread\n\nffrequencies = [0, freqL, freqL, freqU, freqU, nyquist] / nyquist\nfilterweights = firls(201, ffrequencies, idealresponse)\nfilterweights1 = firwin(201, [freqL, freqU] / nyquist, pass_zero=False)\n\nplt.figure()\nplt.subplot(211)\nplt.plot(filterweights, label='firls')\nplt.plot(filterweights1, 'r.', label='firwin')\nplt.plot(filterweights * hamming(len(filterweights)), 'm', label='firls with hamming window')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 14.7a\n\n# Define parameters\ncenter_freq = 60  # in Hz\nfilter_frequency_spread_wide = 10  # Hz +/- the center frequency\n\n# Construct filter kernel\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_wide),\n                center_freq - filter_frequency_spread_wide, center_freq + filter_frequency_spread_wide,\n                (1 + transition_width) * (center_freq + filter_frequency_spread_wide), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweightsW = firls(201, ffrequencies, idealresponse)\nfilterweightsW = (filterweightsW - np.mean(filterweightsW)) / np.std(filterweightsW)  # z-score\n\n# Compute power spectrum of filter kernel\nfft_filtkern = np.abs(fft(filterweightsW))\nfft_filtkern = fft_filtkern / np.max(fft_filtkern)  # normalized to 1.0 for visual comparison ease\n\n# Plot ideal response and best fit\nplt.figure()\nplt.plot(ffrequencies * nyquist, idealresponse, 'r', label='ideal')\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))], 'b', label='best fit')\nplt.ylim([-.1, 1.1])\nplt.xlim([0, nyquist])\nplt.legend()\n\n# Calculate and display SSE (sum of squared errors)\nfreqsidx = [np.argmin(np.abs(hz_filtkern - f)) for f in ffrequencies * nyquist]\nsse = np.sum((idealresponse - fft_filtkern[freqsidx])**2)\nplt.title(f'SSE: {sse}')\nplt.show()\n\n\n# Define parameters\ncenter_freq = 60  # in Hz\nfilter_frequency_spread_wide = 15  # Hz +/- the center frequency\n\n# Construct filter kernel\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_wide),\n                center_freq - filter_frequency_spread_wide, center_freq + filter_frequency_spread_wide,\n                (1 + transition_width) * (center_freq + filter_frequency_spread_wide), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweightsW = firls(201, ffrequencies, idealresponse)\nfilterweightsW = (filterweightsW - np.mean(filterweightsW)) / np.std(filterweightsW)  # z-score\n\n# Compute power spectrum of filter kernel\nfft_filtkern = np.abs(fft(filterweightsW))\nfft_filtkern = fft_filtkern / np.max(fft_filtkern)  # normalized to 1.0 for visual comparison ease\n\n# Plot ideal response and best fit\nplt.figure()\nplt.plot(ffrequencies * nyquist, idealresponse, 'r', label='ideal')\nplt.plot(hz_filtkern, fft_filtkern[:int(np.ceil(len(fft_filtkern) / 2))], 'b', label='best fit')\nplt.ylim([-.1, 1.1])\nplt.xlim([0, nyquist])\nplt.legend()\n\n# Calculate and display SSE (sum of squared errors)\nfreqsidx = [np.argmin(np.abs(hz_filtkern - f)) for f in ffrequencies * nyquist]\nsse = np.sum((idealresponse - fft_filtkern[freqsidx])**2)\nplt.title(f'SSE: {sse}')\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 14.7b\n\n# Define parameters\ncenterfreqs = np.linspace(5, 80, 60)\ntranswidths = np.linspace(0.01, 0.2, 40)\nfilterwidths = np.linspace(0.05, 0.3, 40)\n\n# Initialize SSE matrix for transition widths\nsse = np.zeros((len(centerfreqs), len(transwidths)))\nfor centfreqi, center_freq in enumerate(centerfreqs):\n    for transwidi, transition_width in enumerate(transwidths):\n        filter_frequency_spread_wide = center_freq * 0.2\n\n        ffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_wide),\n                        center_freq - filter_frequency_spread_wide, center_freq + filter_frequency_spread_wide,\n                        (1 + transition_width) * (center_freq + filter_frequency_spread_wide), nyquist] / nyquist\n        filterweightsW = firls(201, ffrequencies, idealresponse)\n        filterweightsW = (filterweightsW - np.mean(filterweightsW)) / np.std(filterweightsW)  # z-score\n\n        fft_filtkern = np.abs(fft(filterweightsW))\n        fft_filtkern = fft_filtkern / np.max(fft_filtkern)\n        freqsidx = [np.argmin(np.abs(hz_filtkern - f)) for f in ffrequencies * nyquist]\n        \n        sse[centfreqi, transwidi] = np.sum((idealresponse - fft_filtkern[freqsidx])**2)\n\n# Plot SSE for transition widths\nplt.figure()\nplt.contourf(transwidths, centerfreqs, sse, 40, cmap='viridis')\nplt.xlabel('Transition Widths')\nplt.ylabel('Center Frequencies')\nplt.clim([0, 1])\nplt.colorbar()\nplt.title('SSE for Transition Widths')\nplt.show()\n\n# Initialize SSE matrix for filter widths\nsse = np.zeros((len(centerfreqs), len(filterwidths)))\nfor centfreqi, center_freq in enumerate(centerfreqs):\n    for filterwidthi, filter_width in enumerate(filterwidths):\n        filter_frequency_spread_wide = center_freq * filter_width\n        transition_width = 0.2\n\n        ffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread_wide),\n                        center_freq - filter_frequency_spread_wide, center_freq + filter_frequency_spread_wide,\n                        (1 + transition_width) * (center_freq + filter_frequency_spread_wide), nyquist] / nyquist\n        filterweightsW = firls(201, ffrequencies, idealresponse)\n        filterweightsW = (filterweightsW - np.mean(filterweightsW)) / np.std(filterweightsW)  # z-score\n\n        fft_filtkern = np.abs(fft(filterweightsW))\n        fft_filtkern = fft_filtkern / np.max(fft_filtkern)\n        freqsidx = [np.argmin(np.abs(hz_filtkern - f)) for f in ffrequencies * nyquist]\n\n        sse[centfreqi, filterwidthi] = np.sum((idealresponse - fft_filtkern[freqsidx])**2)\n\n# Plot SSE for filter widths\nplt.figure()\nplt.contourf(filterwidths, centerfreqs, sse, 40, cmap='viridis')\nplt.xlabel('Filter Widths (% Center Freq.)')\nplt.ylabel('Center Frequencies')\nplt.clim([0, 1])\nplt.colorbar()\nplt.title('SSE for Filter Widths')\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 14.8\n\n# Define parameters\ncenter_freq = 10\nfreqspread = 4  # Hz +/- the center frequency\ntranswid = 0.10\nffrequencies = [0, (1 - transwid) * (center_freq - freqspread), (center_freq - freqspread),\n                (center_freq + freqspread), (1 + transwid) * (center_freq + freqspread), nyquist] / nyquist\n\n# Data to filter\ndata2filter = EEG['data'][46, :, 0]\nfilterweights = firls(201, ffrequencies, idealresponse)\n \n# Filter the data using filtfilt and convolve\nfilter_result = filtfilt(filterweights, 1, data2filter)\nconvol_result = np.convolve(data2filter, filterweights, 'same')\n\n# Plot the results\nplt.figure()\nplt.plot(EEG['times'][0], filter_result, label='filtfilt')\nplt.plot(EEG['times'][0], convol_result, 'r', label='conv')\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Amplitude (μV)')\nplt.legend()\nplt.show()\n\n\n\n\n\n# Figure 14.9\n\n# Define parameters\ncenter_freq = 10  # in Hz\nnyquist = EEG['srate'][0][0] / 2\n\n# Create short sine wave\ntime = np.arange(-2000 / EEG['srate'][0][0] / 10, 2000 / EEG['srate'][0][0] / 10 + 1 / EEG['srate'][0][0], 1 / EEG['srate'][0][0])\nwavelet = np.cos(2 * np.pi * center_freq * time) * np.exp(-time**2 / (2 * (3 / (2 * np.pi * center_freq))**2))\n\nfreqspread = 4  # Hz +/- the center frequency\ntranswid = 0.10\n\n# Construct filter kernels\nffrequencies = [0, (1 - transwid) * (center_freq - freqspread), (center_freq - freqspread),\n                (center_freq + freqspread), (1 + transwid) * (center_freq + freqspread), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(251, ffrequencies, idealresponse)\n\n# Apply forward and reverse filtering\nforward_filt = lfilter(filterweights, 1, wavelet)\nreverse_filt = lfilter(filterweights, 1, forward_filt[::-1])\nfinal_filt_result = reverse_filt[::-1]  # Reverse time again\n\n# Plot the results\nplt.figure()\nplt.plot(wavelet, label='signal')\nplt.plot(forward_filt, 'r', label='forward filter')\nplt.plot(final_filt_result, 'm', label='reverse filter')\nplt.xlim([0, len(wavelet)])\nplt.legend()\nplt.show()\n\n\n\n\n\n# Figure 14.10\n\n# 5th-order Butterworth filter\nbutterB, butterA = butter(5, [(center_freq - filter_frequency_spread) / nyquist, (center_freq + filter_frequency_spread) / nyquist], btype='bandpass')\nbutter_filter = filtfilt(butterB, butterA, data2filter)\n\n# Plot the real part of the filtered signal\nplt.figure()\nplt.subplot(211)\nplt.plot(EEG['times'][0], filter_result, label='FIR')\nplt.plot(EEG['times'][0], butter_filter, 'r', label='Butterworth')\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Amplitude (μV)')\nplt.legend()\n\n# Now plot phases\nplt.subplot(212)\nplt.plot(EEG['times'][0], np.angle(hilbert(filter_result)), label='FIR')\nplt.plot(EEG['times'][0], np.angle(hilbert(butter_filter)), 'r', label='Butterworth')\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Phase angles (rad.)')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 14.12\n\n# Define parameters\nelap_time = [0, 0]\nnum_iter = 100\n\nfreqspread = 4  # Hz +/- the center frequency\ncenter_freq = 20\ntranswid = 0.15\n\n# Construct filter kernel\nffrequencies = [0, (1 - transwid) * (center_freq - freqspread), (center_freq - freqspread),\n                (center_freq + freqspread), (1 + transwid) * (center_freq + freqspread), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(3 * round(EEG['srate'][0][0] / (center_freq - freqspread)) + 1, ffrequencies, idealresponse)\n\n# Concatenated filtering\nfor i in range(num_iter):\n    start_time = time_module.time()\n    data2filter_cat = EEG['data'][46, :, :].flatten('F')\n    filtdat_cat = np.reshape(filtfilt(filterweights, 1, data2filter_cat), (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    elap_time[0] += time_module.time() - start_time\n\n# Separated filtering\nfor i in range(num_iter):\n    start_time = time_module.time()\n    data2filter_sep = EEG['data'][46, :, :]\n    filtdat_sep = np.zeros_like(data2filter_sep)\n    for triali in range(EEG['trials'][0][0]):\n        filtdat_sep[:, triali] = filtfilt(filterweights, 1, data2filter_sep[:, triali])\n    elap_time[1] += time_module.time() - start_time\n\nelap_time = np.array(elap_time) / num_iter\n\n# Plot\nplt.figure()\nplt.plot(EEG['times'][0], np.mean(filtdat_cat, axis=1), label='concatenated')\nplt.plot(EEG['times'][0], np.mean(filtdat_sep, axis=1), 'r', label='separated')\nplt.xlim([-1000, 1500])\nplt.legend()\nplt.show()\n\nplt.figure()\nplt.bar([0, 1], elap_time)\nplt.xticks([0, 1], ['Concatenated', 'Separated'])\nplt.ylabel('Time (s)')\nplt.title(f'Speed increase of {elap_time[1] / elap_time[0]:.2f}!')\nplt.show()"
  },
  {
    "objectID": "chapter13.html",
    "href": "chapter13.html",
    "title": "Chapter 13",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 13 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom scipy.io import loadmat\nfrom scipy.fftpack import fft, ifft\n\n\n# Figure 13.1\n\n# Parameters\nsrate = 500  # Sampling rate in Hz\nf = 10  # Frequency of wavelet in Hz\ntime = np.arange(-1, 1 + 1/srate, 1/srate)  # Time, from -1 to 1 second in steps of 1/sampling-rate\ns = 6 / (2 * np.pi * f)\n\n# Create a wavelet\nwavelet = np.exp(2 * np.pi * 1j * f * time) * np.exp(-time**2 / (2 * s**2))\n\n# Plotting\nfig = plt.figure(figsize=(12, 8))\n\n# Show the projection onto the real axis\nax1 = fig.add_subplot(221, projection='3d')\nax1.plot3D(np.real(wavelet), time, np.imag(wavelet), 'm')\nax1.set_ylabel('Time (ms)')\nax1.set_xlabel('real axis')\nax1.view_init(-90, 0)\nax1.set_title('Projection onto real and time axes')\n\n# Show the projection onto the imaginary axis\nax2 = fig.add_subplot(222, projection='3d')\nax2.plot3D(np.real(wavelet), time, np.imag(wavelet), 'g')\nax2.set_ylabel('Time (ms)')\nax2.view_init(0, 0)\nax2.set_title('Projection onto imaginary and time axes')\n\n# Plot projection onto real and imaginary axes\nax3 = fig.add_subplot(223, projection='3d')\nax3.plot3D(np.real(wavelet), time, np.imag(wavelet), 'k')\nax3.set_xlabel('real axis')\nax3.set_zlabel('imag axis')\nax3.view_init(0, -90)\nax3.set_title('Projection onto imaginary and time axes')\n\n# Plot real and imaginary projections simultaneously\nax4 = fig.add_subplot(224)\nax4.plot(time, np.real(wavelet), 'b')\nax4.plot(time, np.imag(wavelet), 'b:')\nax4.set_xlim([-1, 1])\nax4.set_ylim([-1, 1])\nax4.legend(['real part', 'imaginary part'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.2\n\n# Now show in 3D\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot3D(np.real(wavelet), time, np.imag(wavelet), 'k')\nax.set_ylabel('Time (ms)')\nax.set_xlabel('real amplitude')\nax.set_zlabel('imag amplitude')\nax.set_title('3-D projection')\nax.axis('equal')\nplt.show()\n\n\n\n\n\n# Movie\n\n# Parameters for the movie\nfrequency = 6  # Frequency of the sine wave\nsrate = 500  # Note: should be the same as the data\ntime = np.arange(-0.5, 0.5 + 1/srate, 1/srate)  # Vector of time\n\n# Make wavelet\nwavelet = np.exp(2 * 1j * np.pi * frequency * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * frequency))**2))\n\n# Make a movie to compare cartesian and polar representation of wavelet\nfig, axs = plt.subplots(2, 1, figsize=(10, 6), facecolor=[0.6, 0.2, 0.7])\n\n# Setup top row of data (real and imaginary in cartesian plot)\ncplotR, = axs[0].plot(time[0], np.real(wavelet[0]), 'b')\ncplotI, = axs[0].plot(time[0], np.imag(wavelet[0]), 'b:')\naxs[0].set_ylim([-1, 1])\naxs[0].set_xlim([time[0], time[-1]])\naxs[0].set_xlabel('Time (s)')\naxs[0].set_ylabel('Amplitude')\naxs[0].set_title('Cartesian representation')\n\n# Setup bottom row of data (polar representation)\npplot, = axs[1].plot(np.real(wavelet[0]), np.imag(wavelet[0]), 'k')\naxs[1].set_ylim([-1, 1])\naxs[1].set_xlim([-1, 1])\naxs[1].set_title('Polar representation')\naxs[1].set_xlabel('Real axis')\naxs[1].set_ylabel('Imaginary axis')\naxs[1].axis('square')\n\nplt.tight_layout()\n\n# Animation function\ndef update(ti):\n    cplotR.set_data(time[:ti+1], np.real(wavelet[:ti+1]))\n    cplotI.set_data(time[:ti+1], np.imag(wavelet[:ti+1]))\n    pplot.set_data(np.real(wavelet[:ti+1]), np.imag(wavelet[:ti+1]))\n    axs[1].set_ylim([-1, 1])\n    axs[1].set_xlim([-1, 1])\n    return cplotR, cplotI, pplot\n\n# Create animation\ntimeskip = 5  # If you have a slow computer, set this to a higher number\nani = FuncAnimation(fig, update, frames=range(0, len(time), timeskip), blit=True)\n\n# Display the animation\nHTML(ani.to_html5_video())\n\n\n  \n  Your browser does not support the video tag.\n\n\n\n\n\n\n\n# Figure 13.4\n\n# Euler's formula: exp(1i*k) gives you a vector on a unit circle with angle k\ntime = np.arange(-np.pi, np.pi, 0.25)\n\n# Plotting\nfig, axs = plt.subplots(2, 2, figsize=(10, 8))\n\n# cos(theta) + isin(theta)\naxs[0, 0].plot(np.cos(time), np.sin(time))\naxs[0, 0].axis('square')\naxs[0, 0].set_xlim([-1, 1])\naxs[0, 0].set_ylim([-1, 1])\naxs[0, 0].set_title('cos(theta) + isin(theta)')\n\n# e^(i*theta)\naxs[0, 1].plot(np.exp(1j * time).real, np.exp(1j * time).imag)\naxs[0, 1].axis('square')\naxs[0, 1].set_xlim([-1, 1])\naxs[0, 1].set_ylim([-1, 1])\naxs[0, 1].set_title('e^(i*theta)')\n\n# Both\naxs[1, 0].plot(np.cos(time), np.sin(time), 'bo-', markersize=8)\naxs[1, 0].plot(np.exp(1j * time).real, np.exp(1j * time).imag, 'r.-')\naxs[1, 0].axis('square')\naxs[1, 0].set_xlim([-1, 1])\naxs[1, 0].set_ylim([-1, 1])\naxs[1, 0].set_title('Both')\n\n# I need a better hobby\naxs[1, 1].plot(np.cos(time), np.sin(time))\naxs[1, 1].plot(-.35 + np.cos(time) / 5, .35 + np.sin(time) / 5, 'm', linewidth=12)  # Left eye\naxs[1, 1].plot(.35 + np.cos(time) / 5, .35 + np.sin(time) / 5, 'r.', markersize=3)  # Right eye\nsmile = np.arange(-np.pi, 0, 0.5)\naxs[1, 1].plot(np.cos(smile) / 3, -.35 + np.sin(smile) / 5, 'go', markersize=9)  # Mouth\naxs[1, 1].set_xlabel('Real axis')\naxs[1, 1].set_ylabel('Imaginary axis')\naxs[1, 1].axis('square')\naxs[1, 1].set_xlim([-1, 1])\naxs[1, 1].set_ylim([-1, 1])\naxs[1, 1].set_title('I need a better hobby.')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.5\n\n# Redefine time\ntime = np.arange(-0.5, 0.5 + 1/srate, 1/srate)  # Vector of time\n\n# Plotting\nplt.figure(figsize=(10, 6))\n\n# Plot real and imaginary parts of wavelet\nplt.plot(time, np.real(wavelet), linewidth=2)\nplt.plot(time, np.imag(wavelet), ':', linewidth=2)\n\n# Plot cosine and sine\nplt.plot(time, np.cos(2 * np.pi * frequency * time), 'm', linewidth=2)\nplt.plot(time, np.sin(2 * np.pi * frequency * time), 'm:', linewidth=2)\n\n# Plot gaussian window\ngaus_win = np.exp(-time**2 / (2 * s**2))\nplt.plot(time, gaus_win, 'k')\nplt.xlim([-0.5, 0.5])\nplt.ylim([-1.2, 1.2])\nplt.xlabel('Time (s)')\nplt.legend(['real part of wavelet', 'imaginary part of wavelet', 'cosine', 'sine', 'Gaussian'])\nplt.show()\n\n\n\n\n\n# Figure 13.6\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Create 10 Hz wavelet (kernel)\ntime = np.arange(-(EEG['pnts'][0, 0]/EEG['srate'][0, 0]/2), EEG['pnts'][0, 0]/EEG['srate'][0, 0]/2, 1/EEG['srate'][0, 0])\nf = 10  # Frequency of sine wave in Hz\ns = 4 / (2 * np.pi * f)\nwavelet = np.exp(1j * 2 * np.pi * f * time) * np.exp(-time**2 / (2 * s**2))\n\n# Signal is one sine cycle\ntimeS = np.arange(0, 1/f, 1/EEG['srate'][0, 0])  # One cycle is 1/f\nsignal = np.sin(2 * np.pi * f * timeS)\n\n# Now zero-pad signal\nsignal = np.concatenate((np.zeros(int(EEG['pnts'][0, 0]/2 - len(timeS)/2)), signal, np.zeros(int(EEG['pnts'][0, 0]/2 - len(timeS)/2))))\n\n# Plotting\nfig = plt.figure(figsize=(12, 8))\n\n# Plot waves\nax1 = fig.add_subplot(321)\nax1.plot(np.real(wavelet))\nax1.set_xlim([200, len(time) - 200])\n\nax2 = fig.add_subplot(323)\nax2.plot(signal)\nax2.set_xlim([200, len(time) - 200])\n\nax3 = fig.add_subplot(325)\nax3.plot(np.real(np.convolve(wavelet, signal, 'same')))\nax3.set_xlim([200, len(time) - 200])\nax3.set_ylim([-12, 12])\n\n# Now plot dot products at selected phase lags\nax4 = fig.add_subplot(322, projection='polar')\nax4.plot(0, 12, 'k')\ndp = np.sum(wavelet[int(round(100/f))-3:] * signal[:-int(round(100/f))+3])\nax4.plot([np.angle(dp), np.angle(dp)], [0, np.abs(dp)], 'k')\n\nax5 = fig.add_subplot(324, projection='polar')\nax5.plot(0, 12, 'k')\ndp = np.sum(wavelet[int(round(2.3*(100/f))-3):] * signal[:-int(round(2.3*(100/f))-3)])\nax5.plot([np.angle(dp), np.angle(dp)], [0, np.abs(dp)], 'k')\n\nax6 = fig.add_subplot(326, projection='polar')\nax6.plot(0, 12, 'k')\ndp = np.sum(wavelet * signal)\nax6.plot([np.angle(dp), np.angle(dp)], [0, np.abs(dp)], 'k')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.8\n\n# Create wavelet\nfrequency = 6  # in Hz, as usual\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\ns = (4 / (2 * np.pi * frequency))**2  # Note that s is squared here rather than in the next line...\nwavelet = np.exp(2 * 1j * np.pi * frequency * time) * np.exp(-time**2 / (2 * s) / frequency)\n\n# FFT parameters\nn_wavelet = len(wavelet)\nn_data = EEG['pnts'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nhalf_of_wavelet_size = (len(wavelet) - 1) // 2\n\n# FFT of wavelet and EEG data\nfft_wavelet = fft(wavelet, n_convolution)\nfft_data = fft(EEG['data'][46, :, 0], n_convolution)  # FCz, trial 1\n\nconvolution_result_fft = ifft(fft_wavelet * fft_data, n_convolution) * np.sqrt(s)\n\n# Cut off edges\nconvolution_result_fft = convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size]\n\n# Plot for comparison\nfig, axs = plt.subplots(3, 1, figsize=(10, 8))\n\naxs[0].plot(EEG['times'][0], np.real(convolution_result_fft))\naxs[0].set_xlim([-1000, 1500])\naxs[0].set_ylim([-50, 50])\naxs[0].set_xlabel('Time (ms)')\naxs[0].set_ylabel('Voltage (uV)')\naxs[0].set_title(f'Projection onto real axis is filtered signal at {frequency} Hz.')\n\naxs[1].plot(EEG['times'][0], np.abs(convolution_result_fft)**2)\naxs[1].set_xlim([-1000, 1500])\naxs[1].set_ylim([0, 2000])\naxs[1].set_xlabel('Time (ms)')\naxs[1].set_ylabel('Power (uV^2)')\naxs[1].set_title(f'Magnitude of projection vector squared is power at {frequency} Hz.')\n\naxs[2].plot(EEG['times'][0], np.angle(convolution_result_fft))\naxs[2].set_xlim([-1000, 1500])\naxs[2].set_ylim([-4, 4])\naxs[2].set_xlabel('Time (ms)')\naxs[2].set_ylabel('Phase angle (rad.)')\naxs[2].set_title(f'Angle of vector is phase angle time series at {frequency} Hz.')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.9\n\n# Plotting 3D representations of the convolution result\nfig = plt.figure(figsize=(12, 8))\n\n# Real vs. Imaginary\nax1 = fig.add_subplot(131, projection='3d')\nax1.plot3D(EEG['times'][0], np.real(convolution_result_fft), np.imag(convolution_result_fft))\nax1.set_xlabel('Time (ms)')\nax1.set_ylabel('real')\nax1.set_zlabel('imaginary')\nax1.grid(True)\n\n# Amplitude vs. Phase\nax2 = fig.add_subplot(132, projection='3d')\nax2.plot3D(EEG['times'][0], np.abs(convolution_result_fft), np.angle(convolution_result_fft))\nax2.set_xlabel('Time (ms)')\nax2.set_ylabel('amplitude')\nax2.set_zlabel('phase (rad.)')\n\n# Phase vs. Amplitude\nax3 = fig.add_subplot(133, projection='3d')\nax3.plot3D(EEG['times'][0], np.angle(convolution_result_fft), np.abs(convolution_result_fft), 'b')\nax3.plot3D(EEG['times'][0], np.angle(convolution_result_fft), np.real(convolution_result_fft), 'r')\nax3.set_xlabel('Time (ms)')\nax3.set_zlabel('amplitude')\nax3.set_ylabel('phase (rad.)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.10\nsrate = 500\ntime = np.arange(-1,1 + 1/srate, 1/srate)\n\n# Create a 9 Hz wavelet\nf = 9  # Frequency of wavelet in Hz\ns = 6 / (2 * np.pi * f)\nwavelet9 = np.exp(2 * np.pi * 1j * f * time) * np.exp(-time**2 / (2 * s**2))\n\n# Create a 10 Hz wavelet\nf = 10  # Frequency of wavelet in Hz\ns = 6 / (2 * np.pi * f)\nwavelet10 = np.exp(2 * np.pi * 1j * f * time) * np.exp(-time**2 / (2 * s**2))\n\n# Plotting\nfig, axs = plt.subplots(2, 1, figsize=(10, 6))\n\naxs[0].plot(time, np.real(wavelet9))\naxs[0].plot(time, np.real(wavelet10), 'r')\naxs[0].set_xlim([-1, 1])\naxs[0].set_ylim([-1, 1])\naxs[0].set_xlabel('Time (ms)')\naxs[0].set_ylabel('Amplitude')\n\n# Frequency domain representation\nhz = np.linspace(0, srate/2, int(np.floor(len(time)/2)) + 1)\nfft9 = fft(wavelet9)\nfft10 = fft(wavelet10)\n\naxs[1].plot(hz, np.abs(fft9[:len(hz)]))\naxs[1].plot(hz, np.abs(fft10[:len(hz)]), 'r')\naxs[1].set_xlim([0, 25])\naxs[1].set_ylim([0, 140])\naxs[1].set_xlabel('Frequency (Hz)')\naxs[1].set_ylabel('Amplitude')\naxs[1].legend(['9 Hz wavelet', '10 Hz wavelet'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.11\n\n# Definitions, selections...\nchan2use = 'FCz'\n\nmin_freq = 2\nmax_freq = 80\nnum_frex = 30\n\n# Define wavelet parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nfrex = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\ns = np.logspace(np.log10(3), np.log10(10), num_frex) / (2 * np.pi * frex)\n\n# use the following lines to reproduce figure 13.14\n# s = 3./(2*np.pi*frex)\n# s = 10./(2*np.pi*frex)\n\n# Define convolution parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = 2**int(np.ceil(np.log2(n_convolution)))\nhalf_of_wavelet_size = (n_wavelet - 1) // 2\n\n# Find the index of the channel to use\nchanidx = EEG[\"chanlocs\"][0][\"labels\"] == chan2use\n\n# Reshape the data for the channel of interest\neegdata_chan = np.reshape(EEG['data'][chanidx, :, :], (EEG['pnts'][0, 0] * EEG['trials'][0, 0]), order=\"F\")\n\n# Perform the FFT\neegfft = fft(eegdata_chan, n_conv_pow2)\n\n# Initialize\neegpower = np.zeros((num_frex, EEG['pnts'][0, 0]))  # Frequencies X Time X Trials\n\n# Baseline indices\nbaseidx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in np.array([-500, -200])])\n\n# Loop through frequencies and compute synchronization\nfor fi in range(num_frex):\n    wavelet = fft(np.sqrt(1 / (s[fi] * np.sqrt(np.pi))) * np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time**2 / (2 * (s[fi]**2))), n_conv_pow2)\n    \n    # Convolution\n    eegconv = ifft(wavelet * eegfft, n_conv_pow2)\n    eegconv = eegconv[:n_convolution]\n    eegconv = eegconv[half_of_wavelet_size:-half_of_wavelet_size]\n    \n    # Average power over trials (this code performs baseline transform, which you will learn about in chapter 18)\n    temppower = np.mean(np.abs(np.reshape(eegconv, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), order=\"F\"))**2, axis=1)\n    eegpower[fi, :] = 10 * np.log10(temppower / np.mean(temppower[baseidx[0]:baseidx[1]]))\n\n# Plotting\nfig, axs = plt.subplots(1, 2, figsize=(8, 6))\n\n# Logarithmic frequency scaling\ncf1 = axs[0].contourf(EEG['times'][0], frex, eegpower, 40, cmap='viridis', vmin=-3, vmax=3)\naxs[0].set_yscale('log')\naxs[0].set_yticks(np.logspace(np.log10(min_freq), np.log10(max_freq), 6))\naxs[0].set_yticklabels(np.round(np.logspace(np.log10(min_freq), np.log10(max_freq), 6), 1))\naxs[0].set_xlim([-200, 1000])\naxs[0].set_title('Logarithmic frequency scaling')\n\n# Linear frequency scaling\ncf2 = axs[1].contourf(EEG['times'][0], frex, eegpower, 40, cmap='viridis', vmin=-3, vmax=3)\naxs[1].set_xlim([-200, 1000])\naxs[1].set_title('Linear frequency scaling')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# IMPORTANT TANGENT HERE ON Y-AXIS SCALING!!!\n\n# Plotting\nfig, axs = plt.subplots(2, 2, figsize=(10, 8))\n\n# Logarithmic frequency scaling\ncf1 = axs[0, 0].contourf(EEG['times'][0], frex, eegpower, 40, cmap='jet', vmin=-3, vmax=3)\naxs[0, 0].set_yscale('log')\naxs[0, 0].set_yticks(np.logspace(np.log10(min_freq), np.log10(max_freq), 6))\naxs[0, 0].set_yticklabels(np.round(np.logspace(np.log10(min_freq), np.log10(max_freq), 6), 1))\naxs[0, 0].set_xlim([-200, 1000])\naxs[0, 0].set_title('Logarithmic frequency scaling')\naxs[0, 0].set_ylabel('Frequency (Hz)')\n\n# Linear frequency scaling\ncf2 = axs[0, 1].contourf(EEG['times'][0], frex, eegpower, 40, cmap='jet', vmin=-3, vmax=3)\naxs[0, 1].set_xlim([-200, 1000])\naxs[0, 1].set_title('Linear frequency scaling')\n\n# WRONG Y-AXIS LABELS!!!!\nim1 = axs[1, 0].imshow(eegpower, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], frex[0], frex[-1]], cmap='jet', origin = \"lower\", vmin=-3, vmax=3)\naxs[1, 0].set_xlim([-200, 1000])\naxs[1, 0].set_title('WRONG Y-AXIS LABELS!!!!')\naxs[1, 0].set_ylabel('Frequency (Hz)')\naxs[1, 0].set_xlabel('Time (ms)')\n\n# CORRECT Y-AXIS LABELS!!!!\nim2 = axs[1, 1].imshow(eegpower, aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], 0, len(frex)], cmap='jet', origin = \"lower\", vmin=-3, vmax=3)\naxs[1, 1].set_xlim([-200, 1000])\naxs[1, 1].set_yticks(np.linspace(0, len(frex), 6))\naxs[1, 1].set_yticklabels(np.round(np.logspace(np.log10(min_freq), np.log10(max_freq), 6), 1))\naxs[1, 1].set_title('CORRECT Y-AXIS LABELS!!!!')\naxs[1, 1].set_xlabel('Time (ms)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.12\n\n# Parameters for the wavelet\nfrequency = 6  # Frequency of the sine wave\nsrate = 500  # Note: should be the same as the data\ntime = np.arange(-0.5, 0.5 + 1/srate, 1/srate)  # Vector of time\n\n# Make wavelet\nwavelet = np.exp(2 * 1j * np.pi * frequency * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * frequency))**2))\n\n# Plotting\nfig, axs = plt.subplots(2, 1, figsize=(10, 6))\n\n# Good wavelet\naxs[0].plot(time, np.real(wavelet))\naxs[0].set_xlim([-0.5, 0.5])\naxs[0].set_ylim([-1, 1])\naxs[0].set_title('Good.')\n\n# Now make a wavelet that is too short\ntooLowFrequency = 2\nwavelet = np.exp(2 * 1j * np.pi * tooLowFrequency * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * tooLowFrequency))**2))\n\n# Not good wavelet\naxs[1].plot(time, np.real(wavelet))\naxs[1].set_xlim([-0.5, 0.5])\naxs[1].set_ylim([-1, 1])\naxs[1].set_xlabel('Time')\naxs[1].set_title('Not good.')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.13\n\nfrequency = 10\ntime = np.arange(-0.5, 0.5 + 1/srate, 1/srate)\nnumcycles = [3, 7]\n\nwavecolors = 'br'\n\n# Plotting\nfig = plt.figure(figsize=(12, 8))\n\nfor i, nc in enumerate(numcycles):\n    # Make wavelet\n    wavelet = np.exp(2 * 1j * np.pi * frequency * time) * np.exp(-time**2 / (2 * (nc / (2 * np.pi * frequency))**2))\n    \n    # Time domain representation\n    plt.subplot(2,2,i+1)\n    plt.plot(time, np.real(wavelet), wavecolors[i])\n    plt.xlim([-0.5, 0.5])\n    plt.ylim([-1, 1])\n    plt.xlabel('Time')\n    plt.title(f'Wavelet at {frequency} Hz with {nc} cycles')\n    \n    # Frequency domain representation\n    plt.subplot(2,1,2)\n    fft_wav = 2 * np.abs(fft(wavelet))\n    hz_wav = np.linspace(0, srate/2, int(np.round(len(wavelet)/2)) + 1)\n    plt.plot(hz_wav, fft_wav[:len(hz_wav)], wavecolors[i])\n\nplt.subplot(212)\nplt.xlabel('Frequency (Hz)')\nplt.xlim([0, 50])\nplt.ylim([0, 300])\nplt.legend([f'{numcycles[0]} cycles', f'{numcycles[1]} cycles'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 13.14\n\n# To generate this figure, go up to the code for figure 13.11 and uncomment\n# the lines that define the width of the Gaussians for the Morlet wavelets:\n# s = 3./(2*np.pi*frex);\n# s = 10./(2*np.pi*frex);\n# Then, re-run the code for figure 13.11.\n\n\n# Figure 13.15\n\nfrex = np.logspace(np.log10(2), np.log10(80), 30)\nsrate = 500\ntime = np.arange(-2, 2 + 1/srate, 1/srate)\nN = len(time)\nhz = np.linspace(0, srate/2, int(np.floor(N/2)) + 1)\nfwhm = np.zeros((3, len(frex)))\n\nfor numcyclesi in range(3):\n    if numcyclesi == 0:\n        numcycles = np.repeat(3, len(frex))\n    elif numcyclesi == 1:\n        numcycles = np.repeat(10, len(frex))\n    else:\n        numcycles = np.logspace(np.log10(3), np.log10(10), len(frex))\n    \n    for fi in range(len(frex)):\n        # Make wavelet\n        wavelet = np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time**2 / (2 * (numcycles[fi] / (2 * np.pi * frex[fi]))**2))\n        \n        # Take FFT of wavelet\n        fwave = fft(wavelet)\n        fwave = np.abs(fwave[:len(hz)]) * 2\n        \n        # Normalize power to [0 1]\n        fwave = (fwave - np.min(fwave)) / np.max(fwave)\n        \n        # Find left and right 1/2\n        peakx = np.argmax(fwave)\n        left5 = np.argmin(np.abs(fwave[:peakx-2] - 0.5))\n        right5 = peakx + np.argmin(np.abs(fwave[peakx-1:] - 0.5)) - 1\n        \n        fwhm[numcyclesi, fi] = hz[right5] - hz[left5]\n        \n        # Plot one example of a wavelet's power spectrum and fwhm\n        if fi == int(np.ceil(len(frex)/2))-1 and numcyclesi == 2:\n            plt.figure()\n            \n            # Plot power spectrum\n            plt.plot(hz, fwave, '.-')\n            \n            # Plot fwhm\n            plt.plot(hz[left5], fwave[left5], 'ro', markersize=10)\n            plt.plot(hz[right5], fwave[right5], 'ro', markersize=10)\n            plt.plot([hz[left5], hz[left5]], [0, fwave[left5]], 'r')\n            plt.plot([hz[right5], hz[right5]], [0, fwave[right5]], 'r')\n            \n            plt.xlim([0, 30])\n            plt.ylim([0, 1])\n            plt.xlabel('Frequency (Hz)')\n            plt.ylabel('Normalized power')\n            plt.show()\n\n# Plot FWHM\nplt.figure()\nplt.plot(frex, fwhm[0, :], '.-')\nplt.plot(frex, fwhm[1, :], '.-')\nplt.plot(frex, fwhm[2, :], '.-')\nplt.xlim([0, 80])\nplt.ylim([0, 70])\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('FWHM (Hz)')\nplt.legend(['3', '10', '3-10'])\nplt.show()\n\n# Log-log plot of FWHM\nplt.figure()\nplt.plot(frex, fwhm[0, :], '.-')\nplt.plot(frex, fwhm[1, :], '.-')\nplt.plot(frex, fwhm[2, :], '.-')\nplt.xscale('log')\nplt.yscale('log')\nplt.xlim([frex[0]*0.8, frex[-1]*1.2])\nplt.ylim([np.min(fwhm)*0.8, np.max(fwhm)*1.2])\nplt.gca().set_xticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 6)))\nplt.gca().set_yticks(np.round(10*np.logspace(np.log10(np.min(fwhm)), np.log10(np.max(fwhm)), 6))/10)\nplt.gca().set_xticklabels(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 6)))\nplt.gca().set_yticklabels(np.round(10*np.logspace(np.log10(np.min(fwhm)), np.log10(np.max(fwhm)), 6))/10)\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('FWHM (Hz)')\nplt.legend(['3', '10', '3-10'])\nplt.show()"
  },
  {
    "objectID": "chapter31.html",
    "href": "chapter31.html",
    "title": "Chapter 31",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 31 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\nfrom scipy.stats import norm, pearsonr\nfrom mne import create_info, EvokedArray\nfrom mne.channels import make_dig_montage\nimport networkx as nx\nfrom scipy.sparse import csr_matrix\nfrom scipy.sparse.csgraph import dijkstra\n\n\n# Figure 31.2\n\n# Load data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Specify some time-frequency parameters\ncenter_freq = 10  # Hz\ntime2analyze = 200  # in ms\n\n# Wavelet and FFT parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nhalf_wavelet = (len(time) - 1) // 2\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\n\n# Initialize connectivity output matrix\nconnectivitymat = np.zeros((EEG['nbchan'][0, 0], EEG['nbchan'][0, 0]))\n\n# Time in indices\ntidx = np.argmin(np.abs(EEG['times'][0] - time2analyze))\n\n# Create wavelet and take FFT\ns = 5 / (2 * np.pi * center_freq)\nwavelet_fft = fft(np.exp(2 * 1j * np.pi * center_freq * time) * np.exp(-time**2 / (2 * (s**2))), n_convolution)\n\n# Compute analytic signal for all channels\nanalyticsignals = np.zeros((EEG['nbchan'][0, 0], EEG['pnts'][0, 0], EEG['trials'][0, 0]), dtype=complex)\nfor chani in range(EEG['nbchan'][0, 0]):\n    # FFT of data\n    data_fft = fft(EEG['data'][chani, :, :].flatten('F'), n_convolution)\n    \n    # Convolution\n    convolution_result = ifft(wavelet_fft * data_fft, n_convolution)\n    convolution_result = convolution_result[half_wavelet:-half_wavelet]\n    \n    analyticsignals[chani] = np.reshape(convolution_result, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')\n\n# Now compute all-to-all connectivity\nfor chani in range(EEG['nbchan'][0, 0]):\n    for chanj in range(chani, EEG['nbchan'][0, 0]):  # Note that you don't need to start at 1\n        xsd = analyticsignals[chani, tidx] * np.conj(analyticsignals[chanj, tidx])\n        \n        # Connectivity matrix (phase-lag index on upper triangle; ISPC on lower triangle)\n        connectivitymat[chani, chanj] = np.abs(np.mean(np.sign(np.imag(xsd))))\n        connectivitymat[chanj, chani] = np.abs(np.mean(np.exp(1j * np.angle(xsd))))\n\n# Plotting the connectivity matrix\nplt.figure()\nplt.imshow(connectivitymat, aspect='equal', vmin=0, vmax=0.7)\nxticks = np.arange(1, EEG['nbchan'][0, 0] + 1, 8)\nyticks = np.arange(1, EEG['nbchan'][0, 0] + 1, 8)\nplt.xticks(xticks)\nplt.yticks(yticks)\nplt.gca().set_xticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in xticks])\nplt.gca().set_yticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in yticks])\nplt.colorbar()\nplt.show()\n\n\n\n\n\n# Figure 31.4\n\nplt.figure(figsize=(10, 10))\n\n# Subplot 221\nplt.subplot(221)\n# Get upper part of matrix\ntemp = connectivitymat[np.triu_indices_from(connectivitymat, k=1)]\n# Threshold is one std above median connectivity value\npli_thresh = np.std(temp) + np.median(temp)\n# Plot histogram and vertical line at threshold\nplt.hist(temp, bins=30, alpha=0.75)\nplt.axvline(pli_thresh, color='magenta', linewidth=2)\nplt.xlabel('Phase-lag index')\nplt.ylabel('Count')\nplt.xlim([0, 1])\n\n# Subplot 222\nplt.subplot(222)\n# Get lower part of matrix\ntemp = connectivitymat[np.tril_indices_from(connectivitymat, k=-1)]\n# Find 1 std above median connectivity value\nispc_thresh = np.std(temp) + np.median(temp)\n# Plot histogram and vertical line at threshold\nplt.hist(temp, bins=30, alpha=0.75)\nplt.axvline(ispc_thresh, color='magenta', linewidth=2)\nplt.xlabel('ISPC')\nplt.ylabel('Count')\nplt.xlim([0, 1])\n\n# Subplot 223\nplt.subplot(223)\n# Get the upper triangle of the matrix, excluding the diagonal\npli_mat = np.triu(connectivitymat, k=1)\n# Find 1 std above median connectivity value\ntemp = pli_mat[pli_mat != 0]  # Exclude zeros\n# Apply the threshold and make the matrix symmetric\npli_mat[pli_mat &lt; pli_thresh] = 0\npli_mat = pli_mat + pli_mat.T  # Add the transpose to include the lower triangle\n# Plot the matrix\nplt.imshow(pli_mat, aspect='equal', vmin=0, vmax=0.7)\nxticks = np.arange(1, EEG['nbchan'][0, 0] + 1, 8)\nyticks = np.arange(1, EEG['nbchan'][0, 0] + 1, 8)\nplt.xticks(xticks)\nplt.yticks(yticks)\nplt.gca().set_xticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in xticks])\nplt.gca().set_yticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in yticks])\n\n# Subplot 224\nplt.subplot(224)\n# Make symmetric phase-lag index connectivity matrix\nispc_mat = connectivitymat.copy()\n# Eliminate upper triangle (including the diagonal)\nispc_mat[np.triu_indices_from(ispc_mat, k=0)] = 0\n# Mirror lower triangle to upper triangle\nispc_mat = ispc_mat + ispc_mat.T\n# Apply threshold\nispc_mat[ispc_mat &lt; ispc_thresh] = 0\n# Binarize connectivity matrix\nispc_mat = ispc_mat.astype(bool)\n# Plot the matrix\nplt.imshow(ispc_mat, aspect='equal', vmin=0, vmax=0.7)\nxticks = np.arange(1, EEG['nbchan'][0, 0] + 1, 8)\nyticks = np.arange(1, EEG['nbchan'][0, 0] + 1, 8)\nplt.xticks(xticks)\nplt.yticks(yticks)\nplt.gca().set_xticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in xticks])\nplt.gca().set_yticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in yticks])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 31.6\ndegree_pli = np.sum(pli_mat &gt; 0, axis=0)\ndegree_ispc = np.sum(ispc_mat &gt; 0, axis=0)\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\ndegrees_pli = np.delete(degree_pli, exclude_chans)\ndegrees_ispc = np.delete(degree_ispc, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\nplt.figure(figsize=(10, 5))\n\n# Subplot 121\nax1 = plt.subplot(121)\nevoked = EvokedArray(degrees_pli[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(0, 25000000), axes=ax1, show=False, times=-1, time_format='', colorbar=False)\nplt.title('Connectivity degree, phase-lag index')\n\n# Subplot 122\nax2 = plt.subplot(122)\nevoked = EvokedArray(degrees_ispc[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(0, 25000000), axes=ax2, show=False, times=-1, time_format='', colorbar=False)\nplt.title('Connectivity degree, ISPC')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 31.7 (analyses are here; next cell plots results)\n\nfrex = np.logspace(np.log10(3), np.log10(40), 25)\ntimes2save = np.arange(-300, 1201, 50)\nthresh = np.zeros(len(frex))  # Added threshold vector\n\n# Wavelet and FFT parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nhalf_wavelet = (len(time) - 1) // 2\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nn_conv2 = int(2 ** np.ceil(np.log2(n_convolution)))\n\n# Create wavelet (and take FFT)\nwavelets_fft = np.zeros((len(frex), n_conv2), dtype=complex)\ns = np.logspace(np.log10(4), np.log10(10), len(frex)) / (2 * np.pi * frex)\nfor fi in range(len(frex)):\n    wavelets_fft[fi, :] = fft(np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time**2 / (2 * (s[fi]**2))), n_conv2)\n\n# Find time indices\ntimes2saveidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save]\n\n# Initialize matrices\nalldata = np.zeros((EEG['nbchan'][0, 0], len(frex), len(times2save), EEG['trials'][0, 0]), dtype=complex)\ntf_all2all = np.zeros((EEG['nbchan'][0, 0], EEG['nbchan'][0, 0], len(frex), len(times2save)), dtype=complex)\ntf_degree = np.zeros((EEG['nbchan'][0, 0], len(frex), len(times2save)))\n\n# First, run convolution for all electrodes and save results\nfor chani in range(EEG['nbchan'][0, 0]):\n    # FFT of activity at this electrode (note that this is done outside the frequency loop)\n    eeg_fft = fft(EEG['data'][chani].flatten('F'), n_conv2)\n    \n    # Loop over frequencies\n    for fi in range(len(frex)):\n        # Analytic signal from target\n        conv_res = ifft(wavelets_fft[fi, :] * eeg_fft, n_conv2)\n        conv_res = conv_res[:n_convolution]\n        asig = np.reshape(conv_res[half_wavelet:-half_wavelet], (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')\n        \n        # Store the required time points\n        alldata[chani, fi, :, :] = asig[times2saveidx, :]\n\n# Now that we have all the data, compute all-to-all connectivity\nfor chani in range(EEG['nbchan'][0, 0]):\n    for chanj in range(chani + 1, EEG['nbchan'][0, 0]):\n        # Compute connectivity\n        xsd = alldata[chani] * np.conj(alldata[chanj])\n        \n        # Connectivity matrix (phase-lag index or ISPC; comment one or the other line)\n        # tf_all2all[chani, chanj] = np.abs(np.mean(np.sign(np.imag(xsd)), axis=2))  # PLI\n        tf_all2all[chani, chanj] = np.abs(np.mean(np.exp(1j * np.angle(xsd)), axis=2))  # ISPC\n\n# Now that we have a one-to-all connectivity, threshold the connectivity matrix\n# (separate threshold for each frequency)\nfor fi in range(len(frex)):\n    # Use the absolute values (magnitudes) of the complex numbers for thresholding\n    tempsynch = np.abs(tf_all2all[:, :, fi, :][np.triu_indices(EEG['nbchan'][0, 0], k=1)])\n    thresh[fi] = np.median(tempsynch) + np.std(tempsynch)\n    \n    # Isolate, threshold, binarize\n    for ti in range(tf_all2all.shape[3]):\n        temp = np.abs(tf_all2all[:, :, fi, ti])  # Use the magnitude for thresholding\n        temp = temp + temp.T  # Make symmetric matrix\n        temp = temp &gt; thresh[fi]  # Threshold and binarize\n        tf_degree[:, fi, ti] = np.sum(temp, axis=0)  # Compute degree\n\n\n# Figure 31.7 (plotting)\n\n# Show topographical maps\nfreqs2plot = [5, 9]  # Hz\ntimes2plot = [100, 200, 300]  # ms\nclim = (0, 20000000)\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\ntf_degrees = np.delete(tf_degree, exclude_chans, axis=0)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\nplt.figure(figsize=(12, 8))\nfor fi, freq in enumerate(freqs2plot):\n    for ti, time in enumerate(times2plot):\n        plt_idx = ti + 1 + fi * len(times2plot)\n        ax = plt.subplot(len(freqs2plot), len(times2plot), plt_idx)\n        freq_idx = np.argmin(np.abs(frex - freq))\n        time_idx = np.argmin(np.abs(times2save - time))\n        evoked = EvokedArray(tf_degrees[:, freq_idx, time_idx, np.newaxis], info, tmin=EEG['xmin'][0][0])\n        evoked.set_montage(montage)\n        evoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=clim, axes=ax, show=False, times=-1, time_format='', colorbar=False)\n        plt.title(f\"{time} ms, {freq} Hz\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 31.8\n\nelectrode2plot = 'FCz'  # Change to 'oz' or any other electrode as needed\nbaselineperiod = [-300, -100]\nclim = [-10, 10]\n\n# Convert baseline period time to indices\nbaseidx = [np.argmin(np.abs(times2save - t)) for t in baselineperiod]\n# Subtract baseline\ntf_degree_base = tf_degree - np.mean(tf_degree[:, :, baseidx[0]:baseidx[1]+1], axis=2, keepdims=True)\n\nplt.figure(figsize=(8, 6))\n# Contourf plot for time-frequency connectivity degree at the specified electrode\n# Note that we are now using the 2D slice for the contour plot\nplt.contourf(times2save, frex, np.squeeze(tf_degree_base[EEG['chanlocs'][0]['labels']==electrode2plot, :, :]), 20, cmap='viridis')\nplt.clim(clim)\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 6)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 6)))\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.title(f'TF connectivity degree at electrode {electrode2plot}')\n\nplt.show()\n\n\n\n\n\n# Figure 31.10\n\nfreqs2plot = [5, 9]  # Hz\ntimes2plot = [100, 200, 300]  # ms\nclim = [400000, 800000]\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Open two figures ('h' for handle)\nfigh1 = plt.figure(figsize=(12, 8))\nfigh2 = plt.figure(figsize=(12, 8))\n\nfor fi, freq in enumerate(freqs2plot):\n    for ti, time in enumerate(times2plot):\n        # Frequency index\n        fidx = np.argmin(np.abs(frex - freq))\n        \n        # Extract thresholded connectivity matrix\n        connmat = tf_all2all[:, :, fidx, np.argmin(np.abs(times2save - time))]\n        connmat = connmat + connmat.T  # Make symmetric matrix\n        connmat = connmat &gt; thresh[fidx]  # Threshold and binarize\n        \n        # Initialize\n        clustcoef = np.zeros(EEG['nbchan'][0, 0])\n        \n        for chani in range(EEG['nbchan'][0, 0]):\n            # Find neighbors (suprathreshold connections)\n            neighbors = np.where(connmat[chani, :] &gt; 0)[0]\n            n = len(neighbors)\n            \n            # Cluster coefficient not computed for islands\n            if n &gt; 1:\n                # \"Local\" network of neighbors\n                localnetwork = connmat[np.ix_(neighbors, neighbors)]\n                # Localnetwork is symmetric; remove redundant values by replacing with NaN\n                localnetwork = localnetwork + np.tril(np.nan * np.ones(localnetwork.shape))\n                # Compute cluster coefficient (neighbor connectivity scaled)\n                clustcoef[chani] = 2 * np.nansum(localnetwork) / (n * (n - 1))\n        \n        # Topoplots\n        plt.figure(figh1.number)\n        ax1 = plt.subplot(len(freqs2plot), len(times2plot), ti + 1 + fi * len(times2plot))\n        clustcoefs = np.delete(clustcoef, exclude_chans)\n        evoked = EvokedArray(clustcoefs[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\n        evoked.set_montage(montage)\n        evoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=clim, axes=ax1, show=False, times=-1, time_format='', colorbar=False)\n        plt.title(f'Cluster coefficient: {time} ms, {freq} Hz')\n        \n        # Relationship between degree and cluster coefficient\n        plt.figure(figh2.number)\n        plt.subplot(len(freqs2plot), len(times2plot), ti + 1 + fi * len(times2plot))\n        degree = np.sum(connmat &gt; 0, axis=0)\n        plt.scatter(degree, clustcoef)\n        r, p = pearsonr(degree, clustcoef)\n        plt.ylim([-0.05, 1.05])\n        plt.xlim([0, 30])\n        plt.xlabel('Degree')\n        plt.ylabel('Cluster coefficient')\n        plt.title(f'Correlation: r={r:.2f}, p={p:.2f}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 31.11\n\nthresholds = np.linspace(0, 3, 20)\nclustercoefficients = np.zeros((EEG['nbchan'][0, 0], len(thresholds)))\n\nfor ti, thresh_val in enumerate(thresholds):\n    # Find frequency index\n    fidx = np.argmin(np.abs(frex - freqs2plot[0]))\n    \n    # Extract thresholded connectivity matrix\n    connmat = tf_all2all[:, :, fidx, np.argmin(np.abs(times2save - times2plot[2]))]\n    tmpsynch = tf_all2all[:, :, fidx, :][tf_all2all[:, :, fidx, :] &gt; 0]\n    tthresh = np.median(tmpsynch) + thresh_val * np.std(tmpsynch)\n    connmat = connmat + connmat.T  # Make symmetric matrix\n    connmat = connmat &gt; tthresh  # Threshold and binarize\n    \n    for chani in range(EEG['nbchan'][0, 0]):\n        # Find neighbors (suprathreshold connections)\n        neighbors = np.where(connmat[chani, :] &gt; 0)[0]\n        n = len(neighbors)\n        \n        # Cluster coefficient not computed for islands\n        if n &gt; 1:\n            # \"Local\" network of neighbors\n            localnetwork = connmat[np.ix_(neighbors, neighbors)].astype(float)\n            # Localnetwork is symmetric; remove redundant values by replacing with NaN\n            localnetwork += np.tril(np.nan * np.ones(localnetwork.shape))\n            # Compute cluster coefficient (neighbor connectivity scaled)\n            clustercoefficients[chani, ti] = 2 * np.nansum(localnetwork) / (n * (n - 1))\n\nplt.figure(figsize=(10, 8))\nplt.plot(thresholds, clustercoefficients.T, alpha=0.5)\nplt.plot(thresholds, np.mean(clustercoefficients, axis=0), 'k', linewidth=3)\nplt.xlabel('Threshold (number of standard deviations above median)')\nplt.ylabel('Clustering coefficient')\nplt.xlim([0, 3])\nplt.ylim([-0.025, 1.025])\nplt.show()\n\n\n\n\n\n# Figures 31.13/14 (this cell takes a long time to run...)\n\nuse_real_network = False  # if False, simulate a network (True/False for Figures 13/14)\n\nfreq2use = 10\ntime2use = 100\n\n# Frequency index\nfidx = np.argmin(np.abs(frex - freq2use))\n\nconnmat = tf_all2all[:, :, fidx, np.argmin(np.abs(times2save - time2use))]\nconnmat = connmat + connmat.T  # Make symmetric matrix\nconnmat = connmat &gt; thresh[fidx]  # Threshold and binarize\n\nif not use_real_network:\n    n = 1000  # number of nodes\n    k = 10  # neighbor connectivity\n    connmat = np.zeros((n, n))\n    for i in range(n):\n        # set neighbors to 1 (special cases for start and end of network)\n        connmat[i, max(1, i - k // 2):min(n, i + k // 2)] = 1\n\n# probabilities of rewiring\nprobs = np.logspace(np.log10(0.0001), np.log10(1), 20)\n\ncp = np.zeros(len(probs))\nlp = np.zeros(len(probs))\n\n# loop over a few networks to make plots look a bit nicer\nfor neti in range(10):\n    for probi, prob in enumerate(probs):\n        # rewire\n        # find which edges to rewire\n        real_edges = np.where(np.tril(connmat) != 0)\n        edges_to_rewire = np.random.choice(len(real_edges[0]), size=int(round(prob * len(real_edges[0]))), replace=False)\n        \n        # rewired connectivity matrix\n        connmat_rewired = connmat.copy()\n        \n        # loop through edges and change target\n        for edge_idx in edges_to_rewire:\n            # find XY coordinates\n            x, y = real_edges[0][edge_idx], real_edges[1][edge_idx]\n            \n            # find possible edges to change (cannot already be an edge)\n            edges2change = np.where(connmat_rewired[x, :] == 0)[0]\n            \n            # rewire\n            y2rewire = np.random.choice(edges2change, 1)\n            connmat_rewired[x, y2rewire] = 1\n            connmat_rewired[y2rewire, x] = 1\n            \n            # set original to zero\n            connmat_rewired[x, y] = 0\n            connmat_rewired[y, x] = 0\n        \n        # mirror matrix\n        connmat_rewired = np.tril(connmat_rewired) + np.tril(connmat_rewired).T\n        # binarize\n        connmat_rewired = (connmat_rewired &gt; 0).astype(int)\n        \n        # compute cluster coefficient and path lengths\n        clustcoef_rewired = np.zeros(EEG['nbchan'][0, 0])\n\n        for chani in range(EEG['nbchan'][0, 0]):\n            # Find neighbors (suprathreshold connections)\n            neighbors = np.where(connmat_rewired[chani, :] &gt; 0)[0]\n            n = len(neighbors)\n            \n            # Cluster coefficient not computed for islands\n            if n &gt; 1:\n                # \"Local\" network of neighbors\n                localnetwork = connmat_rewired[np.ix_(neighbors, neighbors)].astype(float)\n                # Localnetwork is symmetric; remove redundant values by replacing with NaN\n                localnetwork += np.tril(np.nan * np.ones(localnetwork.shape))\n                # Compute cluster coefficient (neighbor connectivity scaled)\n                clustcoef_rewired[chani] = 2 * np.nansum(localnetwork) / (n * (n - 1))\n        \n        cp[probi] += np.nanmean(clustcoef_rewired)\n        temppathlengths = dijkstra(csgraph=csr_matrix(connmat_rewired), directed=False, unweighted=True)\n        lp[probi] += np.mean(temppathlengths[temppathlengths != np.inf])\n\n        # Save example networks from select probabilities\n        if probi == 0:\n            network1 = connmat_rewired\n        elif probi == 10:\n            network10 = connmat_rewired\n        elif probi == len(probs) - 1:\n            networkend = connmat_rewired\n\ncp /= neti+1\nlp /= neti+1\n\nplt.figure(figsize=(10, 8))\nplt.plot(probs, cp / cp[0], '-o', label='C_r/C')\nplt.plot(probs, lp / lp[0], 'r-o', label='L_r/L')\nplt.xlabel('Probability of rewiring')\nplt.legend()\nplt.xscale('log')\nplt.axvline(probs[0], color='k', linestyle=':')\nplt.axvline(probs[10], color='k', linestyle=':')\nplt.axvline(probs[-1], color='k', linestyle=':')\nplt.ylim([0, 1.02])\nplt.show()\n\n# Determine the axis limits based on whether you are using a real network or a simulated network\nif use_real_network:\n    xylims = (1, EEG['nbchan'][0, 0])\nelse:\n    xylims = (1, 100)\n\n# Create a figure and plot the three networks\nplt.figure(figsize=(15, 5))\n\n# Subplot for network1\nplt.subplot(131)\nplt.imshow(network1, cmap='gray', aspect='equal')\nplt.xlim(xylims)\nplt.ylim(xylims)\nplt.gca().invert_yaxis()\n\n# Subplot for network10\nplt.subplot(132)\nplt.imshow(network10, cmap='gray', aspect='equal')\nplt.xlim(xylims)\nplt.ylim(xylims)\nplt.gca().invert_yaxis()\n\n# Subplot for networkend\nplt.subplot(133)\nplt.imshow(networkend, cmap='gray', aspect='equal')\nplt.xlim(xylims)\nplt.ylim(xylims)\nplt.gca().invert_yaxis()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Figures 31.15/16\n\nfreq2use = 6\ntime2use = 300\nn_permutations = 1000\n\nthresholds = np.linspace(0, 2, 20)\nswn_z = np.zeros(len(thresholds))\n\nfor threshi, thresh_val in enumerate(thresholds):\n    # Frequency index\n    fidx = np.argmin(np.abs(frex - freq2use))\n    \n    connmat = tf_all2all[:, :, fidx, np.argmin(np.abs(times2save - time2use))]\n    tmpsynch = tf_all2all[:, :, fidx, :][tf_all2all[:, :, fidx, :] &gt; 0]\n    tthresh = np.median(tmpsynch) + thresh_val * np.std(tmpsynch)\n    connmat = connmat + connmat.T  # Make symmetric matrix\n    connmat = connmat &gt; tthresh  # Threshold and binarize\n    nconnections = np.sum(connmat) // 2  # Number of connections (for random network)\n    \n    # find locations of lower triangle\n    matrix_locs = np.where(np.tril(connmat+1-np.eye(len(connmat))) != 0)\n\n    swn_permutations = np.zeros(n_permutations)\n\n    # compute real clustering coefficient and path lengths\n    clustcoef_real = np.zeros(EEG['nbchan'][0, 0])\n    for chani in range(EEG['nbchan'][0, 0]):\n        neighbors = np.where(connmat[chani, :] &gt; 0)[0]\n        n = len(neighbors)\n        if n &gt; 1:\n            localnetwork = connmat[np.ix_(neighbors, neighbors)].astype(float)\n            localnetwork += np.tril(np.nan * np.ones(localnetwork.shape))\n            clustcoef_real[chani] = 2 * np.nansum(localnetwork) / (n * (n - 1))\n    # average clustering coefficient over channels\n    clustcoef_real = np.nanmean(clustcoef_real)\n\n    # average path length (remove zeros and infinities)\n    temppathlengths = dijkstra(csgraph=csr_matrix(connmat), directed=False, unweighted=True)\n    pathlengths_real = np.mean(temppathlengths[temppathlengths != np.inf])\n\n    # first create 1000 random graphs and compute their clustering coefficients and path lengths\n    clustercoefficients_random = np.zeros(n_permutations)\n    pathlengths_random = np.zeros(n_permutations)\n\n    for permi in range(n_permutations):\n\n        # generate random network\n        connmat_random = np.zeros(connmat.shape)\n        # find random locations in lower triangle\n        edges2fill = np.random.choice(len(matrix_locs[0]), size=nconnections, replace=False)\n        # set random locations to 1\n        connmat_random[matrix_locs[0][edges2fill], matrix_locs[1][edges2fill]] = 1\n        # mirror matrix\n        connmat_random = np.tril(connmat_random) + np.tril(connmat_random).T\n        # binarize\n        connmat_random = (connmat_random &gt; 0).astype(int)\n\n        # compute cluster coefficient and path lengths\n        clustcoef_random = np.zeros(EEG['nbchan'][0, 0])\n        for chani in range(EEG['nbchan'][0, 0]):\n            neighbors = np.where(connmat_random[chani, :] &gt; 0)[0]\n            n = len(neighbors)\n            if n &gt; 1:\n                localnetwork = connmat_random[np.ix_(neighbors, neighbors)].astype(float)\n                localnetwork += np.tril(np.nan * np.ones(localnetwork.shape))\n                clustcoef_random[chani] = 2 * np.nansum(localnetwork) / (n * (n - 1))\n        # average clustering coefficient over channels\n        clustercoefficients_random[permi] = np.nanmean(clustcoef_random)\n\n        # average path length (remove zeros and infinities)\n        temppathlengths = dijkstra(csgraph=csr_matrix(connmat_random), directed=False, unweighted=True)\n        pathlengths_random[permi] = np.mean(temppathlengths[temppathlengths != np.inf])\n\n    # compute small-world-networkness\n    for permi in range(n_permutations):\n        whichnetworks2use = np.random.choice(n_permutations, size=2, replace=False)\n        if pathlengths_random[whichnetworks2use[1]] != 0 and clustercoefficients_random[whichnetworks2use[1]] != 0:\n            swn_permutations[permi] = ((clustercoefficients_random[whichnetworks2use[0]] / \n                                        clustercoefficients_random[whichnetworks2use[1]]) / \n                                    (pathlengths_random[whichnetworks2use[0]] / \n                                        pathlengths_random[whichnetworks2use[1]]))\n        else:\n            swn_permutations[permi] = np.nan\n        \n    # True swn and its z-value\n    swn_real = (clustcoef_real / np.mean(clustercoefficients_random)) / (pathlengths_real / np.mean(pathlengths_random))\n    swn_z[threshi] = (swn_real - np.mean(swn_permutations)) / np.std(swn_permutations)\n    \n    if threshi == len(thresholds) // 2:\n        plt.figure(figsize=(10, 5))\n        plt.hist(swn_permutations, bins=50, alpha=0.5)\n        plt.axvline(swn_real, color='magenta', linewidth=3)\n        plt.title(f'Small-world-networkness: Z={swn_z[threshi]:.2f}, p={1 - norm.cdf(np.abs(swn_z[threshi])):.4f}')\n        plt.show()\n\nplt.figure(figsize=(10, 5))\nplt.plot(thresholds, swn_z, '-o', markerfacecolor='white')\nplt.xlabel('Threshold (Standard deviations above median)')\nplt.ylabel('SWN_z')\nplt.xlim([-0.05, 2.05])\nplt.show()"
  },
  {
    "objectID": "chapter15.html",
    "href": "chapter15.html",
    "title": "Chapter 15",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 15 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import detrend\nfrom scipy.fft import fft\nfrom scipy.io import loadmat\n\n\n# Figure 15.1\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define time window in ms\ntimewin = 500\n\n# Convert ms to index\ntimewinidx = round(timewin / (1000 / EEG['srate'][0][0]))\n\n# Create Hann taper function\nhann_win = 0.5 * (1 - np.cos(2 * np.pi * np.arange(timewinidx) / (timewinidx - 1)))\n\n# Detrend data\nd = detrend(EEG['data'][19, :, 15])\n\n# Plot one trial of data\nplt.figure(figsize=(12, 8))\nplt.subplot(311)\nplt.plot(EEG['times'][0], d)\nplt.xlim([-1000, 1500])\nplt.title('One trial of data')\n\n# Find the sample time closest to -50 ms\nstime = np.argmin(np.abs(EEG['times'][0] - (-50)))\n\n# Plot one short-time window of data, windowed\nplt.subplot(323)\nplt.plot(EEG['times'][0][stime:stime + timewinidx], d[stime:stime + timewinidx], label='Original')\nplt.plot(EEG['times'][0][stime:stime + timewinidx], d[stime:stime + timewinidx] * hann_win, 'r', label='Windowed')\nplt.xlim([-50, -50 + timewin])\nplt.title('One short-time window of data, windowed')\nplt.legend()\n\n# Compute power spectrum from that time window\ndfft = fft(d[stime:stime + timewinidx] * hann_win)\nf = np.linspace(0, EEG['srate'][0][0] / 2, int(np.floor(len(hann_win) / 2)) + 1)\nplt.subplot(313)\nplt.plot(f[1:], np.abs(dfft[1:int(np.floor(len(hann_win) / 2)) + 1]) ** 2, '.-')\nplt.title('Power spectrum from that time window')\nplt.xlim([1, 128])\nplt.ylim([-1000, 25000])\nplt.xticks(np.arange(0, EEG['srate'][0][0] / 2 + 1, 10))\n\nplt.tight_layout()\nplt.show()\n\n# Create TF matrix and input column of data at selected time point\ntf = np.zeros((int(np.floor(len(hann_win) / 2)), EEG['pnts'][0][0]))\ntf[:, stime + int(timewinidx / 2) - 11:stime + int(timewinidx / 2) + 10] = np.tile(np.abs(dfft[1:int(np.floor(len(hann_win) / 2)) + 1]) * 2, (21, 1)).T\n\n# Plot TF matrix\nplt.figure(figsize=(12, 6))\nplt.imshow(np.log10(tf + 1), aspect='auto', extent=[EEG['times'][0][0], EEG['times'][0][-1], f[0], f[-1]], origin='lower')\nplt.gca().invert_yaxis()\nplt.clim([-4, 4])\nplt.title('TF matrix')\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 15.2\n\n# Define parameters\ntimewin = 400  # in ms, for stFFT\ntimes2save = np.arange(-300, 1050, 50)  # in ms\nchannel2plot = 'P7'\nfrequency2plot = 15  # in Hz\ntimepoint2plot = 200  # ms\n\n# Convert from ms to index\ntimes2saveidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save]\ntimewinidx = round(timewin / (1000 / EEG['srate'][0][0]))\nchan2useidx = EEG['chanlocs'][0]['labels']==channel2plot\n\n# Create Hann taper\nhann_win = 0.5 * (1 - np.cos(2 * np.pi * np.arange(timewinidx) / (timewinidx - 1)))\n\n# Define frequencies\nfrex = np.linspace(0, EEG['srate'][0][0] / 2, int(np.floor(timewinidx / 2)) + 1)\n\n# Initialize power output matrix\ntf = np.zeros((len(frex), len(times2save)))\n\n# Loop over time points and perform FFT\nfor timepointi, tidx in enumerate(times2saveidx):\n    # Extract time series data for this center time point\n    tempdat = np.squeeze(EEG['data'][chan2useidx, tidx - int(np.floor(timewinidx / 2)) - 1:tidx + int(np.floor(timewinidx / 2)) - (timewinidx + 1) % 2, :])\n    \n    # Taper data\n    taperdat = tempdat * hann_win[:, None]\n    \n    # Perform FFT\n    fdat = fft(taperdat, axis=0) / timewinidx\n    tf[:, timepointi] = np.mean(np.abs(fdat[0:int(np.floor(timewinidx / 2)) + 1, :]) ** 2, axis=1)  # Average over trials\n\n# Plot\nplt.figure(figsize=(8, 6))\nplt.subplot(121)\nfreq2plotidx = np.argmin(np.abs(frex - frequency2plot))\nplt.plot(times2save, np.mean(np.log10(tf[freq2plotidx - 2:freq2plotidx + 3, :]), axis=0))\nplt.title(f'Sensor {channel2plot}, {frequency2plot} Hz')\nplt.xlim([times2save[0], times2save[-1]])\n\nplt.subplot(122)\ntime2plotidx = np.argmin(np.abs(times2save - timepoint2plot))\nplt.plot(frex, np.log10(tf[:, time2plotidx]))\nplt.title(f'Sensor {channel2plot}, {timepoint2plot} ms')\nplt.xlim([frex[0], 40])\n\nplt.tight_layout()\nplt.show()\n\nplt.figure(figsize=(8, 6))\nplt.contourf(times2save, frex, np.log10(tf), 40, cmap='viridis', linestyles='None')\nplt.clim([-2, 1])\nplt.title(f'Sensor {channel2plot}, power plot (no baseline correction)')\n\noverlap = 100 * (1 - np.mean(np.diff(times2save)) / timewin)\nprint(f'Overlap of {overlap}%')\n\nplt.show()\n\n\n\n\nOverlap of 87.5%\n\n\n\n\n\n\n# Figure 15.3\n\n# Create Hamming and Hann windows\nhamming_win = 0.54 - 0.46 * np.cos(2 * np.pi * np.arange(timewinidx) / (timewinidx - 1))\nhann_win = 0.5 * (1 - np.cos(2 * np.pi * np.arange(timewinidx) / (timewinidx - 1)))\n\n# Create Gaussian window\ngaus_win = np.exp(-0.5 * ((2.5 * np.arange(-timewinidx / 2, timewinidx / 2)) / (timewinidx / 2)) ** 2)\n\n# Plot together\nplt.figure(figsize=(8, 4))\nplt.plot(hann_win, label='Hann')\nplt.plot(hamming_win, 'r', label='Hamming')\nplt.plot(gaus_win, 'k', label='Gaussian')\nplt.legend()\nplt.xlim([-5, timewinidx + 5])\nplt.ylim([-0.1, 1.1])\nplt.yticks(np.arange(0, 1.1, 0.2))\nplt.title('Window functions')\nplt.show()\n\n\n\n\n\n# Figure 15.6\n\n# Define parameters\nchan2use = 'O1'\nfrequency2plot = 10  # in Hz\n\n# Find the index of the frequency to plot\nfreq2plotidx = np.argmin(np.abs(frex - frequency2plot))\n\n# Initialize ITPC output matrix\nitpc = np.zeros((len(frex), len(times2save)))\n\n# Loop over time points and perform FFT\nfor timepointi, tidx in enumerate(times2saveidx):\n    # Extract time series data for this center time point\n    tempdat = np.squeeze(EEG['data'][EEG['chanlocs'][0]['labels']==chan2use, tidx - int(np.floor(timewinidx / 2)) - 1:tidx + int(np.floor(timewinidx / 2)) - (timewinidx + 1) % 2, :])\n    \n    # Taper data\n    taperdat = tempdat * hann_win[:, None]\n    \n    # Perform FFT\n    fdat = fft(taperdat, axis=0) / timewinidx\n    # Compute ITPC\n    itpc[:, timepointi] = np.abs(np.mean(np.exp(1j * np.angle(fdat[0:int(np.floor(timewinidx / 2)) + 1, :])), axis=1))  # Average over trials\n\n# Plot ITPC\nplt.figure(figsize=(8, 6))\nplt.contourf(times2save, frex, itpc, 40, cmap='viridis', linestyles='None')\nplt.clim([0, 0.5])\nplt.xlim([-200, 1000])\nplt.title(f'ITPC at sensor {chan2use}')\n\nplt.figure(figsize=(8, 6))\nplt.plot(times2save, np.mean(itpc[freq2plotidx - 2:freq2plotidx + 3, :], axis=0))\nplt.title(f'ITPC at sensor {chan2use}, {frequency2plot} Hz')\nplt.xlim([-200, 1000])\nplt.show()"
  },
  {
    "objectID": "chapter33.html",
    "href": "chapter33.html",
    "title": "Chapter 33",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 33 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\nfrom skimage.measure import label as sk_label, regionprops\nfrom scipy.signal import convolve2d\nfrom statsmodels.stats.multitest import multipletests\n\n\n# Figure 33.1\n\nplt.figure(figsize=(10, 5))\n\n# Subplot 1\nplt.subplot(121)\nx = np.linspace(-4, 4, 8000)\nplt.plot(x, norm.pdf(x))\nplt.gca().autoscale(enable=True, axis='both', tight=True)\n\n# Subplot 2\nplt.subplot(122)\na = np.random.randn(1000)\nplt.hist(a, 50)\nplt.show()\n\n# Display probabilities\nprint(f\"p_n = {np.sum(a &gt; 2) / 1000}\")\nprint(f\"p_z = {1 - norm.cdf(2):.5f}\")\n\n\n\n\np_n = 0.022\np_z = 0.02275\n\n\n\n# Figure 33.5/6\n\n# These figures are generated in the code for chapter 34\n\n\n# Figure 33.8\n\n# Create 2D smoothing kernel\nxi, yi = np.meshgrid(np.arange(-10, 11), np.arange(-10, 11))\nzi = xi**2 + yi**2\nzi = 1 - (zi / np.max(zi))\n\n# Create a random smoothed map\nmap = convolve2d(np.random.randn(100, 100), zi, mode='same')\n\n# Threshold map at an arbitrary value\nmapt = map.copy()\nmapt[np.abs(map) &lt; np.ptp(map) / 4] = 0\n\n# Need a binary map for sk_label\nmapt1 = mapt.copy()\nmapt1[mapt1 != 0] = 1\n\n# Get labeled map via sk_label\nmapl, nblobs = sk_label(mapt1, return_num=True, connectivity=2)\n\n# Extract information from clusters\nclustcount = np.zeros(nblobs)\nclustsum = np.zeros(nblobs)\nfor i in range(nblobs):\n    clustcount[i] = np.sum(mapl == i + 1)\n    clustsum[i] = np.sum(map[mapl == i + 1])\n\n# Regionprops works slightly differently but will give similar information\nblobinfo = regionprops(mapl)\nclustcount = np.zeros(nblobs)\nclustsum = np.zeros(nblobs)\nfor i, blob in enumerate(blobinfo):\n    clustcount[i] = blob.area\n    clustsum[i] = np.sum(map[blob.coords[:, 0], blob.coords[:, 1]])\n\n# Cluster count can be done faster using list comprehension\nclustercount = [blob.area for blob in blobinfo]\n\n# Plotting\nplt.figure(figsize=(15, 5))\nplt.subplot(131)\nplt.imshow(map.T, cmap='viridis')\nplt.title('original')\n\nplt.subplot(132)\nplt.imshow(mapt.T, cmap='viridis')\nplt.title('thresholded')\n\nplt.subplot(133)\nplt.imshow(mapl.T, cmap='viridis')\nplt.title(f'labeled ({nblobs} clusters in total)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 33.10\n\nnsigs = np.round(np.linspace(1, 500, 80)).astype(int)\nnnons = np.round(np.linspace(1, 500, 100)).astype(int)\n\nfdrpvals = np.zeros((20, len(nsigs), len(nnons)))\n\nfor iteri in range(20):\n    for i, nsig in enumerate(nsigs):\n        for j, nnonsig in enumerate(nnons):\n            pvals = np.concatenate((np.random.rand(nsig) * 0.05, np.random.rand(nnonsig) * 0.5 + 0.05))\n            reject, pvals_corrected, _, _ = multipletests(pvals, alpha=0.05, method='fdr_bh')\n            fdr_threshold = np.max(pvals[reject]) if np.any(reject) else np.nan\n            fdrpvals[iteri, i, j] = fdr_threshold\n\nfdrpvals = np.nan_to_num(fdrpvals)\nfdrpvals = np.nanmean(fdrpvals, axis=0)\n\nplt.figure()\nplt.imshow(fdrpvals, aspect='auto')\nplt.clim(0, 0.05)\nplt.xlabel('number of non-significant p-values')\nplt.ylabel('number of significant p-values')\nplt.show()\n\nplt.figure(figsize=(10, 10))\nplt.subplot(211)\nplt.plot(np.nanmean(fdrpvals, axis=0))\nplt.xlabel('number of non-significant p-values')\nplt.ylabel('critical p-value')\nplt.xlim(0, 100)\nplt.ylim(0, 0.05)\n\nplt.subplot(212)\nplt.plot(np.nanmean(fdrpvals, axis=1))\nplt.xlabel('number of significant p-values')\nplt.ylabel('critical p-value')\nplt.xlim(0, 80)\nplt.ylim(0, 0.05)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter17.html",
    "href": "chapter17.html",
    "title": "Chapter 17",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 17 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\n\n\n# Figure 17.1\n\n# Load data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define parameters for figure 17.1\nnum_frex = 6\nfrex = np.logspace(np.log10(4), np.log10(30), num_frex)\ns = 6 / (2 * np.pi * frex)\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\n\n# Initialize wavelets\nmwaves = np.zeros((num_frex, len(time)), dtype=complex)\nswaves = np.zeros((num_frex, len(time)), dtype=complex)\n\n# Create Morlet wavelets and s-transforms\nfor fi in range(num_frex):\n    mwaves[fi, :] = np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time**2 / (2 * (s[fi]**2)))\n    swaves[fi, :] = np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time**2 * frex[fi]**2 / 2)\n\n# Additional parameters for convolution\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_conv = n_wavelet + n_data - 1\nhalf_wave = (len(time) - 1) // 2\n\n# FFT of EEG data\neegfft = fft(EEG['data'][63, :, :].flatten('F'), n_conv)\n\n# Convolution\neegconv = ifft(fft(mwaves[4, :], n_conv) * eegfft)\neegconv = eegconv[half_wave:-half_wave]\n\n# Reshape to time X trials and compute power\neegpower = np.log10(np.abs(np.reshape(eegconv, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')**2))\n\n# Plotting the results for figure 17.1\nplt.figure()\nplt.plot(EEG['times'][0], eegpower[:, 49])\nplt.xlim([-400, 1200])\nplt.ylim([2, 4.5])\nthreshold = np.percentile(eegpower.flatten('F'), 95)\nplt.axhline(y=threshold, color='k')\nplt.title(f\"power at electrode {EEG['chanlocs'][0][63]['labels'][0]} at {frex[4]:.4f} Hz\")\nplt.show()\n\n\n\n\n\n# Figure 17.2\n\nplt.figure(figsize=(12, 6))\nfor i in range(num_frex):\n    plt.subplot(2, 3, i+1)\n    plt.plot(time, np.real(mwaves[i, :]))\n    plt.plot(time, np.real(swaves[i, :]), 'r.')\n    plt.xlim([-1, 1])\n    plt.ylim([-1, 1])\n    plt.title(f\"{frex[i]:.4f} Hz\")\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter28.html",
    "href": "chapter28.html",
    "title": "Chapter 28",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 28 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.signal import detrend\nfrom scipy.stats import zscore, chi2\nfrom statsmodels.tsa.api import VAR\nfrom statsmodels.tsa.ar_model import AutoReg\n\n\n# Figure 28.1\n\nplt.figure()\n\n# - Stationary-like process - #\n\nx = [np.random.randn()]\nfor i in range(1, 30):\n    x.append(np.exp(np.cos(np.pi * x[i-1])) + np.random.randn())\n\nplt.subplot(221)\nplt.plot(x, 'mo-', linewidth=1, markerfacecolor='k', markersize=6)\nplt.xlim([0, 31])\nplt.legend(['x_t = e^cos(pi*x_t-1) + randn'])\nplt.title('Stationary autoregressive process')\n\nx = [np.random.randn(), np.random.randn()]\nfor i in range(2, 30):\n    x.append(0.2 * x[i-1] - 0.4 * x[i-2] + np.random.randn())\n\nplt.subplot(222)\nplt.plot(x, 'mo-', linewidth=1, markerfacecolor='k', markersize=6)\nplt.xlim([0, 31])\nplt.legend(['x_t = .2x_t-1 - .4x_t-2 + randn'])\nplt.title('Stationary autoregressive process')\n\n# - Non-stationary process - #\n\nx = [1]\nfor i in range(1, 30):\n    x.append(1.1 * x[i-1] + np.random.randn())\n\nplt.subplot(223)\nplt.plot(x, 'kp-', linewidth=1, markerfacecolor='g', markersize=10)\nplt.xlim([0, 31])\nplt.title('Non-stationary autoregressive process')\nplt.legend(['x_t = 1.1*x_t-1 + randn'])\n\nx = [1, 1.5]\nfor i in range(2, 30):\n    x.append(1.2 * x[i-2] - 0.3 * x[i-1] + np.random.randn())\n\nplt.subplot(224)\nplt.plot(x, 'kp-', linewidth=1, markerfacecolor='g', markersize=10)\nplt.xlim([0, 31])\nplt.legend(['x_t = -0.3*x_t-1 + 1.2*x_t-2 + randn'])\nplt.title('Non-stationary autoregressive process')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 28.2\n\nplt.figure(figsize=(10, 6))\n\n# - Stationary-like process - #\n\n# define X\nx = [np.random.randn(), np.random.randn()]\nfor i in range(2, 30):\n    x.append(0.2 * x[i-1] - 0.4 * x[i-2] + np.random.randn())\n\n# define y\ny = [np.random.rand(), np.random.rand()]  # random initial conditions\nfor i in range(2, len(x)):\n    y.append(0.25 * y[i-1] - 0.8 * x[i-2] + 1.5 * x[i-1] + np.random.randn())\n\nplt.subplot(221)\nplt.plot(x, 'mo-', linewidth=1, markerfacecolor='k', markersize=6)\nplt.plot(y, 'go-', linewidth=1, markerfacecolor='k', markersize=6)\nplt.xlim([0, 31])\nplt.title('Stationary bivariate autoregression')\nplt.legend(['x_t = .2x_t-1 - .4x_t-2 + randn', 'y=0.25*y_t-1 - 0.8*x_t-2 + 1.5*x_t-1 + randn'])\n\n# - Non-stationary process - #\n\n# define X\nx = [1, 1.5]\nfor i in range(2, 30):\n    x.append(1.2 * x[i-2] - 0.3 * x[i-1] + np.random.randn())\n\n# define y\ny = [np.random.rand(), np.random.rand()]  # random initial conditions\nfor i in range(2, len(x)):\n    y.append(0.25 * y[i-1] - 1.2 * x[i-2] + np.random.randn())\n\nplt.subplot(222)\nplt.plot(x, 'mo-', linewidth=1, markerfacecolor='k', markersize=6)\nplt.plot(y, 'go-', linewidth=1, markerfacecolor='k', markersize=6)\nplt.xlim([0, 31])\nplt.title('Non-stationary bivariate autoregression')\nplt.legend(['x_t = -.3x_t-1 - 1.2x_t-2 + randn', 'y=0.25*y_t-1 - 0.8*x_t-2 + 1.5*x_t-1 + randn'])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 28.3 (note: this cell takes a while to run)\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define channels for Granger prediction\nchan1name = 'O1'\nchan2name = 'F5'\n\n# Granger prediction parameters\ntimewin = 200  # in ms\norder = 27  # in ms\n\n# Temporal down-sample results (but not data!)\ntimes2save = np.arange(-400, 1020, 20)  # in ms\n\n# Convert parameters to indices\ntimewin_points = round(timewin / (1000 / EEG['srate'][0, 0]))\norder_points = round(order / (1000 / EEG['srate'][0, 0]))\n\n# Find the index of those channels\nchans = (EEG['chanlocs'][0]['labels'] == chan1name) | (EEG['chanlocs'][0]['labels'] == chan2name)\n\n# Remove ERP from selected electrodes to improve stationarity\neegdata = (EEG['data'][chans, :, :] - np.mean(EEG['data'][chans, :, :], axis=2, keepdims=True))[::-1, :, :]\n\n# Convert requested times to indices\ntimes2saveidx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save])\n\n# Initialize\nx2y = np.zeros(len(times2save))\ny2x = np.zeros(len(times2save))\nbic = np.zeros((len(times2save), 15))  # Bayes info criteria (hard-coded to order=15)\n\n# Loop over time points\nfor timei in range(len(times2save)):\n    # Data from all trials in this time window\n    tempdata = eegdata[:, times2saveidx[timei] - timewin_points//2:times2saveidx[timei] + timewin_points//2 + 1, :].copy()\n    \n    # Detrend and zscore all data\n    for triali in range(EEG['trials'][0, 0]):\n        tempdata[0, :, triali] = zscore(detrend(tempdata[0, :, triali], axis=0), axis=0)\n        tempdata[1, :, triali] = zscore(detrend(tempdata[1, :, triali], axis=0), axis=0)\n\n    # Reshape tempdata for VAR\n    tempdata = np.reshape(tempdata, (2, timewin_points * EEG['trials'][0][0]), 'F').T\n\n    # Fit univariate AR models for each channel\n    model_x = AutoReg(tempdata[:, 0], lags=order_points, old_names=False)\n    model_y = AutoReg(tempdata[:, 1], lags=order_points, old_names=False)\n    results_x = model_x.fit()\n    results_y = model_y.fit()\n\n    # Fit bivariate VAR model\n    var_model = VAR(tempdata)\n    var_results = var_model.fit(maxlags=order_points)\n\n    # Compute error variances\n    Ex = results_x.sigma2\n    Ey = results_y.sigma2\n    E = var_results.sigma_u.diagonal()\n\n    # Compute Granger causality values as log ratio of error variances\n    y2x[timei] = np.log(Ex / E[0])\n    x2y[timei] = np.log(Ey / E[1])\n\n    # Compute BIC for optimal model order at each time point\n    for bici in range(bic.shape[1]):\n        var_model = VAR(tempdata)\n        var_results = var_model.fit(maxlags=bici + 1)\n        bic[timei, bici] = var_results.bic\n\n# Plot Granger causality over time\nplt.figure()\nplt.plot(times2save, x2y, label=f'GP: {chan1name} -&gt; {chan2name}')\nplt.plot(times2save, y2x, 'r', label=f'GP: {chan2name} -&gt; {chan1name}')\nplt.legend()\nplt.title(f'Window length: {timewin} ms, order: {order} ms')\nplt.xlim([-400, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Granger prediction estimate')\nplt.show()\n\n\n\n\n\n# Figure 28.4\n\n# Plot BIC\nplt.figure()\n\nplt.subplot(121)\nmean_bic = np.mean(bic, axis=0)\nplt.plot((np.arange(1, bic.shape[1] + 1)) * (1000 / EEG['srate'][0, 0]), mean_bic, '--.')\nplt.xlabel('Order (converted to ms)')\nplt.ylabel('Mean BIC over all time points')\n\nbestbic_idx = np.argmin(mean_bic) + 1\nplt.plot(bestbic_idx * (1000 / EEG['srate'][0, 0]), mean_bic[bestbic_idx-1], 'mo', markersize=15)\nplt.title(f'Optimal order is {bestbic_idx} ({bestbic_idx * (1000 / EEG[\"srate\"][0, 0])} ms)')\n\nplt.subplot(122)\nbic_per_timepoint = np.argmin(bic, axis=1)\nplt.plot(times2save, bic_per_timepoint * (1000 / EEG['srate'][0, 0]), '--.')\nplt.xlabel('Time (ms)')\nplt.ylabel('Optimal order (converted to ms)')\nplt.title('Optimal order (in ms) at each time point')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 28.5\n\n# Define frequency range\nmin_freq = 10  # in Hz, using a minimum of 10 Hz because of 200-ms window\nmax_freq = 40\n\norder_points = 15\n\nfrequencies = np.logspace(np.log10(min_freq), np.log10(max_freq), 15)\n\n# Initialize\ntf_granger = np.zeros((2, len(frequencies), len(times2save)))\n\n# Loop over time points\nfor timei in range(len(times2save)):\n    # Data from all trials in this time window\n    tempdata = eegdata[:, times2saveidx[timei] - timewin_points//2:times2saveidx[timei] + timewin_points//2 + 1, :].copy()\n\n    # Detrend and zscore all data\n    for triali in range(EEG['trials'][0, 0]):\n        tempdata[0, :, triali] = zscore(detrend(tempdata[0, :, triali], axis=0), axis=0)\n        tempdata[1, :, triali] = zscore(detrend(tempdata[1, :, triali], axis=0), axis=0)\n\n    # Reshape tempdata for VAR\n    tempdata = np.reshape(tempdata, (2, timewin_points * EEG['trials'][0][0]), 'F').T\n\n    # Fit VAR model\n    var_model = VAR(tempdata)\n    var_results = var_model.fit(maxlags=order_points)\n\n    # Compute Granger causality for each frequency\n    for fi, freq in enumerate(frequencies):\n        # Compute the transfer function matrix (Fourier transform of the VAR coefficients)\n        H = np.eye(2, dtype=complex)\n        for k in range(1, order_points + 1):\n            H -= var_results.params[k:k+1].T * np.exp(-2j * np.pi * freq * k / EEG['srate'][0, 0])\n\n        # Compute the spectral density matrix\n        S = np.linalg.inv(H) @ var_results.sigma_u @ np.linalg.inv(H).conj().T / EEG['srate'][0, 0]\n\n        # Compute Granger causality\n        tf_granger[0, fi, timei] = np.log(np.abs(S[1, 1]) / np.abs(S[1, 1] - (H[1, 0] * var_results.sigma_u[0, 0] * H[1, 0].conj()) / EEG['srate'][0, 0]))\n        tf_granger[1, fi, timei] = np.log(np.abs(S[0, 0]) / np.abs(S[0, 0] - (H[0, 1] * var_results.sigma_u[1, 1] * H[0, 1].conj()) / EEG['srate'][0, 0]))\n\n# Plot time-frequency Granger causality\nplt.figure(figsize=(12, 6))\nplt.subplot(211)\nplt.contourf(times2save, frequencies, tf_granger[0, :, :], 40, cmap='viridis')\nplt.colorbar()\nplt.title(f'{chan1name} -&gt; {chan2name}')\nplt.ylabel('Frequency (Hz)')\n\nplt.subplot(212)\nplt.contourf(times2save, frequencies, tf_granger[1, :, :], 40, cmap='viridis')\nplt.colorbar()\nplt.title(f'{chan2name} -&gt; {chan1name}')\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 28.6\n\n# Plot of cycles per frequency\nplt.figure(figsize=(10, 10))\nfor fi, freq in enumerate(frequencies):\n    plt.subplot(4, 4, fi+1)\n    cycles = np.real(np.exp(-1j * np.arange(1, order_points+1) * 2 * np.pi * freq / EEG['srate'][0, 0]))\n    plt.plot((np.arange(1, order_points+1)) * (1000 / EEG['srate'][0, 0]), cycles)\n    plt.xlim([0.5, 1.015 * order_points * (1000 / EEG['srate'][0, 0])])\n    plt.ylim([-1.1, 1.1])\n    plt.title(f'{round(freq)} Hz')\nplt.xlabel('Time (ms)')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 28.7\n\nplt.figure()\n\n# Select electrode to plot\nelectrode2plot = EEG['chanlocs'][0]['labels']=='O2'\nerp = np.squeeze(np.mean(EEG['data'][electrode2plot, :, :], axis=2))\nplt.subplot(211)\nplt.plot(EEG['times'][0], np.squeeze(EEG['data'][electrode2plot, :, 0]),label='single trial')\nplt.plot(EEG['times'][0], np.squeeze(EEG['data'][electrode2plot, :, 0]) - erp, 'r', label='single trial - ERP')\nplt.plot(EEG['times'][0], erp, 'k', label='ERP')\nplt.xlim([-200, 1200])\nplt.legend()\nplt.title(f'Data from electrode {EEG[\"chanlocs\"][0][\"labels\"][electrode2plot]}')\nplt.gca().invert_yaxis()\n\n# Select another electrode to plot\nelectrode2plot = EEG['chanlocs'][0]['labels']=='AFz'\nerp = np.squeeze(np.mean(EEG['data'][electrode2plot, :, :], axis=2))\nplt.subplot(212)\nplt.plot(EEG['times'][0], np.squeeze(EEG['data'][electrode2plot, :, 0]), label='single trial')\nplt.plot(EEG['times'][0], np.squeeze(EEG['data'][electrode2plot, :, 0]) - erp, 'r', label='single trial - ERP')\nplt.plot(EEG['times'][0], erp, 'k', label='ERP')\nplt.xlim([-200, 1200])\nplt.legend()\nplt.title(f'Data from electrode {EEG[\"chanlocs\"][0][\"labels\"][electrode2plot]}')\nplt.gca().invert_yaxis()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 28.8\n\n# Baseline time window\nbaseline_period = [-400, -100]\n\n# Convert to indices\nbaseidx = [np.argmin(np.abs(times2save - bp)) for bp in baseline_period]\n\n# Plot as % changes from baseline\nplt.figure()\nplt.plot(times2save, 100 * (x2y - np.mean(x2y[baseidx[0]:baseidx[1]+1])) / np.mean(x2y[baseidx[0]:baseidx[1]+1]), label=f'GC: {chan1name} -&gt; {chan2name}')\nplt.plot(times2save, 100 * (y2x - np.mean(y2x[baseidx[0]:baseidx[1]+1])) / np.mean(y2x[baseidx[0]:baseidx[1]+1]), 'r', label=f'GC: {chan2name} -&gt; {chan1name}')\nplt.legend()\nplt.xlim([-400, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Granger prediction estimate (% change from baseline)')\n\nplt.show()\n\n\n# Convert time-frequency domain to percent change\ntf_grangerPC = tf_granger.copy()\nfor i in range(2):\n    meangranger = np.mean(tf_grangerPC[i, :, baseidx[0]:baseidx[1]+1], axis=1)\n    tf_grangerPC[i, :, :] = 100 * (tf_grangerPC[i, :, :] - meangranger[:, None]) / meangranger[:, None]\n\n# Plot time-frequency Granger causality percent change\nplt.figure(figsize=(12, 6))\nfor i in range(2):\n    plt.subplot(2, 1, i+1)\n    plt.contourf(times2save, frequencies, tf_grangerPC[i, :, :], 40, cmap='viridis', vmin=-150, vmax=150)\n    plt.colorbar()\n    if i == 0:\n        plt.title(f'{chan1name} -&gt; {chan2name}; percent change')\n    else:\n        plt.title(f'{chan2name} -&gt; {chan1name}; percent change')\n    plt.ylabel('Frequency (Hz)')\nplt.xlabel('Time (ms)')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 28.9\n\nplt.figure()\n\n# Generate two chi-square distributed random numbers\nd1 = chi2.rvs(2, size=1000)\nd2 = chi2.rvs(2, size=1000)\n\n# Get histograms\ny1, x1 = np.histogram(d1, bins=50)\ny2, x2 = np.histogram(d2, bins=50)\ny3, x3 = np.histogram(d1 - d2, bins=50)\n\nplt.subplot(221)\nplt.plot(x1[:-1], y1, 'k')\nplt.plot(x2[:-1], y2, 'r')\nplt.xlim([0, 20])\nplt.ylim([0, max(y1.max(), y2.max())])\n\nplt.subplot(223)\nplt.plot(x3[:-1], y3)\nplt.xlim([-10, 10])\nplt.ylim([0, 140])\n\n# Once more, with new distributions\nd1 = chi2.rvs(7, size=1000)\nd2 = chi2.rvs(7, size=1000)\n\n# Get histograms\ny1, x1 = np.histogram(d1, bins=50)\ny2, x2 = np.histogram(d2, bins=50)\ny3, x3 = np.histogram(d1 - d2, bins=50)\n\nplt.subplot(222)\nplt.plot(x1[:-1], y1, 'k')\nplt.plot(x2[:-1], y2, 'r')\nplt.xlim([0, 30])\nplt.ylim([0, 80])\n\nplt.subplot(224)\nplt.plot(x3[:-1], y3)\nplt.xlim([-20, 20])\nplt.ylim([0, 80])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter11.html",
    "href": "chapter11.html",
    "title": "Chapter 11",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 11 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fft import fft, ifft\nfrom scipy.io import loadmat\n\n\n# Figure 11.1\n\n# Define parameters\nsrate = 1000  # sampling rate of 1 kHz\ntime = np.arange(-1, 1+1/srate, 1/srate)\nfreq = 10  # in Hz\namp = 2  # amplitude, or height of the sine wave\n\n# Create sine wave\nsine_wave = amp * np.sin(2 * np.pi * freq * time)\n\n# Plot sine wave\nplt.figure()\nplt.plot(time, sine_wave)\nplt.xlim([-1, 1])\nplt.ylim([-3, 3])  # this adjusts the y-axis limits for visibility\nplt.title('My first sine wave!')\nplt.show()\n\n\n\n\n\n# Figure 11.2\n\n# Define a sampling rate\nsrate = 500\n\n# List some frequencies\nfrex = [3, 10, 5, 15, 35]\n\n# List some random amplitudes\namplit = [5, 15, 10, 5, 7]\n\n# Phases\nphases = [np.pi/7, np.pi/8, np.pi, np.pi/2, -np.pi/4]\n\n# Define time\ntime = np.arange(-1, 1+1/srate, 1/srate)\n\n# Loop through frequencies and create sine waves\nsine_waves = np.zeros((len(frex), len(time)))\nfor fi in range(len(frex)):\n    sine_waves[fi, :] = amplit[fi] * np.sin(2 * np.pi * frex[fi] * time + phases[fi])\n\n# Plot each wave separately\nplt.figure()\nfor fi in range(len(frex)):\n    plt.subplot(len(frex), 1, fi+1)\n    plt.plot(sine_waves[fi, :], linewidth=2)\n    plt.axis([0, len(time), -max(amplit), max(amplit)])\nplt.tight_layout()\nplt.show()\n\n# Plot the result\nplt.figure()\nplt.plot(np.sum(sine_waves, axis=0))\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('sum of sine waves')\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 11.3\n\n# Plot sum of sine waves plus random noise\nplt.figure()\nplt.plot(np.sum(sine_waves + 5 * np.random.randn(*sine_waves.shape), axis=0))\nplt.axis([0, 1020, -40, 50])  # this sets the x-axis and y-axis limits\nplt.title('sum of sine waves plus white noise')\nplt.show()\n\n\n\n\n\n# Figure 11.4\n\ntime = np.arange(-1, 1+1/srate, 1/srate)\n\n# Create three sine waves\ns1 = np.sin(2 * np.pi * 3 * time)\ns2 = 0.5 * np.sin(2 * np.pi * 8 * time)\ns3 = s1 + s2\n\n# Plot the sine waves\nplt.figure()\nfor i, s in enumerate([s1, s2, s3], 1):\n    plt.subplot(2, 3, i)\n    plt.plot(time, s)\n    plt.xlim([-1, 1])\n    plt.ylim([-1.6, 1.6])\n    plt.yticks(np.arange(-1.5, 2, 0.5))\n    \n    # Plot power\n    plt.subplot(2, 3, i+3)\n    f = fft(s) / len(time)\n    hz = np.linspace(0, srate/2, int(np.floor(len(time)/2)+1))\n    plt.bar(hz, np.abs(f[:len(hz)]) * 2)\n    plt.xlim([0, 11])\n    plt.ylim([0, 1.2])\n    plt.xticks(np.arange(0, 11))\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 11.5\n\n# Length of sequence\nN = 10\n# Random numbers\ndata = np.random.randn(N)\n# Sampling rate in Hz\nsrate = 200\n# Nyquist frequency\nnyquist = srate / 2\n# Initialize Fourier output matrix\nfourier = np.zeros(N, dtype=complex)\n# Frequencies in Hz\nfrequencies = np.linspace(0, nyquist, N//2+1)\n# Time\ntime = np.arange(N) / N\n\n# Fourier transform is dot-product between sine wave and data at each frequency\nfor fi in range(N):\n    sine_wave = np.exp(-1j * 2 * np.pi * (fi) * time)\n    fourier[fi] = np.sum(sine_wave * data)\nfourier = fourier / N\n\n# Plotting\nfig = plt.figure(figsize=(12, 8))\n\nax1 = fig.add_subplot(221)\nax1.plot(data, '-o')\nax1.set_xlim([-1, N])\nax1.set_title('Time domain representation of the data')\n\nax2 = fig.add_subplot(222, projection='3d')\nax2.plot3D(frequencies, np.angle(fourier[:N//2+1]), np.abs(fourier[:N//2+1])**2, '-o', linewidth=3)\nax2.grid(True)\nax2.set_xlabel('Frequency (Hz)')\nax2.set_ylabel('Phase')\nax2.set_zlabel('Power')\nax2.set_title('3-D representation of the Fourier transform')\n\nax3 = fig.add_subplot(223)\nax3.bar(frequencies, np.abs(fourier[:N//2+1])**2)\nax3.set_xlim([-5, 105])\nax3.set_xlabel('Frequency (Hz)')\nax3.set_ylabel('Power')\nax3.set_title('Power spectrum derived from discrete Fourier transform')\n\nax4 = fig.add_subplot(224)\nax4.bar(frequencies, np.angle(fourier[:N//2+1]))\nax4.set_xlim([-5, 105])\nax4.set_xlabel('Frequency (Hz)')\nax4.set_ylabel('Phase angle')\nax4.set_yticks(np.arange(-np.pi, np.pi, np.pi/2))\nax4.set_title('Phase spectrum derived from discrete Fourier transform')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 11.6\n\n# Compute sine waves and sum to recover the original time series\nreconstructed_data = np.zeros(N)\nfor fi in range(N):\n    sine_wave = fourier[fi] * np.exp(1j * 2 * np.pi * (fi) * time)\n    reconstructed_data += np.real(sine_wave)\n\n# Plot original and reconstructed data\nplt.figure()\nplt.plot(data, '-o', label='original data')\nplt.plot(reconstructed_data, 'r-*', label='inverse Fourier transform data')\nplt.xlim([0, N-1])\nplt.legend()\nplt.show()\n\n\n\n\n\n# Figure 11.7\n\n# Perform FFT\nfft_data = fft(data) / N\n\n# Plotting\nplt.figure(figsize=(18, 6))\n\nplt.subplot(131)\nplt.plot(frequencies, np.abs(fourier[:N//2+1])**2, '*-', label='time-domain Fourier')\nplt.plot(frequencies, np.abs(fft_data[:N//2+1])**2, 'ro-', markersize=8, label='FFT')\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Power')\nplt.title('Power spectrum derived from discrete Fourier transform and from FFT')\nplt.legend()\n\nplt.subplot(132)\nplt.plot(frequencies, np.angle(fourier[:N//2+1]), '*-', label='time-domain Fourier')\nplt.plot(frequencies, np.angle(fft_data[:N//2+1]), 'ro-', markersize=8, label='FFT')\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Phase')\nplt.yticks(np.arange(-np.pi, np.pi+1, np.pi/2))\nplt.title('Phase spectrum derived from discrete Fourier transform and from FFT')\n\nplt.subplot(133)\nplt.plot(reconstructed_data, '*-', label='Manual inverse Fourier transform')\nplt.plot(np.real(ifft(fft(data))), 'ro-', markersize=8, label='ifft')\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.title('Manual inverse Fourier transform and ifft')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 11.9\n\n# List some frequencies\nfrex = [3, 10, 5, 7]\n\n# List some random amplitudes\namplit = [5, 15, 10, 5]\n\n# Phases\nphases = [np.pi/7, np.pi/8, np.pi, np.pi/2]\n\n# Create a time series of sequenced sine waves\nsrate = 500\ntime = np.arange(-1, 1+1/srate, 1/srate)\nstationary = np.zeros(len(time) * len(frex))\nnonstationary = np.zeros(len(time) * len(frex))\n\nfor fi in range(len(frex)):\n    temp_sine_wave = amplit[fi] * np.sin(2 * np.pi * frex[fi] * time + phases[fi])\n    stationary += np.tile(temp_sine_wave, len(frex))\n    temp_sine_wave *= (time + 1)\n    start_idx = fi * len(time)\n    stop_idx = start_idx + len(time)\n    nonstationary[start_idx:stop_idx] = temp_sine_wave\n\n# Plot stationary and non-stationary signals\nplt.figure(figsize=(10, 6))\n\nplt.subplot(221)\nplt.plot(stationary, 'r')\nplt.xlim([1, len(stationary)])\nplt.title('stationary signal')\n\nplt.subplot(222)\nplt.plot(nonstationary)\nplt.xlim([1, len(nonstationary)])\nplt.title('non-stationary signal')\n\n# Perform FFT and plot\nfrequencies = np.linspace(0, srate/2, len(nonstationary)//2+1)\nfft_nonstationary = fft(nonstationary) / len(nonstationary)\nfft_stationary = fft(stationary) / len(stationary)\nplt.subplot(212)\nplt.plot(frequencies, np.abs(fft_stationary[:len(frequencies)])*2, 'r', label='Power stationary')\nplt.plot(frequencies, np.abs(fft_nonstationary[:len(frequencies)])*2, label='Power non-stationary')\nplt.xlim([0, max(frex)*2])\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 11.10\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')[\"EEG\"][0, 0]\neegdat4convol = EEG[\"data\"][46, :, 0]\nsrate = EEG[\"srate\"][0][0]\n\n# Create Gaussian\ntime = np.arange(-1, 1+1/srate, 1/srate)\ns = 5 / (2 * np.pi * 30)\ngaussian = np.exp(-time**2 / (2 * s**2)) / 30\n\n# Plot EEG data and Gaussian\nplt.figure(figsize=(10, 4))\n\nplt.subplot(211)\nplt.plot(eegdat4convol)\n\nplt.subplot(212)\nplt.plot(gaussian)\n\nplt.show()\n\n# Plot convolution results\nplt.figure(figsize=(10, 4))\n\nplt.subplot(211)\nplt.plot(np.convolve(eegdat4convol, gaussian, 'same'))\n\nplt.subplot(212)\nplt.plot(np.abs(fft(np.convolve(eegdat4convol, gaussian, 'same'))))\n\nplt.show()\n\n# Plot FFT results\nplt.figure(figsize=(10, 4))\n\nplt.subplot(211)\nplt.plot(np.abs(fft(eegdat4convol)))\n\nplt.subplot(212)\nplt.plot(np.abs(fft(gaussian)))\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# Figure 11.11\n\n# Define parameters\nsrate = 1000\ntime = np.arange(-0.5, 0.5, 1/srate)\nf = 20\nfg = [15, 5]\ns = np.sin(2 * np.pi * f * time)\n\n# Loop over Gaussian widths\nfor i in range(2):\n    g = np.exp(-time**2 / (2 * (4 / (2 * np.pi * fg[i])**2))) / fg[i]\n    \n    plt.figure(figsize=(10, 8))\n    \n    plt.subplot(411)\n    plt.plot(time, s)\n    plt.title('Sine wave (signal)')\n    plt.xlim([-0.5, 0.5])\n    plt.ylim([-1.1, 1.1])\n    \n    plt.subplot(412)\n    plt.plot(time, g)\n    plt.xlim([-0.5, 0.5])\n    plt.title('Gaussian (kernel)')\n    \n    plt.subplot(413)\n    plt.plot(time, np.convolve(s, g, 'same'))\n    plt.xlim([-0.5, 0.5])\n    plt.ylim([-1.1, 1.1])\n    plt.title('result of convolution')\n    \n    plt.subplot(427)\n    fft_s = np.abs(fft(s))\n    fft_s = fft_s[:len(fft_s)//2+1] / np.max(fft_s[:len(fft_s)//2+1])\n    plt.bar(np.arange(501), fft_s, color='r')\n    \n    fft_g = np.abs(fft(g))\n    fft_g = fft_g[:len(fft_g)//2+1] / np.max(fft_g[:len(fft_g)//2+1])\n    plt.plot(np.arange(501), fft_g)\n    plt.xlim([0, 40])\n    plt.ylim([0, 1.05])\n    plt.title('individual power spectra')\n    \n    plt.subplot(428)\n    plt.bar(np.arange(501), fft_g * fft_s)\n    plt.xlim([0, 40])\n    plt.ylim([0, 0.035])\n    plt.title('multiplied power spectra')\n    \n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n# Figure 11.12\ntimes = EEG[\"times\"][0]\nsrate = EEG[\"srate\"][0][0]\n\n# Create Gaussian\ntime = np.arange(-1, 1+1/srate, 1/srate)\ns = 5 / (2 * np.pi * 30)\ngaussian = np.exp(-time**2 / (2 * s**2)) / 30\n\n# Plot EEG data, Gaussian, and result of convolution\nplt.figure(figsize=(10, 8))\n\nplt.subplot(411)\nplt.plot(times, eegdat4convol)\nplt.xlim([-1000, 1500])\n\nplt.subplot(412)\nplt.plot(time, gaussian)\nplt.xlim([-1, 1])\n\nplt.subplot(413)\nplt.plot(times, eegdat4convol, 'r')\nplt.plot(times, np.convolve(eegdat4convol, gaussian, 'same'))\nplt.xlim([-1000, 1500])\n\nnfft = len(eegdat4convol)\nfft_s = np.abs(fft(eegdat4convol, nfft))\nfft_s = fft_s[:nfft//2+1]\nf = np.linspace(0, srate/2, nfft//2+1)\n\nplt.subplot(427)\nplt.plot(f, fft_s / np.max(fft_s), 'r')\n\nfft_g = np.abs(fft(gaussian, nfft))\nfft_g = fft_g[:nfft//2+1]\nplt.plot(f, fft_g / np.max(fft_g))\n\nplt.xlim([0, 60])\n\nplt.subplot(428)\nplt.plot(f, fft_s * fft_g)\nplt.xlim([0, 60])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter29.html",
    "href": "chapter29.html",
    "title": "Chapter 29",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 29 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import iqr\nfrom scipy.io import loadmat\nfrom scipy.fftpack import fft, ifft\nfrom mne import create_info, EvokedArray\nfrom mne.channels import make_dig_montage\n\n\n# Figure 29.2\n\n# create two signals\ntime = np.arange(0, 1.0001, 0.0001)\nsignal1 = np.sin(2 * np.pi * 10 * time)\nsignal2 = np.random.rand(len(signal1)) * 2 - 1  # uniform random numbers in the same scale as the sine wave\n\n# plot signals\nplt.figure(figsize=(10, 8))\n\nplt.subplot(221)\nplt.plot(time, signal1)\nplt.xlim([time[0], time[-1]])\nplt.ylim([-1, 1])\n\nplt.subplot(222)\nplt.plot(time, signal2, 'r')\nplt.xlim([time[0], time[-1]])\nplt.ylim([-1, 1])\n\n# bin data\nnbins = 50\nhdat1, x1 = np.histogram(signal1, bins=nbins)\nhdat2, x2 = np.histogram(signal2, bins=nbins)\n\n# convert to probability\nhdat1 = hdat1 / np.sum(hdat1)\nhdat2 = hdat2 / np.sum(hdat2)\n\n# plot histograms\nplt.subplot(223)\nplt.plot(x1[:-1], hdat1, label='Sine wave')\nplt.plot(x2[:-1], hdat2, 'r', label='Random data')\nplt.legend()\nplt.xlim([-1, 1])\nplt.xlabel('Value bins')\nplt.ylabel('Probability')\n\nplt.subplot(224)\nplt.plot(np.sort(signal1))\nplt.plot(np.sort(signal2), 'r')\nplt.xlim([0, len(signal1)])\nplt.ylim([-1, 1])\n\n# compute entropy\nentro = np.zeros(2)\nentro[0] = -np.sum(hdat1 * np.log2(hdat1 + np.finfo(float).eps))\nentro[1] = -np.sum(hdat2 * np.log2(hdat2 + np.finfo(float).eps))\n\nprint(f'Entropies of sine wave and random noise are {entro[0]} and {entro[1]}.')\n\nplt.tight_layout()\nplt.show()\n\nEntropies of sine wave and random noise are 5.371662108209934 and 5.639960201778226.\n\n\n\n\n\n\n# Figure 29.3\n\n# range of bin numbers\nnbins = np.arange(10, 2001)\n\nentropyByBinSize = np.zeros(len(nbins))\n\nfor nbini in range(len(nbins)):\n    # bin data, transform to probability, and eliminate zeros\n    hdat, _ = np.histogram(signal1, bins=nbins[nbini])\n    hdat = hdat / np.sum(hdat)\n    \n    # compute entropy\n    entropyByBinSize[nbini] = -np.sum(hdat * np.log2(hdat + np.finfo(float).eps))\n\nplt.figure()\nplt.plot(nbins, entropyByBinSize)\nplt.xlim([nbins[0], nbins[-1]])\nplt.xlabel('Number of bins')\nplt.ylabel('Entropy')\nplt.show()\n\n\n\n\n\n# Figure 29.4\n\n# optimal number of bins for histogram based on a few different guidelines\nn = len(signal1)\nmaxmin_range = np.max(signal1) - np.min(signal1)\n\n# Freedman-Diaconis, Scott, and Sturges rules for bin width\nfd_bins = np.ceil(maxmin_range / (2.0 * iqr(signal1) * n ** (-1/3)))\nscott_bins = np.ceil(maxmin_range / (3.5 * np.std(signal1) * n ** (-1/3)))\nsturges_bins = np.ceil(1 + np.log2(n))\n\nplt.figure(figsize=(10, 8))\n\nplt.subplot(211)\n# plot up to 50 bins\nmaxNbins = np.argmin(np.abs(nbins - 50))  # index of nbins that most closely matches 50\nplt.plot(nbins[:maxNbins], entropyByBinSize[:maxNbins], label='Entropy')\n\nplt.axvline(fd_bins, color='m', linewidth=2, label='Freedman-Diaconis')\nplt.axvline(scott_bins, color='k', linewidth=2, label='Scott')\nplt.axvline(sturges_bins, color='r', linewidth=2, label='Sturges')\n\nplt.legend()\nplt.xlim([nbins[0], nbins[maxNbins]])\nplt.xlabel('Number of bins')\nplt.ylabel('Entropy')\n\nplt.subplot(223)\ny, x = np.histogram(signal1, bins=int(fd_bins))\nplt.bar(x[:-1], y, width=np.diff(x), align='edge', edgecolor='none')\nplt.xlim([np.min(signal1) * 1.1, np.max(signal1) * 1.1])\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.title('Optimal number of bins (FD rule)')\n\nplt.subplot(224)\ny, x = np.histogram(signal1, bins=2000)\nplt.bar(x[:-1], y, width=np.diff(x), align='edge', edgecolor='none')\nplt.xlim([np.min(signal1) * 1.05, np.max(signal1) * 1.05])\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.title('Too many bins (2000)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 29.5\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define time windows for entropy calculation\ntime4entropy = [100, 400]  # in ms\nbase4entropy = [-400, -100]  # in ms\ntopo_entropy = np.zeros(EEG['nbchan'][0][0])\n\n# Convert time windows to indices\ntimeidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in time4entropy]\nbaseidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in base4entropy]\n\n# Calculate entropy for each channel\nfor chani in range(EEG['nbchan'][0][0]):\n    # Entropy during task\n    tempdat = EEG['data'][chani, timeidx[0]:timeidx[1]+1, :].flatten('F')\n    hdat, _ = np.histogram(tempdat, bins=25)\n    hdat = hdat / np.sum(hdat)\n    task_entropy = -np.sum(hdat * np.log2(hdat + np.finfo(float).eps))\n    \n    # Entropy during pre-stim baseline\n    tempdat = EEG['data'][chani, baseidx[0]:baseidx[1]+1, :].flatten('F')\n    hdat, _ = np.histogram(tempdat, bins=25)\n    hdat = hdat / np.sum(hdat)\n    base_entropy = -np.sum(hdat * np.log2(hdat + np.finfo(float).eps))\n    \n    # Compute difference in entropy\n    topo_entropy[chani] = task_entropy - base_entropy\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\ntopo_entropy = np.delete(topo_entropy, exclude_chans)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot the topographic map of entropy differences\nplt.figure(figsize=(10, 8))\nax1 = plt.subplot(111)\nevoked = EvokedArray(topo_entropy[:, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sensors=False, contours=0, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=ax1, show=False, times=-1, time_format='', colorbar=False)\n\n# Define sensor for entropy over time and parameters\nsensor4entropy = 'FCz'\ntimes2save = np.arange(-300, 1250, 50)  # in ms\ntimewindow = 400  # ms\n\n# Convert ms to indices\ntimewindowidx = round(timewindow / (1000 / EEG['srate'][0][0]) / 2)\ntimes2saveidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save]\n\n# Find the index of the selected sensor\nelectrodeidx = EEG['chanlocs'][0]['labels']==sensor4entropy\n\n# Initialize array to store entropy values\ntimeEntropy = np.zeros((2, len(times2save)))\n\n# Calculate entropy over time for the selected sensor\nfor timei, tidx in enumerate(times2saveidx):\n    # Data for first 30 trials\n    tempdata = EEG['data'][electrodeidx, tidx - timewindowidx:tidx + timewindowidx + 1, :30].flatten('F')\n    hdat, _ = np.histogram(tempdata, bins=25)\n    hdat = hdat / np.sum(hdat)\n    timeEntropy[0, timei] = -np.sum(hdat * np.log2(hdat + np.finfo(float).eps))\n    \n    # Data for last 30 trials\n    tempdata = EEG['data'][electrodeidx, tidx - timewindowidx:tidx + timewindowidx + 1, -30:].flatten('F')\n    hdat, _ = np.histogram(tempdata, bins=25)\n    hdat = hdat / np.sum(hdat)\n    timeEntropy[1, timei] = -np.sum(hdat * np.log2(hdat + np.finfo(float).eps))\n\n# Plot the entropy over time\nplt.figure()\nplt.plot(times2save, timeEntropy[0, :], label='First 30 trials')\nplt.plot(times2save, timeEntropy[1, :], label='Last 30 trials')\nplt.xlabel('Time (ms)')\nplt.ylabel('Entropy (bits)')\nplt.title(f'Entropy over time from electrode {sensor4entropy}')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 29.6\n\n# right panel: random noise\nsignal1 = np.random.rand(len(signal1)) * 2 - 1\nsignal2 = np.random.rand(len(signal1)) * 2 - 1\n\n# center panel: one pure sine wave and one sine wave plus random noise\n# Uncomment the following lines to use these signals instead\nsignal1 = np.sin(2 * np.pi * 10 * time)\nsignal2 = signal1 + np.random.randn(len(signal1)) / 2\n\n# left panel: one pure sine wave and its inverse\n# Uncomment the following lines to use these signals instead\nsignal1 = np.sin(2 * np.pi * 10 * time)\nsignal2 = -signal1\n\n# determine the optimal number of bins for each variable\nn = len(signal1)\nmaxmin_range = np.max(signal1) - np.min(signal1)\nfd_bins1 = np.ceil(maxmin_range / (2.0 * iqr(signal1) * n ** (-1/3)))  # Freedman-Diaconis\n\nn = len(signal2)\nmaxmin_range = np.max(signal2) - np.min(signal2)\nfd_bins2 = np.ceil(maxmin_range / (2.0 * iqr(signal2) * n ** (-1/3)))  # Freedman-Diaconis\n\n# and use the average...\nfd_bins = int(np.ceil((fd_bins1 + fd_bins2) / 2))\n\n# bin data (using np.histogram)\nedges1 = np.linspace(min(signal1), max(signal1), fd_bins + 1)\nedges2 = np.linspace(min(signal2), max(signal2), fd_bins + 1)\nnPerBin1, _ = np.histogram(signal1, edges1)\nnPerBin2, _ = np.histogram(signal2, edges2)\n\n# Get the bin indices for each value in signal1 and signal2\nbin_indices1 = np.digitize(signal1, edges1) - 1  # -1 to convert to 0-based indexing\nbin_indices2 = np.digitize(signal2, edges2) - 1  # -1 to convert to 0-based indexing\n\n# compute joint frequency table\njointprobs = np.zeros((fd_bins, fd_bins))\nfor i1 in range(fd_bins):\n    for i2 in range(fd_bins):\n        jointprobs[i1, i2] = np.sum((bin_indices1 == i1) & (bin_indices2 == i2))\njointprobs /= np.sum(jointprobs)\n\n# Plot the signals\nplt.figure(figsize=(12, 6))\nplt.subplot(211)\nplt.plot(time, signal1)\nplt.xlim([time[0], time[-1]])\nplt.ylim([-1, 1])\nplt.subplot(212)\nplt.plot(time, signal2)\nplt.xlim([time[0], time[-1]])\nplt.ylim([-1, 1])\nplt.tight_layout()\nplt.show()\n\n# Plot the joint probability matrix\nplt.figure()\nplt.imshow(jointprobs, cmap='gray', aspect='auto')\nplt.colorbar()\nplt.xlabel('Signal 2 bin')\nplt.ylabel('Signal 1 bin')\nplt.clim(0, 0.01)\nplt.gca().invert_yaxis()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 29.7\n\n# Define a function to calculate mutual information\ndef mutual_information_hgram(hgram):\n    \"\"\"Calculate the mutual information based on a joint histogram.\"\"\"\n    # Convert bins counts to probability values\n    pxy = hgram / float(np.sum(hgram))\n    px = np.sum(pxy, axis=1)  # marginal for x over y\n    py = np.sum(pxy, axis=0)  # marginal for y over x\n    px_py = px[:, None] * py[None, :]  # Broadcast to multiply marginals\n    # Now we can do the calculation using the pxy, px_py 2D arrays\n    nzs = pxy &gt; 0  # Only non-zero pxy values contribute to the sum\n    return np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))\n\n# Define the signals for the subplots\nx1 = np.arange(0, 1.001, 0.001)\ny1 = x1\n\nx2 = np.arange(0, 1.001, 0.001)\ny2 = -x2**3\n\nx3 = np.cos(np.arange(0, 2 * np.pi, 0.01))\ny3 = np.sin(np.arange(0, 2 * np.pi, 0.01))\n\nx4 = np.concatenate([np.cos(np.arange(0, 2 * np.pi, 0.01)), np.cos(np.arange(0, 2 * np.pi, 0.01)) + 1])\ny4 = np.concatenate([np.sin(np.arange(0, 2 * np.pi, 0.01)), np.sin(np.arange(0, 2 * np.pi, 0.01)) - 1])\n\n# Calculate mutual information for each pair of signals\nmi1 = mutual_information_hgram(np.histogram2d(x1, y1, bins=20)[0])\nmi2 = mutual_information_hgram(np.histogram2d(x2, y2, bins=20)[0])\nmi3 = mutual_information_hgram(np.histogram2d(x3, y3, bins=20)[0])\nmi4 = mutual_information_hgram(np.histogram2d(x4, y4, bins=20)[0])\n\n# Plot the signals and their mutual information\nplt.figure(figsize=(10, 10))\n\nplt.subplot(221)\nplt.plot(x1, y1, '.')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.title(f'MI={mi1:.4f}, r_s={np.corrcoef(x1, y1)[0, 1]:.4f}')\n\nplt.subplot(222)\nplt.plot(x2, y2, '.')\nplt.xlim([0, 1])\nplt.ylim([-1, 0])\nplt.title(f'MI={mi2:.4f}, r_s={np.corrcoef(x2, y2)[0, 1]:.4f}')\n\nplt.subplot(223)\nplt.plot(x3, y3, '.')\nplt.xlim([-1, 1])\nplt.ylim([-1, 1])\nplt.title(f'MI={mi3:.4f}, r_s={np.corrcoef(x3, y3)[0, 1]:.4f}')\n\nplt.subplot(224)\nplt.plot(x4, y4, '.')\nplt.xlim([-1, 2])\nplt.ylim([-2, 1])\nplt.title(f'MI={mi4:.4f}, r_s={np.corrcoef(x4, y4)[0, 1]:.4f}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 29.8\n\n# Define error estimation functions\ndef entropy_error(b, n):\n    return (b - 1) / (2.0 * n * np.log(2))\n\ndef mutinfo_error(b, n):\n    return (b - 1)**2 / (2.0 * n * np.log(2))\n\n# Define range of data points and fixed number of bins\nn = np.arange(20, 301)\nnfixed = 15\n\n# Calculate errors\nentropy_errors_fixed = entropy_error(nfixed, n)\nentropy_errors_sturges = entropy_error(np.ceil(1 + np.log2(n)), n)\nmutinfo_errors_fixed = mutinfo_error(nfixed, n)\nmutinfo_errors_sturges = mutinfo_error(np.ceil(1 + np.log2(n)), n)\n\n# Plot entropy error\nplt.figure(figsize=(12, 6))\n\nplt.subplot(211)\nplt.plot(n, entropy_errors_fixed, label=f'{nfixed} bins')\nplt.plot(n, entropy_errors_sturges, 'r', label=\"Sturges' rule\")\nplt.legend()\nplt.xlabel('Number of data points')\nplt.ylabel('Entropy error (bits)')\nplt.xlim([n[0], n[-1]])\n\n# Plot mutual information error\nplt.subplot(212)\nplt.plot(n, mutinfo_errors_fixed, label=f'{nfixed} bins')\nplt.plot(n, mutinfo_errors_sturges, 'r', label=\"Sturges' rule\")\nplt.legend()\nplt.xlabel('Number of data points')\nplt.ylabel('Mutual information error')\nplt.xlim([n[0], n[-1]])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 29.9\n\n# Define the signals\nx = np.concatenate([np.cos(np.arange(0, 2 * np.pi, 0.01)), np.cos(np.arange(0, 2 * np.pi, 0.01)) + 1])\ny = np.concatenate([np.sin(np.arange(0, 2 * np.pi, 0.01)), np.sin(np.arange(0, 2 * np.pi, 0.01)) - 1])\n\n# Define noise levels and initialize mutual information array\nnoiselevels = np.arange(0, 1.01, 0.01)\nmi = np.zeros(len(noiselevels))\n\n# Calculate mutual information for different levels of noise\nfor ni in range(len(noiselevels)):\n    noisy_y = y + np.random.randn(len(y)) * noiselevels[ni]\n    mi[ni] = mutual_information_hgram(np.histogram2d(x, noisy_y, bins=20)[0])\n\n# Plot the original signal without noise\nplt.figure(figsize=(12, 8))\nplt.subplot(221)\nplt.plot(x, y, '.')\nplt.axis([-3, 3, -3, 3])\n\n# Plot the mutual information as a function of noise level\nplt.subplot(212)\nplt.plot(noiselevels, mi)\nplt.xlim([noiselevels[0], noiselevels[-1]])\nplt.xlabel('Noise level')\nplt.ylabel('Mutual information')\n\n# Plot the signal with an intermediate level of noise\nplt.subplot(222)\nmid_noise_idx = round(len(noiselevels) / 2)\nplt.plot(x, y + np.random.randn(len(y)) * noiselevels[mid_noise_idx], '.')\nplt.axis([-3, 3, -3, 3])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 29.9d (takes a while to run)\n\n# Define the range of data lengths and noise levels\nnrange = np.arange(300, 3000, 205)\nnoiselevels = np.arange(0, 1.01, 0.01)\n\n# Initialize the mutual information matrix and bin number array\nmi = np.zeros((len(nrange), len(noiselevels)))\nb = np.zeros(len(nrange))  # number of histogram bins\n\n# Loop over different data lengths\nfor ni, n in enumerate(nrange):\n    # Define time and signals\n    t = np.linspace(0, 2 * np.pi, n)\n    x = np.concatenate([np.cos(t), np.cos(t) + 1])\n    y = np.concatenate([np.sin(t), np.sin(t) - 1])\n    \n    # Loop over different noise levels\n    for noi, noise in enumerate(noiselevels):\n        noisy_y = y + np.random.randn(len(y)) * noise\n        if noi == 0:  # keep number of bins constant across noise levels within each number of points\n            # Manually calculate the number of bins using the Freedman-Diaconis rule\n            data_range = np.max(noisy_y) - np.min(noisy_y)\n            h = 2 * iqr(noisy_y) / (len(noisy_y) ** (1 / 3))\n            num_bins = int(data_range / h)\n            b[ni] = num_bins\n            hgram = np.histogram2d(x, noisy_y, bins=num_bins)[0]\n            mi[ni, noi] = mutual_information_hgram(hgram)\n        else:\n            mi[ni, noi] = mutual_information_hgram(np.histogram2d(x, noisy_y, bins=int(b[ni]))[0])\n\n# Convert to percent change from best-case scenario (no noise, large N)\nmip = 100 * (mi - mi[-1, 0]) / mi[-1, 0]\n\n# Plot the percent decrease in MI due to noise\nplt.figure()\nplt.contourf(noiselevels, nrange, mip, 40, cmap='viridis', vmin=-100, vmax=0)\nplt.colorbar()\nplt.xlabel('Noise level')\nplt.ylabel('N (data length)')\nplt.title('Percent decrease in MI due to noise')\nplt.show()\n\n\n\n\n\n# Figure 29.10\n\n# Define electrodes for mutual information analysis and other parameters\nelectrodes4mi = ['Fz', 'O1']\ntimewindow = 400  # in ms\ntimes2save = np.arange(-400, 1201, 100)\n\n# Convert ms to indices\ntimewindowidx = round(timewindow / (1000 / EEG['srate'][0][0]) / 2)\ntimes2saveidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save]\n\n# Find the indices of the selected electrodes\nelectrodesidx = [EEG['chanlocs'][0]['labels']==electrodes4mi[0], EEG['chanlocs'][0]['labels']==electrodes4mi[1]]\n\n# Initialize outputs\nentropy = np.zeros((3, len(times2save)))\nmi = np.zeros((2, len(times2save)))\nnbins = np.zeros(len(times2save))\n\n# Define a function to calculate mutual information\ndef mutual_information(x, y, bins):\n    \"\"\"Calculate the mutual information based on a joint histogram.\"\"\"\n    c_xy = np.histogram2d(x, y, bins)[0]\n    # Add a small constant to avoid log(0)\n    c_xy += 1e-10\n    # Convert bins counts to probability values\n    pxy = c_xy / float(np.sum(c_xy))\n    px = np.sum(pxy, axis=1)  # marginal for x over y\n    py = np.sum(pxy, axis=0)  # marginal for y over x\n    px_py = px[:, None] * py[None, :]  # Broadcast to multiply marginals\n    # Only non-zero pxy values contribute to the sum\n    nzs = pxy &gt; 0\n    return np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))\n\n# Calculate mutual information over time\nfor timei, tidx in enumerate(times2saveidx):\n    datax = EEG['data'][electrodesidx[0], tidx - timewindowidx:tidx + timewindowidx + 1, :].flatten('F')\n    datay = EEG['data'][electrodesidx[1], tidx - timewindowidx:tidx + timewindowidx + 1, :].flatten('F')\n\n    # Determine the number of bins for each variable using the Freedman-Diaconis rule\n    bins_x = int(np.ceil((np.max(datax) - np.min(datax)) / (2 * iqr(datax) / len(datax) ** (1 / 3))))\n    bins_y = int(np.ceil((np.max(datay) - np.min(datay)) / (2 * iqr(datay) / len(datay) ** (1 / 3))))\n    nbins[timei] = max(bins_x, bins_y)  # Use the larger number of bins\n\n    # Calculate mutual information with variable bin length\n    mi[0, timei] = mutual_information(datax, datay, nbins[timei].astype(int))\n\n    # Calculate mutual information with fixed bin length (e.g., 70)\n    mi[1, timei] = mutual_information(datax, datay, 70)\n\n# Plot the mutual information over time\nplt.figure(figsize=(12, 8))\n\nplt.subplot(221)\nplt.plot(times2save, mi[0, :])\nplt.xlabel('Time (ms)')\nplt.ylabel('MI (bits)')\nplt.title('Variable bin length')\nplt.xlim([times2save[0] - 50, times2save[-1] + 50])\nplt.ylim([np.min(mi) - 0.01, np.max(mi) + 0.01])\n\nplt.subplot(222)\nplt.plot(nbins, mi[0, :], '.')\nplt.xlabel('Bin length')\nplt.ylabel('MI (bits)')\nplt.title('Bin length vs. MI')\nplt.ylim([np.min(mi) - 0.01, np.max(mi) + 0.01])\n\nplt.subplot(223)\nplt.plot(times2save, mi[1, :])\nplt.xlabel('Time (ms)')\nplt.ylabel('MI (bits)')\nplt.title('Constant bin length')\nplt.xlim([times2save[0] - 50, times2save[-1] + 50])\nplt.ylim([np.min(mi) - 0.01, np.max(mi) + 0.01])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 29.11\n\n# Define frequency range and baseline time window\nfrex = np.logspace(np.log10(4), np.log10(40), 20)\nbaselinetime = [-500, -200]\n\n# Convert baseline time window to indices\nbaseidx = [np.argmin(np.abs(times2save - t)) for t in baselinetime]\n\n# Specify convolution parameters\nhalf_wavelet = (len(time) - 1) // 2\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\n\n# FFT of data for both electrodes\nfft_EEG1 = fft(EEG['data'][electrodesidx[0], :, :].flatten('F'), n_convolution)\nfft_EEG2 = fft(EEG['data'][electrodesidx[1], :, :].flatten('F'), n_convolution)\n\n# Initialize outputs\nmi = np.zeros((2, len(frex), len(times2save)))\nispc = np.zeros((len(frex), len(times2save)))\npowc = np.zeros((len(frex), len(times2save)))\n\n# Define a small constant to avoid log of zero\nnumerical_floor = 1e-10\n\n# Loop over frequencies\nfor fi, f in enumerate(frex):\n    # Create wavelet and get its FFT\n    wavelet = np.exp(2 * 1j * np.pi * f * time) * np.exp(-time ** 2 / (2 * (4 / (2 * np.pi * f)) ** 2))\n    fft_wavelet = fft(wavelet, n_convolution)\n    \n    # Convolution for each electrode\n    convres1 = ifft(fft_wavelet * fft_EEG1, n_convolution)\n    convres1 = np.reshape(convres1[half_wavelet:-half_wavelet], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    convres2 = ifft(fft_wavelet * fft_EEG2, n_convolution)\n    convres2 = np.reshape(convres2[half_wavelet:-half_wavelet], (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Loop over time points\n    for ti, tidx in enumerate(times2saveidx):\n        # Get analytic signal in the time window around the time point\n        datax = convres1[tidx - timewindowidx:tidx + timewindowidx + 1, :] + numerical_floor\n        datay = convres2[tidx - timewindowidx:tidx + timewindowidx + 1, :] + numerical_floor\n        \n        # Compute mutual information for power and phase\n        mi[0, fi, ti] = mutual_information_hgram(np.histogram2d(np.log10(np.abs(datax)**2).flatten('F'),\n                                                          np.log10(np.abs(datay)**2).flatten('F'), bins=50)[0])\n        mi[1, fi, ti] = mutual_information_hgram(np.histogram2d(np.angle(datax).flatten('F'),\n                                                          np.angle(datay).flatten('F'), bins=20)[0])\n        \n        # Compute inter-site phase clustering (ISPC)\n        ispc[fi, ti] = np.abs(np.mean(np.exp(1j * (np.angle(datay) - np.angle(datax))), axis=0)).mean()\n        \n        # Compute power correlation (Spearman's rank correlation)\n        powc[fi, ti] = np.corrcoef(np.abs(datax).flatten('F'), np.abs(datay).flatten('F'))[0, 1]\n\n# Baseline-subtract the mutual information\nmi_baselined = mi - mi[:, :, baseidx[0]:baseidx[1]+1].mean(axis=2, keepdims=True)\n\n# Plot the results\nplt.figure(figsize=(12, 10))\n\n# Plot mutual information for power\nplt.subplot(2, 2, 1)\nplt.contourf(times2save, frex, mi_baselined[0, :, :], 40, cmap='viridis')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\n\n# Plot mutual information for phase\nplt.subplot(2, 2, 2)\nplt.contourf(times2save, frex, mi_baselined[1, :, :], 40, cmap='viridis')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\n\n# Plot power correlation\nplt.subplot(2, 2, 3)\nplt.contourf(times2save, frex, powc, 40, cmap='viridis')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\n\n# Plot inter-site phase clustering\nplt.subplot(2, 2, 4)\nplt.contourf(times2save, frex, ispc, 40, cmap='viridis')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 29.12\n\n# Define the signals\ntime = np.arange(0, 1.0001, 0.0001)\nsignal1 = np.sin(2 * np.pi * 10 * time)\nsignal2 = -signal1\n\n# Define lags\nlagz = np.arange(1, 1501, 10)\nmilags = np.zeros(len(lagz))\n\n# Calculate mutual information for different lags\nfor li, lag in enumerate(lagz):\n    # Circularly shift signal2 by the current lag\n    shifted_signal2 = np.roll(signal2, lag)\n    # Compute mutual information\n    milags[li] = mutual_information_hgram(np.histogram2d(signal1, shifted_signal2, bins=15)[0])\n\n# Plot mutual information as a function of lag\nplt.figure()\nplt.plot(lagz / (1 / np.mean(np.diff(time))), milags)\nplt.xlabel('Lag (seconds)')\nplt.ylabel('Mutual information (bits)')\nplt.show()\n\n# Now on real data (6 Hz power MI from figure 11)\n# Assuming EEG data has been loaded and 'EEG' variable is available from previous code\n\n# Define frequency for analysis\nfreq = 6  # 6 Hz\n\n# Create wavelet and get its FFT\nwavelet = np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time ** 2 / (2 * (4 / (2 * np.pi * freq)) ** 2))\nfft_wavelet = fft(wavelet, n_convolution)\n\n# Convolution for each electrode with wavelet\nconvres1 = ifft(fft_wavelet * fft_EEG1, n_convolution)\nconvres1 = convres1[n_wavelet//2:-n_wavelet//2+1].reshape((EEG['pnts'][0][0], EEG['trials'][0][0]))\n\nconvres2 = ifft(fft_wavelet * fft_EEG2, n_convolution)\nconvres2 = convres2[n_wavelet//2:-n_wavelet//2+1].reshape((EEG['pnts'][0][0], EEG['trials'][0][0]))\n\n# Get power data\npow1 = np.log10(np.abs(convres1) ** 2)\npow2 = np.log10(np.abs(convres2) ** 2)\n\n# Define lags for real data\nonecycle = int(1000 / freq)\nonecycleidx = int(onecycle / (1000 / EEG['srate'][0][0]))\nlagz = np.arange(-onecycleidx, onecycleidx + 1)\nmilags = np.zeros(len(lagz))\n\n# Calculate mutual information for different lags on real data\nfor li, lag in enumerate(lagz):\n    if lag &lt; 0:\n        milags[li] = mutual_information_hgram(np.histogram2d(pow1[:lag, :].flatten(), pow2[-lag:, :].flatten(), bins=30)[0])\n    elif lag == 0:\n        milags[li] = mutual_information_hgram(np.histogram2d(pow1.flatten(), pow2.flatten(), bins=30)[0])\n    else:\n        milags[li] = mutual_information_hgram(np.histogram2d(pow1[lag:, :].flatten(), pow2[:-lag, :].flatten(), bins=30)[0])\n\n# Plot mutual information as a function of lag for real data\nplt.figure()\nplt.plot(1000 * lagz / EEG['srate'][0][0], milags)\nplt.xlabel(f\"{electrodes4mi[0]} leads {electrodes4mi[1]} ... Lag (ms) ... {electrodes4mi[1]} leads {electrodes4mi[0]}\")\nplt.ylabel('Mutual information (bits)')\nplt.xlim([-onecycle, onecycle])\nplt.show()"
  },
  {
    "objectID": "chapter30.html",
    "href": "chapter30.html",
    "title": "Chapter 30",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 30 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\nfrom scipy.stats import norm\n\n\n# Figure 30.1\n\n# Load data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define channel to plot\nchannel2plot = 'O1'\n\n# Wavelet parameters\nfreq2plot = 25\n\n# Other wavelet parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nhalf_of_wavelet_size = (len(time)-1)//2\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0]*EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\n\n# Find sensor index\nsensoridx = EEG['chanlocs'][0]['labels']==channel2plot\n\n# FFT of data\nfft_EEG = fft(EEG['data'][sensoridx, :, :].flatten('F'), n_convolution)\n\n# Create wavelet and get its FFT\nwavelet = np.exp(2*1j*np.pi*freq2plot*time) * np.exp(-time**2 / (2*(4/(2*np.pi*freq2plot))**2))\nfft_wavelet = fft(wavelet, n_convolution)\n\nconvolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\nconvolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\nconvolution_result = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Plotting\nplt.figure(figsize=(10, 6))\n\nplt.subplot(211)\nplt.plot(EEG['times'][0], np.real(convolution_result[:, 0])) # Filtered signal from the first trial\nplt.xlabel('Time (ms)'), plt.ylabel('Filtered signal amplitude')\nplt.xlim([-200, 1000])\nplt.ylim([-50, 50])\n\nplt.subplot(212)\nplt.plot(EEG['times'][0], np.abs(convolution_result[:, 0])**2) # Power from the first trial\nplt.xlabel('Time (ms)'), plt.ylabel('Power')\nplt.xlim([-200, 1000])\nplt.ylim([0, 3000])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 30.2\n\n# Load data\neeg = loadmat('../data/accumbens_eeg.mat')['eeg'][0]\nsrate = 1000\n\n# Wavelet parameters\nfreq2plot = 70\n\n# Other wavelet parameters\ntime = np.arange(-1, 1 + 1/srate, 1/srate)\nhalf_of_wavelet_size = (len(time)-1)//2\nn_wavelet = len(time)\nn_data = len(eeg)\nn_convolution = n_wavelet + n_data - 1\n\n# FFT of data\nfft_EEG = fft(eeg, n_convolution)\n\n# Create wavelet and get its FFT\nwavelet = np.exp(2*1j*np.pi*freq2plot*time) * np.exp(-time**2 / (2*(4/(2*np.pi*freq2plot))**2))\nfft_wavelet = fft(wavelet, n_convolution)\n\nconvolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\nconvolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\n\neegtime = np.arange(0, len(eeg)) / srate\n\n# Plotting\nplt.figure(figsize=(10, 8))\n\nplt.subplot(311)\nplt.plot(eegtime, eeg)\nplt.xlabel('Time (ms)'), plt.ylabel('Broadband signal amplitude')\nplt.xlim([0, 1])\n\nplt.subplot(312)\nplt.plot(eegtime, np.real(convolution_result)) # Filtered signal from the first trial\nplt.xlabel('Time (ms)'), plt.ylabel('Filtered signal amplitude')\nplt.xlim([0, 1])\n\nplt.subplot(313)\nplt.plot(eegtime, np.abs(convolution_result)**2) # Power from the first trial\nplt.xlabel('Time (ms)'), plt.ylabel('Power')\nplt.xlim([0, 1])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 30.3\n\n# We will first test for cross-frequency coupling between two specific frequency bands\nfreq4phase = 10  # in Hz\nfreq4power = 70\n\n# Wavelet and FFT parameters\nsrate = 1000\ntime = np.arange(-1, 1 + 1/srate, 1/srate)\nhalf_of_wavelet_size = (len(time)-1)//2\nn_wavelet = len(time)\nn_data = len(eeg)\nn_convolution = n_wavelet + n_data - 1\nfft_data = fft(eeg, n_convolution)\n\n# Wavelet for phase and its FFT\nwavelet4phase = np.exp(2*1j*np.pi*freq4phase*time) * np.exp(-time**2 / (2*(4/(2*np.pi*freq4phase))**2))\nfft_wavelet4phase = fft(wavelet4phase, n_convolution)\n\n# Wavelet for power and its FFT\nwavelet4power = np.exp(2*1j*np.pi*freq4power*time) * np.exp(-time**2 / (2*(4/(2*np.pi*freq4power))**2))\nfft_wavelet4power = fft(wavelet4power, n_convolution)\n\n# Get phase values\nconvolution_result_fft = ifft(fft_wavelet4phase * fft_data, n_convolution)\nphase = np.angle(convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size])\n\n# Get power values (note: 'power' is a built-in function so we'll name this variable 'amp')\nconvolution_result_fft = ifft(fft_wavelet4power * fft_data, n_convolution)\npwr = np.abs(convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size])**2\n\n# Plot power and phase\nplt.figure(figsize=(12, 4))\n\nplt.subplot(131)\nplt.plot(eegtime, phase)\nplt.plot(eegtime, (pwr - np.mean(pwr)) / np.std(pwr), 'r')\nplt.legend(['10 Hz phase', '70 Hz power'])\nplt.xlim([0, 1])\nplt.ylim([-4, 6])\n\n# Plot power as a function of phase in polar space\nplt.subplot(132, projection='polar')\nplt.polar(phase, pwr, '.')\n\n# Plot histogram of power over phase\nn_hist_bins = 30\nphase_edges = np.linspace(np.min(phase), np.max(phase), n_hist_bins + 1)\namp_by_phases = np.zeros(n_hist_bins)\n\nfor i in range(n_hist_bins - 1):\n    amp_by_phases[i] = np.mean(pwr[(phase &gt; phase_edges[i]) & (phase &lt; phase_edges[i + 1])])\n\nplt.subplot(133)\nplt.bar(phase_edges[:-1], amp_by_phases, align='edge', width=np.diff(phase_edges)[0])\nplt.xlim([-np.pi, np.pi])\nplt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\nplt.xlabel(f'Phase at {freq4phase} Hz (rad.)')\nplt.ylabel(f'Power at {freq4power} Hz')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 30.4\n\n# Phase bias is the phase time series without the negative half of the cycle\nphase_bias = phase[phase &gt;= -np.pi/2]\n\n# Power bias is the corresponding power time series\npower_bias = pwr[phase &gt;= -np.pi/2]\n\n# Plot power as a function of phase in polar space\nplt.figure(figsize=(12, 4))\n\nplt.subplot(131, projection='polar')\nplt.polar(phase, pwr, '.')\nplt.title(f'PAC = {np.round(np.abs(np.mean(pwr * np.exp(1j * phase)))):.0f}')\n\nplt.subplot(132, projection='polar')\nplt.polar(phase, pwr * 10, '.')\nplt.title(f'PAC = {np.round(np.abs(np.mean(pwr * 10 * np.exp(1j * phase)))):.0f}')\n\nplt.subplot(133, projection='polar')\nplt.polar(phase_bias, power_bias, '.')\nplt.title(f'PAC = {np.round(np.abs(np.mean(power_bias * np.exp(1j * phase_bias)))):.0f}')\n\nplt.show()\n\n\n\n\n\n# Figure 30.5\n\n# Observed cross-frequency coupling (note the similarity to Euler's formula)\nobsPAC = np.abs(np.mean(pwr * np.exp(1j * phase)))\nobsPAC_bias = np.abs(np.mean(power_bias * np.exp(1j * phase_bias)))\n\nnum_iter = 1000\npermutedPAC = np.zeros((2, num_iter))\n\n# Permutation test\nfor i in range(num_iter):\n    # Select random time point\n    random_timepoint = np.random.choice(np.round(len(eeg) * 0.8).astype(int), 1) + np.round(len(eeg) * 0.1).astype(int)\n    random_timepoint_bias = np.random.choice(np.round(len(power_bias) * 0.8).astype(int), 1) + np.round(len(power_bias) * 0.1).astype(int)\n    \n    # Shuffle power\n    timeshiftedpwr = np.concatenate((pwr[random_timepoint[0]:], pwr[:random_timepoint[0]]))\n    timeshiftedpwr_bias = np.concatenate((power_bias[random_timepoint_bias[0]:], power_bias[:random_timepoint_bias[0]]))\n    \n    # Compute PAC\n    permutedPAC[0, i] = np.abs(np.mean(timeshiftedpwr * np.exp(1j * phase)))\n    permutedPAC[1, i] = np.abs(np.mean(timeshiftedpwr_bias * np.exp(1j * phase_bias)))\n\n# Compute PACz\npacz = np.zeros(2)\npacz[0] = (obsPAC - np.mean(permutedPAC[0, :])) / np.std(permutedPAC[0, :])\npacz[1] = (obsPAC_bias - np.mean(permutedPAC[1, :])) / np.std(permutedPAC[1, :])\n\n# Plotting\nplt.figure(figsize=(12, 8))\n\nplt.subplot(221)\nplt.hist(permutedPAC[0, :], bins=50)\nplt.axvline(obsPAC, color='m', linewidth=3)\nplt.legend(['Observed value', 'Permuted values'])\nplt.xlabel('Modulation strength'), plt.ylabel('Number of observations')\nplt.title(f'PAC_z = {pacz[0]}')\n\nplt.subplot(222)\nplt.hist(permutedPAC[1, :], bins=50)\nplt.axvline(obsPAC_bias, color='m', linewidth=3)\nplt.legend(['Observed value', 'Permuted values'])\nplt.xlabel('Modulation strength'), plt.ylabel('Number of observations')\nplt.title(f'PAC_z = {pacz[1]}')\n\n# Plot histogram of power over phase\nn_hist_bins = 30\nphase_edges = np.linspace(np.min(phase), np.max(phase), n_hist_bins + 1)\namp_by_phases = np.zeros(n_hist_bins)\n\nfor i in range(n_hist_bins - 1):\n    amp_by_phases[i] = np.mean(pwr[(phase &gt; phase_edges[i]) & (phase &lt; phase_edges[i + 1])])\n\nplt.subplot(223)\nplt.bar(phase_edges[:-1], amp_by_phases, align='edge', width=np.diff(phase_edges)[0])\nplt.xlim([-np.pi, np.pi])\nplt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\nplt.xlabel(f'Phase at {freq4phase} Hz (rad.)')\nplt.ylabel(f'Power at {freq4power} Hz')\n\n# Plot histogram of power over phase bias\nphase_edges_bias = np.linspace(np.min(phase_bias), np.max(phase_bias), n_hist_bins + 1)\namp_by_phases_bias = np.zeros(n_hist_bins)\n\nfor i in range(n_hist_bins - 1):\n    amp_by_phases_bias[i] = np.mean(power_bias[(phase_bias &gt; phase_edges_bias[i]) & (phase_bias &lt; phase_edges_bias[i + 1])])\n\nplt.subplot(224)\nplt.bar(phase_edges_bias[:-1], amp_by_phases_bias, align='edge', width=np.diff(phase_edges_bias)[0])\nplt.xlim([-np.pi, np.pi])\nplt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\nplt.xlabel(f'Phase at {freq4phase} Hz (rad.)')\nplt.ylabel(f'Power at {freq4power} Hz')\n\nplt.show()\n\n\n\n\n\n# Figure 30.6\n\n# Initialize the array to store permuted PAC values for three different permutation methods\npermutedPAC = np.zeros((3, num_iter))\n\n# Permutation tests\nfor i in range(num_iter):\n    \n    # Permutation method 1: select random time point\n    random_timepoint = np.random.choice(np.round(len(eeg) * 0.8).astype(int), 1) + np.round(len(eeg) * 0.1).astype(int)\n    timeshiftedpwr = np.concatenate((pwr[random_timepoint[0]:], pwr[:random_timepoint[0]]))\n    permutedPAC[0, i] = np.abs(np.mean(timeshiftedpwr * np.exp(1j * phase)))\n    \n    # Permutation method 2: totally randomize power time series\n    permutedPAC[1, i] = np.abs(np.mean(pwr[np.random.permutation(len(pwr))] * np.exp(1j * phase)))\n    \n    # Permutation method 3: FFT-based power time series randomization\n    f = fft(pwr)  # compute FFT\n    A = np.abs(f)  # extract amplitudes\n    zphs = np.cos(np.angle(f)) + 1j * np.sin(np.angle(f))  # extract phases\n    powernew = np.real(ifft(A * zphs[np.random.permutation(len(zphs))]))  # recombine using randomized phases\n    powernew = powernew - np.min(powernew)\n    \n    permutedPAC[2, i] = np.abs(np.mean(powernew * np.exp(1j * phase)))\n\n# Compute PACz and plot\nplt.figure(figsize=(15, 8))\n\nfor i in range(3):\n    plt.subplot(2, 3, i + 1)\n    \n    # Plot example power time series\n    if i == 0:\n        plt.plot(eegtime, timeshiftedpwr)\n        plt.title('H_0: Time-shifted')\n    elif i == 1:\n        plt.plot(eegtime, pwr[np.random.permutation(len(pwr))])\n        plt.title('H_0: Randomized')\n    elif i == 2:\n        plt.plot(eegtime, powernew)\n        plt.title('H_0: FFT-derived randomization')\n    \n    plt.xlim([0, eegtime[-1]])\n    plt.ylim([np.min(pwr), np.max(pwr)])\n    \n    # Plot null-hypothesis distribution\n    plt.subplot(2, 3, i + 4)\n    pacz = (obsPAC - np.mean(permutedPAC[i, :])) / np.std(permutedPAC[i, :])\n    y, x = np.histogram(permutedPAC[i, :], bins=50)\n    plt.bar(x[:-1], y, width=np.diff(x), align='edge')\n    plt.axvline(obsPAC, color='m', linewidth=3)\n    plt.legend(['Observed value', 'Permuted values'])\n    plt.xlabel('Modulation strength'), plt.ylabel('Number of observations')\n    plt.title(f'PAC_z = {pacz}')\n\nplt.show()\n\n\n\n\n\n# Figure 30.7\n\n# Define the time points to plot\ntimes2plot = np.arange(-200, 1201, 100)\nfreq4phase = 10  # Hz for phase\nfreq4power = 25  # Hz for power\n\ncfc_numcycles = 3  # number of cycles at phase-frequency\n\npacz = np.zeros(len(times2plot))\nitpc = np.zeros(len(times2plot))\n\n# Convert cfc times to indices\ncfc_time_window = cfc_numcycles * (1000 / freq4phase)\ncfc_time_window_idx = np.round(cfc_time_window / (1000 / EEG['srate'][0][0])).astype(int)\n\n# Other wavelet parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nhalf_of_wavelet_size = (len(time)-1)//2\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0]*EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\n\n# FFT of scalp EEG data\nfft_EEG = fft(EEG['data'][sensoridx, :, :].flatten('F'), n_convolution)\n\nfor timei, timepoint in enumerate(times2plot):\n    \n    cfc_centertime_idx = np.argmin(np.abs(EEG['times'][0] - timepoint))\n    \n    # Convolution for lower frequency phase\n    wavelet = np.exp(2 * 1j * np.pi * freq4phase * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * freq4phase))**2))\n    fft_wavelet = fft(wavelet, n_convolution)\n    convolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\n    convolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\n    lower_freq_phase = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Convolution for upper frequency power\n    wavelet = np.exp(2 * 1j * np.pi * freq4power * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * freq4power))**2))\n    fft_wavelet = fft(wavelet, n_convolution)\n    convolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\n    convolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\n    upper_freq_power = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Extract temporally localized power and phase\n    power_ts = np.abs(upper_freq_power[cfc_centertime_idx - np.floor(cfc_time_window_idx/2+0.5).astype(int):cfc_centertime_idx + np.floor(cfc_time_window_idx/2+0.5).astype(int) + 1, :])**2\n    phase_ts = np.angle(lower_freq_phase[cfc_centertime_idx - np.floor(cfc_time_window_idx/2+0.5).astype(int):cfc_centertime_idx + np.floor(cfc_time_window_idx/2+0.5).astype(int) + 1, :])\n\n    # Compute observed PAC\n    obsPAC = np.abs(np.mean(power_ts.flatten('F') * np.exp(1j * phase_ts.flatten('F'))))\n    \n    # Compute lower frequency ITPC\n    itpc[timei] = np.mean(np.abs(np.mean(np.exp(1j * phase_ts), axis=1)))\n    \n    # Permutation test\n    permutedPAC = np.zeros(num_iter)\n    for i in range(num_iter):\n        random_timepoint = np.random.choice(np.round(cfc_time_window_idx * 0.8).astype(int), EEG['trials'][0][0]) + np.round(cfc_time_window_idx * 0.1).astype(int)\n        for triali in range(EEG['trials'][0][0]):\n            power_ts[:, triali] = np.roll(power_ts[:, triali], random_timepoint[triali])\n        \n        permutedPAC[i] = np.abs(np.mean(power_ts.flatten('F') * np.exp(1j * phase_ts.flatten('F'))))\n    \n    pacz[timei] = (obsPAC - np.mean(permutedPAC)) / np.std(permutedPAC)\n\n# Plotting\nplt.figure(figsize=(10, 6))\n\nplt.subplot(211)\nplt.plot(times2plot, pacz, '-o', markerfacecolor='w')\n\n# Calculate the z-value threshold for p=0.05, correcting for multiple comparisons\nzval = norm.ppf(1 - (0.05 / len(times2plot)))\n\nplt.axhline(zval, color='k', linestyle=':')\nplt.axhline(0, color='k')\nplt.xlabel('Time (ms)'), plt.ylabel('PAC_z')\nplt.title(f'PAC_z at electrode {channel2plot} between {freq4power} Hz power and {freq4phase} Hz phase')\n\n# Also plot ITPC for comparison\nplt.subplot(212)\nplt.plot(times2plot, itpc, '-o', markerfacecolor='w')\nplt.xlabel('Time (ms)'), plt.ylabel('ITPC')\nplt.title(f'ITPC at electrode {channel2plot} at {freq4phase} Hz')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 30.8a\n\n# Define the phase frequencies to explore\nphase_freqs = np.arange(2, 21)  # Hz\ncfc_centertime = 300  # ms post-stimulus\npacz = np.zeros(len(phase_freqs))\ncfc_centertime_idx = np.argmin(np.abs(EEG['times'][0] - cfc_centertime))\n\n# Loop over phase frequencies\nfor fi, pfreq in enumerate(phase_freqs):\n    \n    # Convolution for lower frequency phase\n    wavelet = np.exp(2 * 1j * np.pi * pfreq * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * pfreq))**2))\n    fft_wavelet = fft(wavelet, n_convolution)\n    convolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\n    convolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\n    lower_freq_phase = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Extract temporally localized power and phase\n    power_ts = np.abs(upper_freq_power[cfc_centertime_idx - np.floor(cfc_time_window_idx/2+0.5).astype(int):cfc_centertime_idx + np.floor(cfc_time_window_idx/2+0.5).astype(int) + 1, :])**2\n    phase_ts = np.angle(lower_freq_phase[cfc_centertime_idx - np.floor(cfc_time_window_idx/2+0.5).astype(int):cfc_centertime_idx + np.floor(cfc_time_window_idx/2+0.5).astype(int) + 1, :])\n    \n    # Compute observed PAC\n    obsPAC = np.abs(np.mean(power_ts.flatten('F') * np.exp(1j * phase_ts.flatten('F'))))\n    \n    # Permutation test\n    num_iter = 2000\n    permutedPAC = np.zeros(num_iter)\n    for i in range(num_iter):\n        random_timepoint = np.random.choice(np.round(cfc_time_window_idx * 0.8).astype(int), EEG['trials'][0][0]) + np.round(cfc_time_window_idx * 0.1).astype(int)\n        for triali in range(EEG['trials'][0][0]):\n            power_ts[:, triali] = np.roll(power_ts[:, triali], random_timepoint[triali])\n        \n        permutedPAC[i] = np.abs(np.mean(power_ts.flatten('F') * np.exp(1j * phase_ts.flatten('F'))))\n    \n    pacz[fi] = (obsPAC - np.mean(permutedPAC)) / np.std(permutedPAC)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(phase_freqs, pacz, '-o')\nplt.xlim([phase_freqs[0] - 0.5, phase_freqs[-1] + 0.5])\nplt.xlabel('Lower frequency for phase (Hz)'), plt.ylabel('PAC_z')\nmax_phase_freq = phase_freqs[np.argmax(pacz)]\nplt.title(f'Best lower frequency phase coupled with {freq4power} Hz is {max_phase_freq} Hz')\nplt.show()\n\n\n\n\n\n# Figure 30.8b\n\n# Define the power frequencies to explore\npower_freqs = np.arange(20, EEG['srate'][0][0]/2 + 1, 5)  # Hz\npacz = np.zeros(len(power_freqs))\n\n# convolution for lower frequency phase\nwavelet = np.exp(2 * 1j * np.pi * freq4phase * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * freq4phase))**2))\nfft_wavelet = fft(wavelet, n_convolution)\nconvolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\nconvolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\nlower_freq_phase = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Loop over power frequencies\nfor fi, pwr_freq in enumerate(power_freqs):\n    \n    # Convolution for upper frequency power\n    wavelet = np.exp(2 * 1j * np.pi * pwr_freq * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * pwr_freq))**2))\n    fft_wavelet = fft(wavelet, n_convolution)\n    convolution_result = ifft(fft_wavelet * fft_EEG, n_convolution)\n    convolution_result = convolution_result[half_of_wavelet_size:-half_of_wavelet_size]\n    upper_freq_power = np.reshape(convolution_result, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Extract temporally localized power and phase\n    power_ts = np.abs(upper_freq_power[cfc_centertime_idx - np.floor(cfc_time_window_idx/2+0.5).astype(int):cfc_centertime_idx + np.floor(cfc_time_window_idx/2+0.5).astype(int) + 1, :])**2\n    phase_ts = np.angle(lower_freq_phase[cfc_centertime_idx - np.floor(cfc_time_window_idx/2+0.5).astype(int):cfc_centertime_idx + np.floor(cfc_time_window_idx/2+0.5).astype(int) + 1, :])\n    \n    # Compute observed PAC\n    obsPAC = np.abs(np.mean(power_ts.flatten('F') * np.exp(1j * phase_ts.flatten('F'))))\n    \n    # Permutation test\n    num_iter = 2000\n    permutedPAC = np.zeros(num_iter)\n    for i in range(num_iter):\n        random_timepoint = np.random.choice(np.round(cfc_time_window_idx * 0.8).astype(int), EEG['trials'][0][0]) + np.round(cfc_time_window_idx * 0.1).astype(int)\n        for triali in range(EEG['trials'][0][0]):\n            power_ts[:, triali] = np.roll(power_ts[:, triali], random_timepoint[triali])\n        \n        permutedPAC[i] = np.abs(np.mean(power_ts.flatten('F') * np.exp(1j * phase_ts.flatten('F'))))\n    \n    pacz[fi] = (obsPAC - np.mean(permutedPAC)) / np.std(permutedPAC)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(power_freqs, pacz, '-o')\nplt.xlim([power_freqs[0] - 3, power_freqs[-1] + 3])\nplt.xlabel('Upper frequency for power (Hz)'), plt.ylabel('PAC_z')\nmax_power_freq = power_freqs[np.argmax(pacz)]\nplt.title(f'Best upper frequency power coupled with {freq4phase} Hz is {max_power_freq} Hz')\nplt.show()\n\n\n\n\n\n# Figure 30.9\n\n# You have to figure this one out on your own!\n\n\n# Figure 30.10\n\n# This figure is created by combining the code for figure 30.8. You need\n# two loops, one for lower-frequency phase and one for upper-frequency\n# power. Compute PAC at each phase-power pair, and then make an image of\n# the resulting (z-scored) PAC values.\n\n\n# Figure 30.11\n\n# Define the frequencies for phase and power\nfreqs4phase = np.arange(1, 21)\nfreqs4power = np.arange(25, int(EEG['srate'][0][0] / 2) + 1)\n\n# Initialize the matrix to store the number of power cycles per phase cycle\npowcycles_per_phscycles = np.zeros((len(freqs4power), len(freqs4phase)))\n\n# Loop over phase and power frequencies\nfor phsi, pfreq in enumerate(freqs4phase):\n    for powi, pwr_freq in enumerate(freqs4power):\n        # Number of power cycles per phase cycle, scaled by sampling rate\n        powcycles_per_phscycles[powi, phsi] = (pwr_freq / pfreq) / (1000 / EEG['srate'][0][0])\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.imshow(np.log10(powcycles_per_phscycles), extent=[freqs4phase[0], freqs4phase[-1], freqs4power[0], freqs4power[-1]], aspect='auto', origin='lower', cmap='gray')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n# Figure 30.12\n\n# Define wavelet parameters\nupperfreq = 70\nlowerfreq = 12\n\n# Other wavelet parameters\ntime = np.arange(-1, 1 + 1/srate, 1/srate)\nhalf_of_wavelet_size = (len(time)-1)//2\nn_wavelet = len(time)\nn_data = len(eeg)\nn_convolution = n_wavelet + n_data - 1\n\n# FFT of data\nfft_EEG = fft(eeg, n_convolution)\n\n# Convolution for lower frequency phase (with 4 cycles)\nwaveletL = np.exp(2*1j*np.pi*lowerfreq*time) * np.exp(-time**2 / (2*(4/(2*np.pi*lowerfreq))**2))\nfft_waveletL = fft(waveletL, n_convolution)\nconvolution_resultL = ifft(fft_waveletL * fft_EEG, n_convolution)\nlowerfreq_phase = np.angle(convolution_resultL[half_of_wavelet_size:-half_of_wavelet_size])\n\n# Convolution for upper frequency (with 4 cycles)\nwaveletH = np.exp(2*1j*np.pi*upperfreq*time) * np.exp(-time**2 / (2*(4/(2*np.pi*upperfreq))**2))\nfft_waveletH = fft(waveletH, n_convolution)\nconvolution_resultH = ifft(fft_waveletH * fft_EEG, n_convolution)\nupperfreq_amp = np.abs(convolution_resultH[half_of_wavelet_size:-half_of_wavelet_size])\n\n# Filter the upper frequency power in the lower frequency range\nconvolution_result_filtered = ifft(fft_waveletL * fft(upperfreq_amp, n_convolution), n_convolution)\nupperfreq_amp_phase = np.angle(convolution_result_filtered[half_of_wavelet_size:-half_of_wavelet_size])\n\n# Plotting\nplt.figure(figsize=(12, 10))\n\nplt.subplot(411)\nplt.plot(eegtime, lowerfreq_phase)\nplt.xlim([0, 2])\nplt.title(f'{lowerfreq} Hz phase')\n\nplt.subplot(412)\nplt.plot(eegtime, upperfreq_amp)\nplt.xlim([0, 2])\nplt.title(f'{upperfreq} Hz power')\n\nplt.subplot(413)\nplt.plot(eegtime, np.real(convolution_result_filtered[half_of_wavelet_size:-half_of_wavelet_size]))\nplt.xlim([0, 2])\nplt.title(f'{upperfreq} Hz power filtered at {lowerfreq} Hz')\n\nplt.subplot(414)\nplt.plot(eegtime, upperfreq_amp_phase)\nplt.plot(eegtime, lowerfreq_phase, 'r')\nplt.legend(['Upper', 'Lower'])\nplt.xlim([0, 2])\nplt.title(f'Phase of {lowerfreq} Hz component in {upperfreq} Hz power')\n\nplt.tight_layout()\nplt.show()\n\n# Compute synchronization\nphasephase_synch = np.abs(np.mean(np.exp(1j * (lowerfreq_phase - upperfreq_amp_phase))))\nprint(f'Phase-phase coupling between {lowerfreq} Hz and {upperfreq} Hz is {phasephase_synch:.5f}')\n\n\n\n\nPhase-phase coupling between 12 Hz and 70 Hz is 0.27535"
  },
  {
    "objectID": "chapter12.html",
    "href": "chapter12.html",
    "title": "Chapter 12",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 12 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.signal import firls, filtfilt\nfrom scipy.fft import fft, ifft\n\n\n# Figure 12.1\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define time and frequency for the sine wave\ntime = np.arange(-1, 1 + 1/EEG['srate'], 1/EEG['srate'])\nf = 4  # frequency of sine wave in Hz\n\n# Create sine wave (actually, a cosine wave)\nsine_wave = np.cos(2 * np.pi * f * time)\n\n# Make a Gaussian\ns = 4 / (2 * np.pi * f)\ngaussian_win = np.exp(-time**2 / (2 * s**2))\n\n# Plot the sine wave multiplied by the Gaussian window\nplt.figure()\nplt.plot(time, sine_wave * gaussian_win)\nplt.show()\n\n\n\n\n\n# Figure 12.2\n\n# Plotting EEG data and sine waves with different envelopes\nplt.figure(figsize=(10, 8))\n\n# Plot EEG data from one electrode and one trial\nplt.subplot(511)\nplt.plot(np.squeeze(EEG['data'][46,:,0]))\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('EEG data (electrode 47, trial 1)')\n\n# Plot sine wave at 12 Hz\nplt.subplot(512)\nsine_wave = np.cos(2 * np.pi * 12 * time)\nplt.plot(sine_wave)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('12 Hz sine wave')\n\n# Plot sine wave with boxcar envelope (short duration)\nplt.subplot(513)\nboxcar = np.zeros_like(sine_wave)\nmidpoint = (len(time) - 1) // 2\nboxcar[midpoint - round(EEG['srate'][0,0] / 12 / 5):midpoint + round(EEG['srate'][0,0] / 12 / 1.25)] = 1\nplt.plot(sine_wave * boxcar)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('Sine wave with short boxcar envelope')\n\n# Plot sine wave with boxcar envelope (long duration)\nplt.subplot(514)\nboxcar = np.zeros_like(sine_wave)\nboxcar[midpoint - 50:midpoint + 50] = 1\nplt.plot(sine_wave * boxcar)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('Sine wave with long boxcar envelope')\n\n# Plot sine wave with Gaussian envelope\nplt.subplot(515)\ns = 1.5 / (2 * np.pi * 12)\ngaussian_win = np.exp(-time**2 / (2 * s**2))\nplt.plot(time, sine_wave * gaussian_win)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('Sine wave with Gaussian envelope')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 12.3\n\n# Create a complex wavelet and plot its components\nsrate = 500  # sampling rate in Hz\nf = 10  # frequency of the sine wave in Hz\ntime = np.arange(-1, 1 + 1/srate, 1/srate)  # time vector\n\n# Create a complex sine wave (wavelet)\nsine_wave = np.exp(2 * np.pi * 1j * f * time)\n\n# Make a Gaussian\ns = 6 / (2 * np.pi * f)\ngaussian_win = np.exp(-time**2 / (2 * s**2))\n\n# Combine sine wave and Gaussian to create a wavelet\nwavelet = sine_wave * gaussian_win\n\n# Plot each component and the wavelet\nplt.figure(figsize=(8, 6))\n\nplt.subplot(311)\nplt.plot(time, np.real(sine_wave))\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('Sine wave')\n\nplt.subplot(312)\nplt.plot(time, gaussian_win)\nplt.gca().autoscale(enable=True, axis='both', tight=True)\nplt.title('Gaussian window')\n\nplt.subplot(313)\nplt.plot(time, np.real(wavelet))\nplt.title('My first wavelet!')\nplt.xlim([-1, 1])\nplt.ylim([-1, 1])\nplt.xlabel('Time (ms)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 12.4\n\n# Create a family of wavelets\nnum_wavelets = 80\nlowest_frequency = 2\nhighest_frequency = 100\n\n# Define frequencies\nfrequencies = np.linspace(lowest_frequency, highest_frequency, num_wavelets)\n\n# Plot frequency order vs. frequency in Hz\nplt.figure()\nplt.plot(frequencies, '-*')\nplt.xlabel('Frequency order')\nplt.ylabel('Frequency in Hz')\nplt.show()\n\n# Initialize wavelet family\nwavelet_family = np.zeros((num_wavelets, len(time)), dtype=complex)\n\n# Loop through frequencies and create wavelets\nfor fi in range(num_wavelets):\n    sinewave = np.exp(2 * 1j * np.pi * frequencies[fi] * time)\n    gaus_win = np.exp(-time**2 / (2 * (6 / (2 * np.pi * frequencies[fi]))**2))\n    wavelet_family[fi, :] = sinewave * gaus_win\n\n# Plot a few wavelets\nplt.figure(figsize=(8, 6))\n\nplt.subplot(211)\nplt.plot(time, np.real(wavelet_family[::round(np.random.rand() * 30), :]).T)\nplt.xlim([-1, 1])\nplt.ylim([-1, 1])\nplt.title('A few wavelets...')\n\nplt.subplot(212)\nplt.plot(time, np.real(wavelet_family[29, :]))\nplt.plot(time, np.imag(wavelet_family[29, :]), ':')\nplt.xlim([-1, 1])\nplt.ylim([-1, 1])\nplt.title('Real and imaginary parts of one wavelet')\nplt.legend(['real', 'imaginary'])\n\nplt.tight_layout()\nplt.show()\n\n# Image the wavelet family\nplt.figure()\nplt.imshow(np.real(wavelet_family), aspect='auto', extent=[time[0], time[-1], frequencies[0], frequencies[-1]], origin='lower')\nplt.xlabel('Time (s)')\nplt.ylabel('Frequency (Hz)')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# Figure 12.5\n\n# EEG data from one trial (electrode FCz)\neegdata = EEG['data'][46, :, 9]\n\n# Create wavelet\ntime = np.arange(-1, 1+1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nf = 6  # frequency of sine wave in Hz\nsine_wave = np.exp(1j * 2 * np.pi * f * time)\ns = 4.5 / (2 * np.pi * f)\ngaussian_win = np.exp(-time**2 / (2 * s**2))\nwavelet = sine_wave * gaussian_win\nhalfwaveletsize = int(np.ceil(len(wavelet) / 2))\n\n# Convolve with data\nn_conv = len(wavelet) + EEG['pnts'][0, 0] - 1\nfft_w = fft(wavelet, n_conv)\nfft_e = fft(eegdata, n_conv)\nift = ifft(fft_e * fft_w, n_conv) * np.sqrt(s) / 10  # empirical scaling factor\nwavelet_conv_data = np.real(ift[halfwaveletsize-1:-halfwaveletsize+1])\n\n# Create filter and apply to data\nnyquist = EEG['srate'][0, 0] / 2\ntransition_width = 0.2  # percent\nfilter_low = 4  # Hz\nfilter_high = 8  # Hz\nffrequencies = [0, filter_low * (1 - transition_width), filter_low, filter_high, filter_high * (1 + transition_width), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(round(3 * (EEG['srate'][0, 0] / filter_low))+1, ffrequencies, idealresponse)\neeg_4to8 = filtfilt(filterweights, 1, eegdata)\n\n# Plot raw data, wavelet convolved data, and band-pass filtered data\nplt.figure()\nplt.plot(EEG['times'][0], eegdata)\nplt.plot(EEG['times'][0], wavelet_conv_data, 'r', linewidth=2)\nplt.plot(EEG['times'][0], eeg_4to8, 'm', linewidth=2)\nplt.xlim([-200, 1200])\nplt.ylim([-50, 40])\nplt.xlabel('Time (ms)')\nplt.ylabel('Voltage (µV)')\nplt.gca().invert_yaxis()\nplt.legend(['Raw data', 'Wavelet convolved', 'Band-pass filtered'])\nplt.show()\n\n\n\n\n\n# Figure 12.6\n\n# Make a theta-band-centered wavelet\ntime = np.arange(-1, 1+1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nn_conv = EEG['pnts'][0, 0] + len(time) - 1\nn2p1 = n_conv // 2 + 1\n\nf = 6\ns = 6 / (2 * np.pi * f)\nwavelet = np.exp(2 * np.pi * 1j * f * time) * np.exp(-time**2 / (2 * s**2))\nhalfwaveletsize = int(np.ceil(len(wavelet) / 2))\n\neegdata = EEG['data'][46,:,9]\n\nplt.figure(figsize=(10, 8))\n\nplt.subplot(311)\nplt.plot(EEG['times'][0], eegdata)\nplt.xlim([-500, 1200])\nplt.ylim([-50, 50])\n\nplt.subplot(323)\nfft_w = fft(wavelet, n_conv)\nhz = np.linspace(0, EEG['srate'][0, 0] / 2, n2p1)\nplt.plot(hz, np.abs(fft_w[:n2p1]) / np.max(np.abs(fft_w[:n2p1])), 'k')\n\nfft_e = fft(eegdata, n_conv)\nplt.plot(hz, np.abs(fft_e[:n2p1]) / np.max(np.abs(fft_e[:n2p1])), 'r')\nplt.xlim([0, 40])\nplt.ylim([0, 1.05])\nplt.title('Individual power spectra')\n\nplt.subplot(324)\nplt.plot(hz, np.abs(fft_e[:n2p1]) * np.abs(fft_w[:n2p1]))\nplt.xlim([0, 40])\n\nplt.subplot(313)\nplt.plot(EEG['times'][0], eegdata)\nift = ifft(fft_e * fft_w, n_conv) * np.sqrt(s) / 10\nplt.plot(EEG['times'][0], np.real(ift[halfwaveletsize-1:-halfwaveletsize+1]), 'r')\nplt.xlim([-500, 1200])\nplt.ylim([-50, 50])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 12.7\n\n# Create 10 Hz wavelet (kernel)\ntime = np.arange(-(EEG['pnts'][0, 0]/EEG['srate'][0, 0]/2), EEG['pnts'][0, 0]/EEG['srate'][0, 0]/2, 1/EEG['srate'][0, 0])\nf = 10  # frequency of sine wave in Hz\ns = 4 / (2 * np.pi * f)\nwavelet = np.cos(2 * np.pi * f * time) * np.exp(-time**2 / (2 * s**2))\n\n# Signal is one sine cycle\ntimeS = np.arange(0, 1/f, 1/EEG['srate'][0, 0])\nsignal = np.sin(2 * np.pi * f * timeS)\n\n# Zero-pad signal\nsignal = np.concatenate((np.zeros(EEG['pnts'][0, 0]//2 - len(timeS)//2), signal, np.zeros(EEG['pnts'][0, 0]//2 - len(timeS)//2)))\n\nplt.figure(figsize=(10, 8))\n\n# Plot wavelet\nplt.subplot(321)\nplt.plot(wavelet)\nplt.xlim([200, len(time) - 200])\n\n# Plot signal\nplt.subplot(323)\nplt.plot(signal)\nplt.xlim([200, len(time) - 200])\n\n# Plot convolution of wavelet and signal\nplt.subplot(325)\nplt.plot(np.convolve(wavelet, signal, 'same'))\nplt.xlim([200, len(time) - 200])\nplt.ylim([-12, 12])\n\n# Plot dot products at selected phase lags\nplt.subplot(322)\nplt.plot(wavelet[round(100/f)-2:], 'r')\nplt.plot(signal)\nplt.xlim([200, len(time) - 200])\nplt.title(f'Dot product: {int(np.fix(np.sum(wavelet[round(100/f)-3:] * signal[:-round(100/f)+3])))}')\n\nplt.subplot(324)\nplt.plot(wavelet[round(2.3*(100/f)-2):], 'r')\nplt.plot(signal)\nplt.xlim([200, len(time) - 200])\nplt.title(f'Dot product: {int(np.fix(np.sum(wavelet[round(2.3*(100/f)-3):] * signal[:-round(2.3*(100/f)-3)])))}')\n\nplt.subplot(326)\nplt.plot(wavelet, 'r')\nplt.plot(signal)\nplt.xlim([200, len(time) - 200])\nplt.title(f'Dot product: {int(np.fix(np.sum(wavelet * signal)))}')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter09.html",
    "href": "chapter09.html",
    "title": "Chapter 9",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 9 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\n# Note: The following code requires the MNE library for topographical plotting.\n# If MNE is not installed, you can install it using pip:\n# %pip install mne\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.interpolate import griddata\nfrom scipy.signal import filtfilt, firls\nfrom mne import create_info, EvokedArray\nfrom mne.channels import make_dig_montage\n\n\n# Figure 9.1a\n\n# Load EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Plot a few trials from one channel\nwhich_channel_to_plot = 'FCz'\nchannel_index = EEG['chanlocs'][0]['labels']==which_channel_to_plot\nx_axis_limit = [-200, 1000]  # in ms\nnum_trials2plot = 12\n\nfig, axs = plt.subplots(int(np.ceil(num_trials2plot / np.ceil(np.sqrt(num_trials2plot)))), \n                        int(np.ceil(np.sqrt(num_trials2plot))), figsize=(12, 8))\naxs = axs.flatten()\n\nfor i in range(num_trials2plot):\n    random_trial = np.random.choice(EEG['trials'][0][0], 1)\n    axs[i].plot(EEG['times'][0], EEG['data'][channel_index, :, random_trial].flatten())\n    axs[i].set_xlim(x_axis_limit)\n    axs[i].set_title(f'Trial {random_trial[0]+1}')\n    axs[i].set_yticklabels([])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 9.1b\n\nplt.figure(figsize=(10, 5))\n# Plot all trials\nplt.plot(EEG['times'][0], np.squeeze(EEG['data'][channel_index, :, :]), 'y')\n# plot ERP (simply the average time-domain signal)\nplt.plot(EEG['times'][0], np.squeeze(np.mean(EEG['data'][channel_index, :, :], axis=2)), 'k')\nplt.xlim([-300, 1000])\nplt.ylim([-60, 60])\nplt.gca().invert_yaxis()\nplt.show()\n\n# Plot ERP (Event-Related Potential)\n\nplt.figure(figsize=(10, 5))\nplt.plot(EEG['times'][0], np.squeeze(np.mean(EEG['data'][channel_index, :, :], axis=2)), 'k', linewidth=2)\nplt.axhline(0, color='k')\nplt.axvline(0, color='k', linestyle=':')\nplt.xlim([-300, 1000])\nplt.ylim([-3, 7])\nplt.xlabel('Time (ms)')\nplt.ylabel('Voltage (μV)')\nplt.title(f'ERP from electrode {EEG[\"chanlocs\"][0][channel_index][0][0]}')\nplt.gca().invert_yaxis()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 9.2\n\n# Plot filtered ERPs\nchan2plot = 'P7'\n\nerp = np.squeeze(np.mean(EEG['data'][EEG['chanlocs'][0]['labels']==chan2plot, :, :], axis=2))\n\n# Define filter parameters\nnyquist = EEG['srate'][0][0] / 2\ntransition_width = 0.15 # percent\n\n# Filter from 0-40 Hz\nfilter_cutoff = 40\nffrequencies = [0, filter_cutoff, filter_cutoff * (1 + transition_width), nyquist] / nyquist\nidealresponse = [1, 1, 0, 0]\nfilterweights = firls(101, ffrequencies, idealresponse)\nerp_0to40 = filtfilt(filterweights, 1, erp)\n\n# Filter from 0-10 Hz\nfilter_cutoff = 10\nffrequencies = [0, filter_cutoff, filter_cutoff * (1 + transition_width), nyquist] / nyquist\nidealresponse = [1, 1, 0, 0]\nfilterweights = firls(101, ffrequencies, idealresponse)\nerp_0to10 = filtfilt(filterweights, 1, erp)\n\n# Filter from 5-15 Hz\nfilter_low = 5\nfilter_high = 15\nffrequencies = [0, filter_low * (1 - transition_width), filter_low, filter_high, filter_high * (1 + transition_width), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(round(3 * (EEG['srate'][0][0] / filter_low)) + 1, ffrequencies, idealresponse)\nerp_5to15 = filtfilt(filterweights, 1, erp)\n\n# Plot all filtered ERPs\nplt.figure(figsize=(8, 6))\nplt.plot(EEG['times'][0], erp, 'k', label='None')\nplt.plot(EEG['times'][0], erp_0to40, 'b', linewidth=2, label='0-40 Hz')\nplt.plot(EEG['times'][0], erp_0to10, 'r', label='0-10 Hz')\nplt.plot(EEG['times'][0], erp_5to15, 'm', label='5-15 Hz')\nplt.xlim([-200, 1200])\nplt.xlabel('Time (ms)')\nplt.ylabel('Voltage (μV)')\nplt.title(f'ERP from electrode {chan2plot}')\nplt.legend()\nplt.gca().invert_yaxis()\nplt.show()\n\n\n\n\n\n# Figure 9.3\n\nplt.figure(figsize=(10, 8))\n\n# Butterfly plot\nplt.subplot(2, 1, 1)\nplt.plot(EEG['times'][0], np.squeeze(np.mean(EEG['data'], axis=2)).T)\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Voltage (μV)')\nplt.title('ERP from all sensors')\nplt.gca().invert_yaxis()\n\n# Topographical variance plot\nplt.subplot(2, 1, 2)\nplt.plot(EEG['times'][0], np.var(np.mean(EEG['data'], axis=2), axis=0))\nplt.xlim([-200, 1000])\nplt.xlabel('Time (ms)')\nplt.ylabel('Variance (μV²)')\nplt.title('Topographical variance')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 9.4\n\nc = -np.mean(EEG['data'][:, 299, :], axis=1)\nc = c - np.min(c)\nc = c / np.max(c)\nc = np.tile(c, (3, 1))\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# note that we flip the y-coordinate here to match the Matlab figure\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(chan_labels, EEG['srate'], ch_types='eeg')\nevoked1 = EvokedArray(np.zeros((64, 1)), info, tmin=EEG['xmin'][0][0])\nevoked1.set_montage(montage)\nevoked2 = EvokedArray(c[0, :, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked2.set_montage(montage)\n\n# Plot using MNE's topomap function\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nevoked2.plot_topomap(sensors=False, contours=0, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='gray', axes=ax[1], show=False, times=-1, time_format='', colorbar=False)\nevoked1.plot_topomap(sensors=False, contours=0, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='gray', vlim=ax[1].get_images()[0].get_clim(), axes=ax[0], show=False, times=-1, time_format='', colorbar=False)\n\n# Plot the sensors using scatter\nfor i in range(len(coords)):\n    ax[0].scatter(coords[i, 0], coords[i, 1], s=20, c=[c[0, i]], marker='o', cmap='gray', vmin=0, vmax=1, edgecolors='none')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Introduction to topographical plotting\n\ndef pol2cart(theta, radius):\n    \"\"\"Convert polar coordinates to Cartesian.\"\"\"\n    x = radius * np.cos(theta)\n    y = radius * np.sin(theta)\n    return x, y\n\ntimepoint2plot = 100  # in ms\ntrial2plot = 97#np.random.choice(EEG['trials'][0][0], 1)[0]\ncolor_limit = 20  # more-or-less arbitrary, but this is a good value\n\n# Convert time point from ms to index\ntimepointidx = np.argmin(np.abs(EEG['times'][0] - timepoint2plot))\n\n# Get X and Y coordinates of electrodes\nth = np.pi / 180 * np.array([chan['theta'] for chan in EEG['chanlocs'][0]])\nradii = np.array([chan['radius'] for chan in EEG['chanlocs'][0]])\nelectrode_locs_X, electrode_locs_Y = pol2cart(th, radii)\n\n# Flatten the electrode location arrays\nelectrode_locs_X = electrode_locs_X.flatten()\nelectrode_locs_Y = electrode_locs_Y.flatten()\n\n# Interpolate to get a nice surface\ninterpolation_level = 100\ninterpX = np.linspace(min(electrode_locs_X), max(electrode_locs_X), interpolation_level)\ninterpY = np.linspace(min(electrode_locs_Y), max(electrode_locs_Y), interpolation_level)\n\n# meshgrid is a function that creates 2D grid locations based on 1D inputs\ngridX, gridY = np.meshgrid(interpX, interpY)\n\n# Let's look at these matrices\nplt.figure()\nplt.subplot(121)\nplt.imshow(gridX, cmap='viridis')\n\nplt.subplot(122)\nplt.imshow(gridY)\nplt.tight_layout()\nplt.show()\n\n# Interpolate the data on a 2D grid\ninterpolated_EEG_data = griddata((electrode_locs_X, electrode_locs_Y), EEG['data'][:, timepointidx, trial2plot], (gridX, gridY), method='cubic')\n\n# Plot the interpolated data\nfig, axs = plt.subplots(1, 2, figsize=(12, 6))\nim = axs[0].contourf(interpY, interpX, interpolated_EEG_data.T, 100, cmap='jet', vmin=-color_limit, vmax=color_limit)\naxs[0].set_title('Interpolated data in Python')\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(chan_labels, EEG['srate'], ch_types='eeg')\nevoked = EvokedArray(EEG['data'][:, timepointidx, trial2plot, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\n\n# Plot using MNE's topomap function\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(-color_limit*1000000, color_limit*1000000), axes=axs[1], show=False, times=-1, time_format='', colorbar=False)\naxs[1].set_title('Topomap using MNE')\n\nplt.show()\n\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\n\n# Plot the surface\nsurf = ax.plot_surface(gridX, gridY, interpolated_EEG_data.T, cmap='jet', linewidth=0, antialiased=False)\nsurf.set_clim(-color_limit, color_limit)\nax.set_xlabel('left-right of scalp')\nax.set_ylabel('anterior-posterior of scalp')\nax.set_zlabel('μV')\nax.view_init(elev=25, azim=-45)\nax.set_xlim([np.min(interpY) * 1.1, np.max(interpY) * 1.1])\nax.set_ylim([np.min(interpX) * 1.1, np.max(interpX) * 1.1])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# Figure 9.5\n\ntimes2plot = [np.argmin(np.abs(EEG['times'][0] - t)) for t in np.arange(-100, 650, 50)]\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(chan_labels, EEG['srate'], ch_types='eeg')\nevoked = EvokedArray(np.mean(EEG['data'], axis=2) , info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\n\n# Plot the topomaps\nfig, axs = plt.subplots(3, 5, figsize=(15, 10))\nfor i, time_point in enumerate(times2plot):\n    ax = axs[i // 5, i % 5]  # Determine the subplot position\n    # Introduce a random noise to the FC4 channel at the specific time point\n    evoked.data[EEG['chanlocs'][0]['labels']=='FC4', time_point] = np.random.randn() * 10\n    # Plot the topomap\n    evoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=(-8000000, 8000000), axes=ax, show=False, times=evoked.times[time_point], colorbar=False)\n    ax.set_title(f'{round(evoked.times[time_point]*1000)} ms')  # Convert seconds back to milliseconds for the title\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 9.6\n\nuseRTs = True  # Change to False to sort by EEG data\n\n# Get RTs from each trial\nrts = np.array([epoch['eventlatency'][0][np.where(np.array(epoch['eventlatency'][0]) == 0)[0][0] + 1][0][0] for epoch in EEG['epoch'][0]])\n\n# Find the sorting indices for RTs\nif useRTs:\n    rts_idx = np.argsort(rts)\nelse:\n    rts_idx = np.argsort(EEG['data'][46, 333, :])\n\n# Plot sorted data\nplt.figure(figsize=(12, 8))\nplt.imshow(EEG['data'][46, :, rts_idx], aspect='auto', extent=[min(EEG['times'][0]), max(EEG['times'][0]), 1, EEG['trials'][0][0]], vmin=-30, vmax=30, origin=\"lower\", cmap='viridis')\nplt.xlim([-200, 1200])\nplt.xlabel('Time (ms)')\nplt.ylabel('Trials (sorted)')\nplt.colorbar(label='Voltage (μV)')\n\n# Also plot the RTs on each trial\nif useRTs:\n    plt.plot(rts[rts_idx], np.arange(1, EEG['trials'][0][0] + 1), 'k', linewidth=3)\nplt.show()"
  },
  {
    "objectID": "chapter04a.html",
    "href": "chapter04a.html",
    "title": "Chapter 4a",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 4 script A – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\n\n\n# Variables, part I\n\n# Let's start with variables. To create a variable, you simply assign it information. \n# For example,\n\nmike = 10\nbob = 20\n\n# If you type these in their own cell and run it (or run this cell), you will create the variables.\n# Because the variables refer to numbers, ou can add them, multiply them, etc:\nmike + bob # Note: You can also put comments after code\nprint((mike + bob) / (mike - bob))\n\n# Notice that when the result is by itself, the output is suppressed, \n# and when there is a 'print' statement, it outputs the results.\n\n# Variables can also be strings:\nmike = 'mike' \nprint(mike)\n# Now we've re-assigned mike from a number to a string.\n# Type 'whos' into the a new cell (this command is only avaliable in IPython).\n\n\n# You can also assign arrays to variables:\na_simple_matrix = np.array([[3, 4, 5], [1, 2, 3], [9, 8, 7]])\n\n# String and list concatenation:\nmikes_full_name = mike + ' cohen'\nmikes_two_fav_numbers = [7] + [23]\n\n# Type whos in the command to see the properties of our variables.\n# Note the difference between the numpy array and the list.\n\n-3.0\nmike\nVariable   Type      Data/Info\n------------------------------\nbob        int       20\nmike       str       mike\nnp         module    &lt;module 'numpy' from '/Us&lt;...&gt;kages/numpy/__init__.py'&gt;\n\n\n\n# %% Variables, part II\n\n# Variables can be more sophisticated. Variables can be lists or dictionaries, which\n# are like blocks that may contain different kinds of information. \nvar1 = [np.array([1, 2, 3, 4, 5, 6, 7]), 'hello world', np.array([1, 3, 6, 7, 4, 3, 5, 6, 7, 87, 76, 43, 4, 5, 6, 767])]\n\nprint(var1)\nprint(var1[1]) # Python is zero-indexed (where Matlab is one-indexed), so the first element is 0, the second is 1, etc.\n\n# Another type of variable is a dictionary. Dictionaries contain keys that \n# are used for different kinds of data. For example:\n\nANTS = [{'name': 'mike', 'position': 'author', 'favorite_toothpaste_flavor': 'cinnamon', 'number_of_watches': 18, 'favorite_color': [0.8, 0.1, 0.8]}]\n\n# You can also have a list of dictionaries\nANTS.append({'name': 'Your name here', 'position': 'reader', 'favorite_toothpaste_flavor': 'bratworst', 'number_of_watches': 1, 'favorite_color': [1, 1, 1]})\n\n# Now you can get information about all keys from one specific element of\n# the dictionary:\nprint(ANTS[0])\n\n# Or information about one key within one member:\nprint(ANTS[0]['number_of_watches'])\n\n# Or information about one key from all members (dictionaries are similar to Python structs,\n# but we have to use a loop for a list of dictionaries to get all the values):\nfor ant in ANTS:\n    print(ant['favorite_toothpaste_flavor'])\n\n# Note that this last result came out as two separate answers. If you want\n# to combine them into a single output (e.g., a list), use square brackets (called list comprehension):\nprint([favorite_flavor['favorite_toothpaste_flavor'] for favorite_flavor in ANTS])\n\n[array([1, 2, 3, 4, 5, 6, 7]), 'hello world', array([  1,   3,   6,   7,   4,   3,   5,   6,   7,  87,  76,  43,   4,\n         5,   6, 767])]\nhello world\n{'name': 'mike', 'position': 'author', 'favorite_toothpaste_flavor': 'cinnamon', 'number_of_watches': 18, 'favorite_color': [0.8, 0.1, 0.8]}\n18\ncinnamon\nbratworst\n['cinnamon', 'bratworst']\n\n\n\nround(np.random.rand(1)[0] * 10)\n\n3\n\n\n\n# Functions\n\n# Functions are modular pieces of code that can be stored in a separate file or within the same script. \n# Most Python functions defined in scripts or modules (.py files) are viewable and editable. \n# Some functions are part of compiled extension modules or built-in functions, and their source code \n# may not be directly editable from within Python, but the source is often available online for open-source libraries.\n\n# Functions may take inputs:\nprint(np.random.permutation(4) + 1) # permutation is a function from numpy's random module that randomly permutes integers. 4 is the input.\n\n# Or a list:\nprint(np.mean([1, 3, 2, 4, 3, 5, 4, 6]))\n\n# Most functions also give outputs:\npermuted_integers = np.random.permutation(4) + 1  # now the output of the function is stored in a new variable\n\n# Some functions can have multiple inputs: \nrandom_number_matrix = np.random.rand(4, 6)  # Here, we asked for a 4 x 6 matrix of random numbers\n\n# Some functions have multiple outputs:\nunique_elements, indices, inverse_indices, counts = np.unique(np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4]), return_index=True, return_inverse=True, return_counts=True)\n# This also shows list indexing, which we'll get to soon.\n\n# IMPORTANT: You can use the output of one function as the input to another\n# function. This is a powerful way to make your programming fast and\n# efficient. On the other hand, if you embed functions to an extreme you\n# might create unreadable code.\nmax_value = np.max(np.random.permutation(round(np.random.rand(1)[0] * 10) + 1))\n\n# Use the help() function in Python to read about a function.\nhelp(np.max)\n\n[4 3 1 2]\n3.5\nHelp on function amax in module numpy:\n\namax(a, axis=None, out=None, keepdims=&lt;no value&gt;, initial=&lt;no value&gt;, where=&lt;no value&gt;)\n    Return the maximum of an array or maximum along an axis.\n    \n    Parameters\n    ----------\n    a : array_like\n        Input data.\n    axis : None or int or tuple of ints, optional\n        Axis or axes along which to operate.  By default, flattened input is\n        used.\n    \n        .. versionadded:: 1.7.0\n    \n        If this is a tuple of ints, the maximum is selected over multiple axes,\n        instead of a single axis or all the axes as before.\n    out : ndarray, optional\n        Alternative output array in which to place the result.  Must\n        be of the same shape and buffer length as the expected output.\n        See :ref:`ufuncs-output-type` for more details.\n    \n    keepdims : bool, optional\n        If this is set to True, the axes which are reduced are left\n        in the result as dimensions with size one. With this option,\n        the result will broadcast correctly against the input array.\n    \n        If the default value is passed, then `keepdims` will not be\n        passed through to the `amax` method of sub-classes of\n        `ndarray`, however any non-default value will be.  If the\n        sub-class' method does not implement `keepdims` any\n        exceptions will be raised.\n    \n    initial : scalar, optional\n        The minimum value of an output element. Must be present to allow\n        computation on empty slice. See `~numpy.ufunc.reduce` for details.\n    \n        .. versionadded:: 1.15.0\n    \n    where : array_like of bool, optional\n        Elements to compare for the maximum. See `~numpy.ufunc.reduce`\n        for details.\n    \n        .. versionadded:: 1.17.0\n    \n    Returns\n    -------\n    amax : ndarray or scalar\n        Maximum of `a`. If `axis` is None, the result is a scalar value.\n        If `axis` is an int, the result is an array of dimension\n        ``a.ndim - 1``. If `axis` is a tuple, the result is an array of \n        dimension ``a.ndim - len(axis)``.\n    \n    See Also\n    --------\n    amin :\n        The minimum value of an array along a given axis, propagating any NaNs.\n    nanmax :\n        The maximum value of an array along a given axis, ignoring any NaNs.\n    maximum :\n        Element-wise maximum of two arrays, propagating any NaNs.\n    fmax :\n        Element-wise maximum of two arrays, ignoring any NaNs.\n    argmax :\n        Return the indices of the maximum values.\n    \n    nanmin, minimum, fmin\n    \n    Notes\n    -----\n    NaN values are propagated, that is if at least one item is NaN, the\n    corresponding max value will be NaN as well. To ignore NaN values\n    (MATLAB behavior), please use nanmax.\n    \n    Don't use `amax` for element-wise comparison of 2 arrays; when\n    ``a.shape[0]`` is 2, ``maximum(a[0], a[1])`` is faster than\n    ``amax(a, axis=0)``.\n    \n    Examples\n    --------\n    &gt;&gt;&gt; a = np.arange(4).reshape((2,2))\n    &gt;&gt;&gt; a\n    array([[0, 1],\n           [2, 3]])\n    &gt;&gt;&gt; np.amax(a)           # Maximum of the flattened array\n    3\n    &gt;&gt;&gt; np.amax(a, axis=0)   # Maxima along the first axis\n    array([2, 3])\n    &gt;&gt;&gt; np.amax(a, axis=1)   # Maxima along the second axis\n    array([1, 3])\n    &gt;&gt;&gt; np.amax(a, where=[False, True], initial=-1, axis=0)\n    array([-1,  3])\n    &gt;&gt;&gt; b = np.arange(5, dtype=float)\n    &gt;&gt;&gt; b[2] = np.NaN\n    &gt;&gt;&gt; np.amax(b)\n    nan\n    &gt;&gt;&gt; np.amax(b, where=~np.isnan(b), initial=-1)\n    4.0\n    &gt;&gt;&gt; np.nanmax(b)\n    4.0\n    \n    You can use an initial value to compute the maximum of an empty slice, or\n    to initialize it to a different value:\n    \n    &gt;&gt;&gt; np.amax([[-50], [10]], axis=-1, initial=0)\n    array([ 0, 10])\n    \n    Notice that the initial value is used as one of the elements for which the\n    maximum is determined, unlike for the default argument Python's max\n    function, which is only used for empty iterables.\n    \n    &gt;&gt;&gt; np.amax([5], initial=6)\n    6\n    &gt;&gt;&gt; max([5], default=6)\n    5\n\n\n\n\n# Indexing\n\n# Indexing is a powerful tool in Python to access particular parts of a\n# variable. Indexing is very simple: Imagine you have 100 twinkies arranged\n# in a 10 x 10 square: \ntwinkies = np.random.rand(10, 10)\nprint(twinkies)\n\n# If you wanted to eat the twinkie in the 4th row, 8th column, you write:\nthe_twinkie_i_will_eat = twinkies[3, 7]  # Note that Python uses 0-based indexing\n\n[[0.71680002 0.91444112 0.85337882 0.69393486 0.53377898 0.10552462\n  0.8325251  0.32966788 0.60414777 0.43907981]\n [0.60223129 0.19649738 0.11138368 0.71313554 0.97254411 0.29302234\n  0.50892182 0.06174653 0.29760079 0.18459811]\n [0.86871296 0.67628576 0.72403987 0.32141214 0.62569337 0.26442655\n  0.37324339 0.35766801 0.94052991 0.12013302]\n [0.95698372 0.01533838 0.87996818 0.36103708 0.96636523 0.94047199\n  0.05760845 0.56294767 0.59013346 0.80633789]\n [0.00443878 0.66507484 0.46783183 0.24749734 0.62522643 0.43081793\n  0.97331878 0.23196507 0.83054278 0.46982867]\n [0.04513855 0.52286592 0.42894132 0.07598115 0.37216146 0.54241335\n  0.72229356 0.60185356 0.74494803 0.09559892]\n [0.24329035 0.0538897  0.63931877 0.43486536 0.84296493 0.03724381\n  0.61648748 0.54327865 0.11589266 0.61994909]\n [0.83270249 0.11868825 0.15322009 0.34767308 0.35336613 0.05274876\n  0.13274518 0.58680836 0.78530101 0.78775087]\n [0.0897554  0.8269869  0.63522463 0.98638605 0.83295373 0.57299752\n  0.40682979 0.83908079 0.11665225 0.0371035 ]\n [0.29550498 0.33689451 0.30962236 0.88264263 0.51978015 0.73404555\n  0.61042828 0.48795031 0.51967649 0.64214817]]\n\n\n\n# The colon operator\n\n# In Python, we use the range() function or numpy's arange() to create sequences of numbers.\n# Unlike Matlab, which is inclusive:inclusive, most Python functions and the Python colon are inclusive:exclusive\n# Observe:\nprint(list(range(1, 11)))\n# You can also increment by a certain amount:\nprint(list(range(1, 11, 2)))\ncount2ten = np.arange(1, 10, 0.23956)\n\n# The colon operator is also useful when indexing. Let's say you want to\n# eat several twinkies:\ntwinkies_i_will_eat = twinkies[3:8, 1:7]\n\n# Question: How big should the variable twinkies_i_will_eat be? \nprint(twinkies.shape, twinkies_i_will_eat.shape)  # answer\n\n# To count backwards, you must specify that you want to skip with a negative number:\nrookie_mistake = list(range(10, 1))\nhow_the_pros_do_it = list(range(10, 0, -1))\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n[1, 3, 5, 7, 9]\n(10, 10) (5, 6)\n\n\n\n# Determining the sizes of variables\n\n# You can see variable sizes using the shape attribute (use np.shape(list) for variables that are not numpy arrays),\n# but there are also ways to output matrix sizes into variables, which will be useful in many situations.\n\nprint(len(random_number_matrix))  # \"len\" returns the length of the first dimension, different from Matlab length\n\n# You can use shape to find the sizes of all dimensions:\nprint(twinkies.shape)\nprint(twinkies.shape[0])  # or only specific dimensions...\n\nprint(np.size(twinkies))  # np.size returns the total number of elements\n\n# These functions also produce outputs:\ntwinkie_array_size = twinkies.shape\nprint(np.prod(twinkie_array_size))  # np.prod returns the product of input numbers\n\n# Of course, these functions work on non-numeric variables, e.g.,\nprint(len(ANTS))\n\n4\n(10, 10)\n10\n100\n100\n2\n\n\n\n# For-loops\n\n# A for-loop is a way to iterate repeatedly:\n\nfor counting_variable in range(1, 11):\n    print(counting_variable)  # print is used instead of disp in Python\n\n# Another example:\nfor counting_variable in range(1, 11, 2):\n    print(f\"The {counting_variable}th iteration value times 2 divided by 3 and added to 7 is {counting_variable * 2 / 3 + 7}.\")\n\n# You can embed loops within loops\n# Variables must be initialized beforehand in Python\n# Initialize array with zeros\nproduct_matrix = np.zeros((5, 7))\nfor i in range(5):\n    for j in range(7):\n        product_matrix[i, j] = (i + 1) * (j + 1)  # Python uses 0-based indexing, so we add 1\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nThe 1th iteration value times 2 divided by 3 and added to 7 is 7.666666666666667.\nThe 3th iteration value times 2 divided by 3 and added to 7 is 9.0.\nThe 5th iteration value times 2 divided by 3 and added to 7 is 10.333333333333334.\nThe 7th iteration value times 2 divided by 3 and added to 7 is 11.666666666666668.\nThe 9th iteration value times 2 divided by 3 and added to 7 is 13.0.\n\n\n\n# If-statements\n\n# Exactly how it sounds\nif 4 &gt; 5:\n    print('Something has gone awry in the universe')\n\nif 4 &gt; 5:\n    print('Something is still very wrong')\nelse:\n    print('Whew! Everything\\'s normal.')  # note the escape character for the single quote\n\n# The 'elif' statement in Python is similar to 'else if' in Matlab\nfor counting_variable in range(1, 11, 2):\n    if counting_variable == 1:\n        print(f\"The {counting_variable}st iteration value times 2 divided by 3 and added to 7 is {counting_variable * 2 / 3 + 7}.\")\n    elif counting_variable == 3:\n        print(f\"The {counting_variable}rd iteration value times 2 divided by 3 and added to 7 is {counting_variable * 2 / 3 + 7}.\")\n    else:\n        print(f\"The {counting_variable}th iteration value times 2 divided by 3 and added to 7 is {counting_variable * 2 / 3 + 7}.\")\n\nWhew! Everything's normal.\nThe 1st iteration value times 2 divided by 3 and added to 7 is 7.666666666666667.\nThe 3rd iteration value times 2 divided by 3 and added to 7 is 9.0.\nThe 5th iteration value times 2 divided by 3 and added to 7 is 10.333333333333334.\nThe 7th iteration value times 2 divided by 3 and added to 7 is 11.666666666666668.\nThe 9th iteration value times 2 divided by 3 and added to 7 is 13.0.\n\n\n\n# Boolean (true/false)\n\n# Sometimes, it's useful to know if a statement is TRUE or FALSE. \n# You can use a double-equals sign:\n\nprint(5 == 5)\n\n# The answer is 'True'. The opposite of true is false:\nprint(5 == 4)\n\n# You can assign these answers to variables:\nfourIsFive = (4 == 5)\n\nprint(type(fourIsFive))\n# Note that 'fourIsFive' is type \"bool\", or boolean.\n\n# Other related useful functions:\nmatrix0 = np.full((10, 3), False)\nmatrix1 = np.full((4, 12), True)\n\n# You can use the not operator \"not\" to negate a statement:\nprint(not (1 == 1))  # False because the negation of 1==1 is false\nprint(not (4 &gt; 3))   # Also false because the negation of 4&gt;3 is false\nprint(not (4 &lt; 3))   # True because it is false (not) that 4 is greater than 3. Tricky!\n\n# Things can sometimes get tricky:\ntruthtest = (1 == 2)\n\n# Remember:\n#    One equals sign is a statement (\"you have this value\").\n#    Two equals signs means you are asking a question (\"are these the same?\").\n\nTrue\nFalse\n&lt;class 'bool'&gt;\nFalse\nFalse\nTrue\n\n\n\n# Repmat\n\n# In Python, we can use numpy's tile function to replicate matrices.\n\nmat = np.random.rand(4, 4)\n\nprint(mat + 23)\n\n# Now imagine that mat is EEG data with 4 electrodes and 10 time points:\nmat = np.random.rand(4, 10)\n\n# Now you want to subtract the mean over time:\nmeanOverTime = np.mean(mat, axis=1)  # axis=1 computes the mean across columns\n\n# We can use broadcasting in numpy to avoid using tile (repmat in Matlab).\n# Broadcasting is a way to apply operations to arrays of different sizes.\n# For example, we can subtract the mean over time from each column of mat:\nmatmean = mat - meanOverTime[:, np.newaxis]\n\n# Note that we had to add a new axis to meanOverTime or we would have gotten an error.\nprint(matmean.shape, meanOverTime.shape)\nprint(matmean.shape, meanOverTime[:, np.newaxis].shape)\n\n# Other examples of tile:\nmat = np.array([[1, 2, 3], [10, 20, 30]])\n\nprint(np.tile(mat, (1, 1)))\nprint(np.tile(mat, (1, 2)))\nprint(np.tile(mat, (2, 1)))\n\n[[23.1523629  23.47661228 23.69606541 23.63615074]\n [23.947989   23.59127802 23.78580446 23.41453622]\n [23.08314859 23.20787045 23.48836488 23.31685668]\n [23.92628478 23.66622238 23.10865491 23.45568586]]\n(4, 10) (4,)\n(4, 10) (4, 1)\n[[ 1  2  3]\n [10 20 30]]\n[[ 1  2  3  1  2  3]\n [10 20 30 10 20 30]]\n[[ 1  2  3]\n [10 20 30]\n [ 1  2  3]\n [10 20 30]]\n\n\n\n# Bsxfun\n\n# In Python, broadcasting can often replace the need for Matlab's bsxfun.\n\n# For example, the following function will add 4 to a random matrix:\nprint(np.random.randn(10, 10) + 4)\n\n# Broadcasting is more useful because it performs singleton-expansion, \n# which means you may be able to avoid using tile (repmat in Matlab).\n# For example, imagine a dataset with 100 channels and 100,000 time points: \na = np.random.rand(100, 100000)\n\n# To subtract the mean of the entire time series using tile:\nam = a - np.tile(np.mean(a, axis=1)[:, np.newaxis], (1, a.shape[1]))\n\n# Using broadcasting:\nam = a - np.mean(a, axis=1)[:, np.newaxis]\n\n# Let's do a timing test...\nstart_time = time.time()\nfor i in range(100):\n    am = a - np.tile(np.mean(a, axis=1)[:, np.newaxis], (1, a.shape[1]))\nend_time = time.time()\nt_repmat = end_time - start_time\n\nstart_time = time.time()\nfor i in range(100):\n    am = a - np.mean(a, axis=1)[:, np.newaxis]\nend_time = time.time()\nt_broadcasting = end_time - start_time\n\nplt.bar(['tile', 'broadcasting'], [t_repmat, t_broadcasting])\nplt.title(f\"Broadcasting took {100 * t_broadcasting / t_repmat:.2f}% of the computation time.\")\nplt.show()\n\n# Thus, broadcasting is a bit faster but also more convenient to use, and more elegant. \n# There are other similar functions to bsxfun, including map and list comprehensions. \n# In addition to speed, these Pythonic approaches allow you to avoid using loops. \n# For example, let's say you want to know the length of items in a list. \n\n# Create list whose elements have variable lengths\nc = [np.random.randn(round(np.random.rand() * 100)) for _ in range(40)]\n\n# Now you want to know how many elements are in each cell. \n# You can use a loop:\ncell_lengths = []\nfor cell in c:\n    cell_lengths.append(len(cell))\n\n# But a list comprehension is more efficient and Pythonic:\ncell_lengths = [len(cell) for cell in c]\n\n[[3.72575434 5.09479641 5.2844894  3.24154709 3.9001987  3.44699231\n  3.62769027 1.83274102 4.12573213 6.55017652]\n [1.76086019 5.18311295 3.87075567 2.55194521 4.6167451  3.77451712\n  4.71012882 4.12877651 4.10565641 4.46323168]\n [5.2840933  2.29680123 2.856885   4.93435378 5.21897896 4.89902387\n  5.089644   4.30083742 2.60948632 6.04621335]\n [4.7885357  2.47254263 3.76052746 4.46794821 4.38429933 6.82641351\n  3.23409069 3.7604493  4.03813451 4.3738998 ]\n [4.07727716 3.6706917  3.7112679  3.1798255  5.47535044 2.76429583\n  3.40867482 4.60628721 4.40658711 4.9536188 ]\n [1.99924868 6.42063175 5.38427583 3.86909974 2.36371438 6.5740867\n  4.91466732 5.44524153 5.33388013 4.10217675]\n [3.64033592 3.67308013 3.40544299 3.16816511 4.15287308 1.98080457\n  4.96347617 5.06319543 4.03626352 3.68192297]\n [3.12478077 3.60611802 4.44336806 3.98176969 3.91365394 4.95863677\n  4.71192879 5.47153137 2.6375985  3.57457651]\n [4.92538998 3.49080906 4.06847014 4.77631555 5.03077872 5.17921003\n  4.02388979 4.35883406 4.79960176 3.27782922]\n [5.15510314 5.53106072 5.84572495 5.10580011 3.90009246 3.29202752\n  3.80428873 4.69067036 5.50983613 3.84142254]]\n\n\n\n\n\nContinue on to script b…"
  },
  {
    "objectID": "chapter23.html",
    "href": "chapter23.html",
    "title": "Chapter 23",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 23 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.signal import firls, filtfilt\nfrom scipy.fftpack import fft, ifft\nfrom mne import create_info, EvokedArray\nfrom mne.channels import make_dig_montage\n\n\n# Figure 23.2\n\n# Load sample data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Compute ERP\nerp = np.mean(EEG['data'], axis=2)\n\n# Subtract mean and compute covariance\nerp = erp - np.mean(erp, axis=1, keepdims=True)\ncovar = np.dot(erp, erp.T) / (EEG['pnts'][0][0] - 1)\n\n# Plot covariance of ERP\nplt.subplot(311)\nplt.imshow(covar, aspect='equal', clim=[-1, 5])\nxticks = [20, 40, 60]\nyticks = [10, 20, 30, 40, 50, 60]\nplt.xticks(xticks)\nplt.yticks(yticks)\nplt.gca().set_xticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in xticks])\nplt.gca().set_yticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in yticks])\nplt.title('Covariance of ERP')\n\n# One covariance of all timepoints\neeg = np.reshape(EEG['data'], (EEG['nbchan'][0][0], EEG['pnts'][0][0] * EEG['trials'][0][0]), 'F')\neeg = eeg - np.mean(eeg, axis=1, keepdims=True)\ncovar = np.dot(eeg, eeg.T) / (len(eeg) - 1)\n\n# Plot covariance of single-trial EEG\nplt.subplot(312)\nplt.imshow(covar, aspect='equal', clim=[20000, 150000])\nxticks = [20, 40, 60]\nyticks = [10, 20, 30, 40, 50, 60]\nplt.xticks(xticks)\nplt.yticks(yticks)\nplt.gca().set_xticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in xticks])\nplt.gca().set_yticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in yticks])\nplt.title('Covariance of single-trial EEG')\n\n# Average single-trial covariances\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(EEG['trials'][0][0]):\n    eeg = EEG['data'][:, :, i] - np.mean(EEG['data'][:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= i\n\n# Plot average covariance of single-trial EEG\nplt.subplot(313)\nplt.imshow(covar, aspect='equal', clim=[20, 150])\nxticks = [20, 40, 60]\nyticks = [10, 20, 30, 40, 50, 60]\nplt.xticks(xticks)\nplt.yticks(yticks)\nplt.gca().set_xticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in xticks])\nplt.gca().set_yticklabels([EEG['chanlocs'][0]['labels'][tick-1][0] for tick in yticks])\nplt.title('Average covariance of single-trial EEG')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 23.3\n\n# Compute covariance of ERP\nerp = np.mean(EEG['data'], axis=2)\nerp = erp - np.mean(erp, axis=1, keepdims=True)\ncovar = np.dot(erp, erp.T) / (EEG['pnts'][0][0] - 1)\n\n# PCA via eigenvalue decomposition\neigvals, pc = np.linalg.eig(covar)\n\npc = pc[:, np.argsort(-eigvals)]\neigvals = np.sort(eigvals)[::-1]\neigvals = 100 * eigvals / np.sum(eigvals)  # Convert to percent change\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\npc_lp = np.delete(pc, exclude_chans, axis=0)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot the first 9 principal components\nfor i in range(9):\n    plt.figure(102, figsize=(10, 10))\n    ax = plt.subplot(3, 3, i + 1)\n    evoked = EvokedArray(pc_lp[:, i, np.newaxis], info, tmin=EEG['xmin'][0][0])\n    evoked.set_montage(montage)\n    evoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=ax, show=False, times=-1, time_format='', colorbar=False)\n    plt.title(f'PC #{i + 1}, eigval={eigvals[i]:.4f}')\n\n    plt.figure(101, figsize=(10, 10))\n    plt.subplot(9, 1, i + 1)\n    plt.plot(EEG['times'][0], pc[:, i].T @ erp)\n    plt.axhline(0, color='k')\n    plt.xlim([-200, 1200])\n    plt.title(f'PC #{i + 1}, eigval={eigvals[i]:.4f}')\n\nplt.tight_layout()\nplt.show()\n\n# Average single-trial covariances\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(EEG['trials'][0][0]):\n    eeg = EEG['data'][:, :, i] - np.mean(EEG['data'][:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= EEG['trials'][0][0]\n\n# PCA via eigenvalue decomposition\neigvals, pc = np.linalg.eig(covar)\n\npc = pc[:, np.argsort(-eigvals)]\neigvals = np.sort(eigvals)[::-1]\neigvals = 100 * eigvals / np.sum(eigvals)  # Convert to percent change\n\npc_lp = np.delete(pc, exclude_chans, axis=0)\n\n# Plot the first 9 principal components\nfor i in range(9):\n    plt.figure(10, figsize=(10, 10))\n    ax = plt.subplot(3, 3, i + 1)\n    evoked = EvokedArray(pc_lp[:, i, np.newaxis], info, tmin=EEG['xmin'][0][0])\n    evoked.set_montage(montage)\n    evoked.plot_topomap(sensors=False, sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=ax, show=False, times=-1, time_format='', colorbar=False)\n    plt.title(f'PC #{i + 1}, eigval={eigvals[i]:.4f}')\n\n    plt.figure(11, figsize=(10, 10))\n    ax = plt.subplot(9, 1, i + 1)\n    pctimes = np.zeros(EEG['pnts'][0][0])\n    for triali in range(EEG['trials'][0][0]):\n        eeg = EEG['data'][:, :, triali] - np.mean(EEG['data'][:, :, triali], axis=1, keepdims=True)\n        pctimes += pc[:, i].T @ eeg\n    plt.plot(EEG['times'][0], pctimes / EEG['trials'][0][0])\n    plt.axhline(0, color='k')\n    plt.xlim([-200, 1200])\n    plt.title(f'PC #{i + 1}, eigval={eigvals[i]:.4f}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Tangent\n\n# An easily made mistake is to confuse the dimension order of the PC matrix. \n# To be sure you have the correct orientation, plot the first component; \n# it should have a spatially broad ERP-like distribution.\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot the first principal component to ensure correct orientation\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nevoked = EvokedArray(pc[:, 0, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[0], show=False, times=-1, time_format='', colorbar=False)\naxs[0].set_title('Correct orientation!')\n\nevoked = EvokedArray(pc[0, :, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=axs[1], show=False, times=-1, time_format='', colorbar=False)\naxs[1].set_title('Incorrect orientation!')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 23.4\n\npcanum = 2 # 1 for panel A; 2 for panel B\n\n# Average single-trial covariances\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(EEG['trials'][0][0]):\n    eeg = EEG['data'][:, :, i] - np.mean(EEG['data'][:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= EEG['trials'][0][0]\n\n# PCA via eigenvalue decomposition\neigvals, pc = np.linalg.eig(covar)\n\npc = pc[:, np.argsort(-eigvals)]\neigvals = np.sort(eigvals)[::-1]\neigvals = 100 * eigvals / np.sum(eigvals)  # Convert to percent change\n\n# Project the EEG data onto the chosen principal component for each trial\npcadata = np.zeros((EEG['pnts'][0][0], EEG['trials'][0][0]))\nfor i in range(EEG['trials'][0][0]):\n    # Calculate the PCA scores (projections) for the chosen component\n    pcadata[:, i] = np.dot(pc[:, pcanum-1].T, EEG['data'][:, :, i] - np.mean(EEG['data'][:, :, i], axis=1, keepdims=True))\n\nmin_freq = 2\nmax_freq = 80\nnum_frex = 30\n\n# Define wavelet parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nfrex = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\ns = np.logspace(np.log10(3), np.log10(10), num_frex) / (2 * np.pi * frex)\n\n# Define convolution parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\nn_conv_pow2 = int(2**np.ceil(np.log2(n_convolution)))\nhalf_of_wavelet_size = (n_wavelet - 1) // 2\n\n# Get FFT of data\neegfft = fft(pcadata.flatten('F'), n_conv_pow2)\n\n# Initialize\neegpower = np.zeros((num_frex, EEG['pnts'][0][0]))  # frequencies X time X trials\n\nbaseidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in [-500, -200]]\n\n# Loop through frequencies and compute synchronization\nfor fi in range(num_frex):\n    wavelet = fft(np.exp(2 * 1j * np.pi * frex[fi] * time) * np.exp(-time ** 2 / (2 * (s[fi] ** 2))), n_conv_pow2)\n    \n    eegconv = ifft(wavelet * eegfft)\n    eegconv = eegconv[:n_convolution]\n    eegconv = eegconv[half_of_wavelet_size:-half_of_wavelet_size]\n    \n    temppower = np.mean(np.abs(np.reshape(eegconv, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')) ** 2, axis=1)\n    eegpower[fi, :] = 10 * np.log10(temppower / np.mean(temppower[baseidx[0]:baseidx[1]+1]))\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\npc_lp = np.delete(pc, exclude_chans, axis=0)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plotting the results\nax = plt.subplot(221)\nevoked = EvokedArray(pc_lp[:, pcanum-1, np.newaxis], info, tmin=EEG['xmin'][0][0])\nevoked.set_montage(montage)\nevoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=ax, show=False, times=-1, time_format='', colorbar=False)\nplt.subplot(222)\nplt.plot(EEG['times'][0], np.mean(pcadata, axis=1))\nplt.xlim([-200, 1200])\n\nplt.subplot(212)\nplt.contourf(EEG['times'][0], frex, eegpower, 40, cmap='jet')\nplt.clim([-3, 3])\nplt.xlim([-200, 1000])\nplt.yscale('log')\nplt.yticks(np.logspace(np.log10(min_freq), np.log10(max_freq), 6))\nplt.gca().set_yticklabels([f'{f:.1f}' for f in np.logspace(np.log10(min_freq), np.log10(max_freq), 6)])\nplt.title(f'TF power from component {pcanum}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 23.5\n\n# Recompute PCA\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(EEG['trials'][0][0]):\n    eeg = EEG['data'][:, :, i] - np.mean(EEG['data'][:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= EEG['trials'][0][0]\neigvals, pc = np.linalg.eig(covar)\neigvals = 100 * np.sort(eigvals)[::-1] / np.sum(eigvals)  # Convert to percent change\n\n# Plot eigenvalues as percent variance accounted for\nplt.plot(np.arange(1, len(eigvals)+1), eigvals, '-o', markerfacecolor='w')\nplt.ylim([-1, 70])\nplt.xlim([0, 65])\n\n# Amount of variance expected by chance, computed analytically\nplt.plot([1, EEG['nbchan'][0][0]], [100 / EEG['nbchan'][0][0]] * 2, 'k')\n\n# Amount of variance expected by chance, computed based on random data\nnperms = 1000\npermeigvals = np.zeros((nperms, EEG['nbchan'][0][0]))\nfor permi in range(nperms):\n    # Randomize ERP time points within each channel\n    randdat = np.copy(erp)\n    for ch in range(erp.shape[0]):\n        np.random.shuffle(randdat[ch, :])\n    # Compute covariance matrix of the randomized data\n    covar = np.dot(randdat, randdat.T) / (EEG['pnts'][0][0] - 1)\n    # Perform eigenvalue decomposition\n    eigvals, pc = np.linalg.eig(covar)\n    eigvals = np.sort(eigvals)[::-1]  # Sort eigenvalues in descending order\n    permeigvals[permi, :] = 100 * eigvals / np.sum(eigvals)  # Convert to percent change\n\nplt.plot(np.arange(1, len(np.mean(permeigvals, axis=0))+1), np.mean(permeigvals, axis=0), 'r-o', markerfacecolor='w')\nplt.legend(['% var. accounted for', 'chance-level (alg)', 'chance-level (perm.test)'])\nplt.show()\n\n\n\n\n\n# Figure 23.6\n\n# Define parameters\nwhichcomp = 1 # 1 for panel A; 2 for panel B\n\ncentertimes = np.arange(-200, 1201, 50)\ntimewindow = 200  # ms on either side of center times\nmaptimes = np.array([-100, 200, 500, 1000] if whichcomp == 1 else [0, 300, 750, 1000])\nclim = (80000, 150000) if whichcomp == 1 else (-200000, 200000)\n\n# Initialize variables\npcvariance = np.zeros(len(centertimes))\nfirstpcas = np.zeros((len(centertimes), EEG['nbchan'][0][0]))\n\ntimesidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in centertimes]\ntimewinidx = round(timewindow / (1000 / EEG['srate'][0][0]))\nmapsidx = [np.argmin(np.abs(centertimes - t)) for t in maptimes]\n\n# Perform temporally localized PCA\nfor ti, center_time in enumerate(centertimes):\n    # Temporally localized covariance\n    covar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\n    for i in range(EEG['trials'][0][0]):\n        eeg = EEG['data'][:, timesidx[ti] - timewinidx:timesidx[ti] + timewinidx + 1, i]\n        eeg = eeg - np.mean(eeg, axis=1, keepdims=True)\n        covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\n    covar /= EEG['trials'][0][0]\n    \n    # PCA via eigenvalue decomposition\n    eigvals, pc = np.linalg.eig(covar)\n    pc = pc[:, np.argsort(-eigvals)]\n    eigvals = np.sort(eigvals)[::-1]\n    eigvals = 100 * eigvals / np.sum(eigvals)  # Convert to percent change\n    \n    pcvariance[ti] = eigvals[whichcomp - 1]\n    firstpcas[ti, :] = pc[:, whichcomp - 1]\n\n# Adjust the sign of the principal components for consistent visualization.\n# Just do it for the first component since its visualization is only in the positive range.\nif whichcomp == 1:\n    for i in range(firstpcas.shape[0]):\n        if np.sum(firstpcas[i, :]) &lt; 0:\n            firstpcas[i, :] = -firstpcas[i, :]\n\n# Plot variance over time\nplt.plot(centertimes, pcvariance)\nplt.xlim([-200, 1200])\nplt.xlabel('Time (ms)')\nplt.ylabel(f'% variance from PC{whichcomp}')\nplt.show()\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\nfirstpcas = np.delete(firstpcas, exclude_chans, axis=1)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot topomaps at specified times\nfor i, maptime in enumerate(maptimes):\n    ax = plt.subplot(int(np.ceil(len(maptimes) / np.ceil(np.sqrt(len(maptimes))))), int(np.ceil(np.sqrt(len(maptimes)))), i + 1)\n    evoked = EvokedArray(firstpcas[mapsidx[i], :, np.newaxis], info, tmin=EEG['xmin'][0][0])\n    evoked.set_montage(montage)\n    evoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', vlim=clim, axes=ax, show=False, times=-1, time_format='', colorbar=False)\n    plt.title(f'PC{whichcomp} from {maptime} ms')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 23.7\n\n# Filter parameters\ncenter_freq = 12  # in Hz\nfilter_frequency_spread = 3  # Hz +/- the center frequency\ntransition_width = 0.2\n\n# Construct filter kernel\nnyquist = EEG['srate'][0][0] / 2\nfilter_order = round(3 * (EEG['srate'][0][0] / (center_freq - filter_frequency_spread)))\n\nffrequencies = [0, (1 - transition_width) * (center_freq - filter_frequency_spread), (center_freq - filter_frequency_spread), (center_freq + filter_frequency_spread), (1 + transition_width) * (center_freq + filter_frequency_spread), nyquist] / nyquist\nidealresponse = [0, 0, 1, 1, 0, 0]\nfilterweights = firls(filter_order, ffrequencies, idealresponse)\n\n# Filter the data\nfilter_result = filtfilt(filterweights, 1, np.reshape(EEG['data'], (EEG['nbchan'][0][0], EEG['pnts'][0][0] * EEG['trials'][0][0]), 'F'))\nfilter_result = np.reshape(filter_result, (EEG['nbchan'][0][0], EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Perform PCA on filtered data\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(EEG['trials'][0][0]):\n    eeg = filter_result[:, :, i] - np.mean(filter_result[:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= EEG['trials'][0][0]\n\neigvals, pc = np.linalg.eig(covar)\n\npc = pc[:, np.argsort(-eigvals)]\neigvals = np.sort(eigvals)[::-1]\neigvals = 100 * eigvals / np.sum(eigvals)  # Convert to percent change\n\n# create channel montage \nchan_labels = [chan['labels'][0] for chan in EEG['chanlocs'][0]]\ncoords = np.vstack([-1*EEG['chanlocs']['Y'], EEG['chanlocs']['X'], EEG['chanlocs']['Z']]).T\n# remove channels outside of head\nexclude_chans = np.where(np.array([chan['radius'][0][0] for chan in EEG['chanlocs'][0]]) &gt; 0.54)\ncoords = np.delete(coords, exclude_chans, axis=0)\nchan_labels = np.delete(chan_labels, exclude_chans)\npc_lp = np.delete(pc, exclude_chans, axis=0)\nmontage = make_dig_montage(ch_pos=dict(zip(chan_labels, coords)), coord_frame='head')\n\n# create MNE Info and Evoked object\ninfo = create_info(list(chan_labels), EEG['srate'], ch_types='eeg')\n\n# Plot the first 9 principal components\nfor i in range(9):\n    plt.figure(10, figsize=(10, 10))\n    ax = plt.subplot(3, 3, i + 1)\n    evoked = EvokedArray(pc_lp[:, i, np.newaxis], info, tmin=EEG['xmin'][0][0])\n    evoked.set_montage(montage)\n    evoked.plot_topomap(sphere=EEG['chanlocs'][0][0]['sph_radius'][0][0], cmap='jet', axes=ax, show=False, times=-1, time_format='', colorbar=False)\n    plt.title(f'PC #{i + 1}, eigval={eigvals[i]:.4f}')\n\n    plt.figure(11, figsize=(10, 10))\n    plt.subplot(9, 1, i + 1)\n    plt.plot(EEG['times'][0], pc[:, i].T @ np.mean(filter_result, axis=2))\n    plt.axhline(0, color='k')\n    plt.xlim([-200, 1200])\n    plt.title(f'PC #{i + 1}, eigval={eigvals[i]:.4f}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 23.8\n\n# Note about this code: The legend of this figure (page 304) states that the PCA computed on all trials and then the weights were\n# separately applied to the first and last 30 trials. However, in the code below (and thus, in the book figure), the PCA is \n# actually computed separately on the first and last 30 trials.\n\n# PCA on first 30 trials\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(30):\n    eeg = filter_result[:, :, i] - np.mean(filter_result[:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= 30\n\neigvals, pc_first = np.linalg.eig(covar)\npc_first = pc_first[:, np.argsort(-eigvals)]\n\n# PCA on last 30 trials\ncovar = np.zeros((EEG['nbchan'][0][0], EEG['nbchan'][0][0]))\nfor i in range(EEG['trials'][0][0] - 30, EEG['trials'][0][0]):\n    eeg = filter_result[:, :, i] - np.mean(filter_result[:, :, i], axis=1, keepdims=True)\n    covar += np.dot(eeg, eeg.T) / (EEG['pnts'][0][0] - 1)\ncovar /= 30\neigvals, pc_last = np.linalg.eig(covar)\npc_last = pc_last[:, np.argsort(-eigvals)]\n\n# Plot the first 9 principal components for first and last 30 trials\nfor i in range(9):\n    plt.subplot(3, 3, i + 1)\n    plt.plot(EEG['times'][0], pc_first[:, i].T @ np.mean(filter_result[:, :, :30], axis=2))\n    plt.plot(EEG['times'][0], pc_last[:, i].T @ np.mean(filter_result[:, :, -30:], axis=2), 'r')\n    plt.xlim([-200, 1200])\n    plt.title(f'PC #{i + 1}')\nplt.legend(['first 30 trials', 'last 30 trials'])\nplt.show()"
  },
  {
    "objectID": "chapter27.html",
    "href": "chapter27.html",
    "title": "Chapter 27",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 27 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr, spearmanr, kstest, rankdata\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\nfrom scipy.signal import correlate, correlation_lags\n\n\n# an aside on covariance and correlation\n\na = np.random.randn(100)\nb = np.random.randn(100)\n\ncorr1 = np.corrcoef(a, b)[0, 1]\n\na1 = a - np.mean(a)\nb1 = b - np.mean(b)\ncorr2 = (a1 @ b1.T) / np.sqrt((a1 @ a1.T) * (b1 @ b1.T))\n\nc = np.vstack((a1, b1))\ncovmat = c @ c.T\n\n# notice the following:\nprint(covmat[0, 0] == a1 @ a1.T)\nprint(covmat[1, 1] == b1 @ b1.T)\nprint(covmat[1, 0] == a1 @ b1.T)\n# actually, some of these might not be exactly equal due to very small computer rounding errors.\n# try this instead:\nprint((covmat[1, 0] - a1 @ b1.T) &lt; 1e-14)\n\ncorr3 = covmat[0, 1] / np.sqrt(covmat[0, 0] * covmat[1, 1])\n\nprint(f\"\\nPython numpy.corrcoef function: {corr1}\")\nprint(f\"covariance scaled by variances: {corr2}\")\nprint(f\"covariance computed as matrix: {corr3}\\n\")\n\nFalse\nFalse\nFalse\nTrue\n\nPython numpy.corrcoef function: -0.18111792542261373\ncovariance scaled by variances: -0.18111792542261368\ncovariance computed as matrix: -0.18111792542261373\n\n\n\n\n# Figure 27.1\n\nanscombe = np.array([\n    # series 1    series 2    series 3     series 4\n    [10, 8.04,    10, 9.14,    10, 7.46,     8, 6.58],\n    [8, 6.95,     8, 8.14,     8, 6.77,     8, 5.76],\n    [13, 7.58,    13, 8.76,    13, 12.74,    8, 7.71],\n    [9, 8.81,     9, 8.77,     9, 7.11,     8, 8.84],\n    [11, 8.33,    11, 9.26,    11, 7.81,     8, 8.47],\n    [14, 9.96,    14, 8.10,    14, 8.84,     8, 7.04],\n    [6, 7.24,     6, 6.13,     6, 6.08,     8, 5.25],\n    [4, 4.26,     4, 3.10,     4, 5.39,     8, 5.56],\n    [12, 10.84,   12, 9.13,    12, 8.15,     8, 7.91],\n    [7, 4.82,     7, 7.26,     7, 6.42,     8, 6.89],\n    [5, 5.68,     5, 4.74,     5, 5.73,    19, 12.50],\n])\n\n# plot and compute correlations\nplt.figure(figsize=(10, 10))\nfor i in range(1, 5):\n    plt.subplot(2, 2, i)\n    x = anscombe[:, (i - 1) * 2]\n    y = anscombe[:, (i - 1) * 2 + 1]\n    plt.plot(x, y, '.')\n    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color='red')\n    corr_p, _ = pearsonr(x, y)\n    corr_s, _ = spearmanr(x, y)\n    plt.title(f'r_p={round(corr_p, 3)}; r_s={round(corr_s, 3)}')\nplt.show()\n\n\n\n\n\n# Figure 27.2\n\n# Load EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\nsensor2use = 'Fz'\ncenterfreq = 10  # in Hz\n\n# setup wavelet convolution and outputs\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nhalf_of_wavelet_size = (len(time) - 1) // 2\n\n# FFT parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nwavelet_cycles = 4.5\n\n\n# FFT of data (note: this doesn't change on frequency iteration)\nfft_data = fft(EEG['data'][EEG['chanlocs'][0]['labels']==sensor2use, :, :].flatten('F'), n_convolution)\n\n# create wavelet and run convolution\nfft_wavelet = fft(np.exp(2 * 1j * np.pi * centerfreq * time) * np.exp(-time ** 2 / (2 * (wavelet_cycles / (2 * np.pi * centerfreq)) ** 2)), n_convolution)\nconvolution_result_fft = ifft(fft_wavelet * fft_data, n_convolution) * np.sqrt(wavelet_cycles / (2 * np.pi * centerfreq))\nconvolution_result_fft = convolution_result_fft[half_of_wavelet_size: -half_of_wavelet_size]\nconvolution_result_fft = np.abs(np.reshape(convolution_result_fft, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n\n# trim edges so the distribution is not driven by edge artifact outliers\nconvolution_result_fft = convolution_result_fft[99:-100, :]\n\n# plot distribution of power data\nplt.figure(figsize=(12, 6))\nplt.subplot(121)\nplt.hist(convolution_result_fft.flatten('F'), bins=500)\nplt.xlim([0, 5000])\nplt.title('Distribution of power values')\n\nplt.subplot(122)\nplt.hist(np.log10(convolution_result_fft.flatten('F')), bins=500)\nplt.title('Distribution of log10 power values')\nplt.show()\n\n# test for normal distribution, if you have the stats toolbox\nif 'kstest' in dir():\n    p1 = kstest(convolution_result_fft.flatten('F'), 'norm')[1]\n    p2 = kstest(np.log10(convolution_result_fft.flatten('F')), 'norm')[1]\n    p3 = kstest(np.random.randn(convolution_result_fft.size), 'norm')[1]\n    print(f'KS test for normality of power: {p1} (&gt;.05 means normal distribution)')\n    print(f'KS test for normality of log10(power): {p2} (&gt;.05 means normal distribution)')\n    print(f'KS test for normality of random data: {p3} (&gt;.05 means normal distribution)')\n\n\n\n\nKS test for normality of power: 0.0 (&gt;.05 means normal distribution)\nKS test for normality of log10(power): 0.0 (&gt;.05 means normal distribution)\nKS test for normality of random data: 0.6439599564317877 (&gt;.05 means normal distribution)\n\n\n\n# Figure 27.3\n\n# Fisher Z transformation\nlots_of_corr_coefs = np.random.rand(1000) * 2 - 1\nfisher_z_coefs = 0.5 * np.log((1 + lots_of_corr_coefs) / (1 - lots_of_corr_coefs))\n\nplt.figure(figsize=(12, 12))\n\n# Histogram of correlation coefficients\nplt.subplot(221)\nplt.hist(lots_of_corr_coefs, 50)\nplt.xlabel('Correlation coefficient')\nplt.ylabel('Count')\nplt.xlim([-1, 1])\nplt.xticks(np.arange(-1, 1.5, 0.5))\n\n# Histogram of Fisher-Z transformed coefficients\nplt.subplot(222)\nplt.hist(fisher_z_coefs, 50)\nplt.xlabel('Fisher-Z transformed coefficients')\nplt.ylabel('Count')\nplt.xlim([-5, 5])\nplt.xticks(np.arange(-4, 5, 2))\n\n# Scatter plot of correlation coefficients vs. Fisher-Z transformed coefficients\nplt.subplot(223)\nplt.plot(lots_of_corr_coefs, fisher_z_coefs, '.')\nplt.xlabel('Correlation coefficient')\nplt.ylabel('Fisher-Z transformed coefficients')\nplt.xlim([-1, 1])\nplt.xticks(np.arange(-1, 1.5, 0.5))\n\n# Scatter plot of atanh (inverse Fisher-Z) vs. Fisher-Z\nplt.subplot(224)\nplt.plot(np.arctanh(lots_of_corr_coefs), fisher_z_coefs, '.')\nplt.xlabel('atanh')\nplt.ylabel('Fisher-Z')\nr = np.corrcoef(np.arctanh(lots_of_corr_coefs), fisher_z_coefs)[0, 1]\nplt.legend([f'Correlation = {r}'])\nplt.xticks(np.arange(-4, 5, 2))\nplt.yticks(np.arange(-4, 5, 2))\nplt.axis([-4, 4, -4, 4])\nplt.show()\n\n\n\n\n\n# Figure 27.4\n\n# Define sensors and frequencies\nsensor1 = 'Fz'\nsensor2 = 'P5'\n\ncenterfreq = 6  # in Hz\ntrial2plot = 10 - 1 # subtract 1 because Python is 0-indexed\n\n# Keep only requested time regions\ntimes2plot_idx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in [-300, 1200]])\n\n# FFT of data for both sensors\nfft_data1 = fft(EEG['data'][EEG['chanlocs'][0]['labels']==sensor1, :, :].flatten('F'), n_convolution)\nfft_data2 = fft(EEG['data'][EEG['chanlocs'][0]['labels']==sensor2, :, :].flatten('F'), n_convolution)\n\n# Create wavelet and run convolution for both sensors\nfft_wavelet = fft(np.exp(2 * 1j * np.pi * centerfreq * time) * np.exp(-time ** 2 / (2 * (wavelet_cycles / (2 * np.pi * centerfreq)) ** 2)), n_convolution)\n\n# Convolution for sensor 1\nconvolution_result_fft1 = ifft(fft_wavelet * fft_data1, n_convolution) * np.sqrt(wavelet_cycles / (2 * np.pi * centerfreq))\nconvolution_result_fft1 = convolution_result_fft1[half_of_wavelet_size: -half_of_wavelet_size]\nconvolution_result_fft1 = np.abs(np.reshape(convolution_result_fft1, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n\n# Convolution for sensor 2\nconvolution_result_fft2 = ifft(fft_wavelet * fft_data2, n_convolution) * np.sqrt(wavelet_cycles / (2 * np.pi * centerfreq))\nconvolution_result_fft2 = convolution_result_fft2[half_of_wavelet_size: -half_of_wavelet_size]\nconvolution_result_fft2 = np.abs(np.reshape(convolution_result_fft2, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n\nconvolution_result_fft1 = convolution_result_fft1[times2plot_idx[0]:times2plot_idx[1] + 1, :]\nconvolution_result_fft2 = convolution_result_fft2[times2plot_idx[0]:times2plot_idx[1] + 1, :]\n\n# Plotting the power values and their relationship\nplt.figure(figsize=(12, 12))\nplt.subplot(211)\nplt.plot(EEG['times'][0][times2plot_idx[0]:times2plot_idx[1] + 1], convolution_result_fft1[:, trial2plot])\nplt.plot(EEG['times'][0][times2plot_idx[0]:times2plot_idx[1] + 1], convolution_result_fft2[:, trial2plot], 'r')\nplt.xlabel('Time (ms)')\nplt.xlim(EEG['times'][0][times2plot_idx])\nplt.legend([sensor1, sensor2])\n\nplt.subplot(223)\nplt.plot(convolution_result_fft1[:, trial2plot], convolution_result_fft2[:, trial2plot], '.')\nplt.title('Power relationship')\nplt.xlabel(f'{sensor1} {centerfreq}Hz power')\nplt.ylabel(f'{sensor2} {centerfreq}Hz power')\nr = np.corrcoef(convolution_result_fft1[:, trial2plot], convolution_result_fft2[:, trial2plot])[0, 1]\nplt.legend([f'Pearson R = {r}'])\n\nplt.subplot(224)\nplt.plot(rankdata(convolution_result_fft1[:, trial2plot]), rankdata(convolution_result_fft2[:, trial2plot]), '.')\nplt.title('Rank-power relationship')\nplt.xlabel(f'{sensor1} {centerfreq}Hz rank-power')\nplt.ylabel(f'{sensor2} {centerfreq}Hz rank-power')\nr_spearman = spearmanr(convolution_result_fft1[:, trial2plot], convolution_result_fft2[:, trial2plot])[0]\nplt.legend([f'Spearman Rho = {r_spearman}'])\nplt.ylim(plt.xlim())\nplt.show()\n\n\n\n\n\n# Figure 27.5\n\n# Compute how many time points are in one cycle, and limit xcov to this lag\nnlags = round(EEG['srate'][0][0] / centerfreq)\n\n# Rank transform the power values\nrank_power1 = rankdata(np.abs(convolution_result_fft1[:, trial2plot]) ** 2)\nrank_power2 = rankdata(np.abs(convolution_result_fft2[:, trial2plot]) ** 2)\n\n# Compute cross-correlation\ncorrvals = correlate(rank_power1 - np.mean(rank_power1), \n                            rank_power2 - np.mean(rank_power2), \n                            mode='full')\n\n# Normalize the cross-correlation values to get correlation coefficients\ncorrvals /= np.sqrt(np.sum((rank_power1 - np.mean(rank_power1)) ** 2) * np.sum((rank_power2 - np.mean(rank_power2)) ** 2))\n\n# Get lags and convert to milliseconds\nlags = correlation_lags(len(rank_power1), len(rank_power2), mode='full')\ncorrlags = lags / EEG['srate'][0][0] * 1000\n\n# Find the center index corresponding to zero lag\ncenter_idx = np.where(lags == 0)[0][0]\n\n# Plot the cross-correlation\nplt.figure(figsize=(10, 5))\nplt.plot(corrlags[center_idx - nlags:center_idx + nlags + 1], \n         corrvals[center_idx - nlags:center_idx + nlags + 1], '-o', markerfacecolor='w')\nplt.axvline(0, color='k', linestyle='--')\nplt.xlabel(f'{sensor1} leads --- Time lag (ms) --- {sensor2} leads')\nplt.ylabel('Correlation coefficient')\nplt.title('Cross-correlation between sensors')\nplt.show()\n\n\n\n\n\n# Figure 27.6\n\n# Define sensors and frequencies\nsensor1 = 'POz'\nsensor2 = 'Fz'\n\n# Define time windows and frequencies\ntimewin1 = [-300, -100]  # in ms relative to stim onset\ntimewin2 = [200, 400]\n\ncenterfreq1 = 6  # in Hz\ncenterfreq2 = 6\n\n# Convert time from ms to index\ntimeidx1 = [np.argmin(np.abs(EEG['times'][0] - t)) for t in timewin1]\ntimeidx2 = [np.argmin(np.abs(EEG['times'][0] - t)) for t in timewin2]\n\n# FFT parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nwavelet_cycles = 4.5\n\n# FFT of data for both sensors\nfft_data1 = fft(EEG['data'][EEG['chanlocs'][0]['labels']==sensor1, :, :].flatten('F'), n_convolution)\nfft_data2 = fft(EEG['data'][EEG['chanlocs'][0]['labels']==sensor2, :, :].flatten('F'), n_convolution)\n\n# Create wavelet and run convolution for both sensors\nfft_wavelet1 = fft(np.exp(2 * 1j * np.pi * centerfreq1 * time) * np.exp(-time ** 2 / (2 * (wavelet_cycles / (2 * np.pi * centerfreq1)) ** 2)), n_convolution)\nconvolution_result_fft1 = ifft(fft_wavelet1 * fft_data1, n_convolution) * np.sqrt(wavelet_cycles / (2 * np.pi * centerfreq1))\nconvolution_result_fft1 = convolution_result_fft1[half_of_wavelet_size: -half_of_wavelet_size]\nanalyticsignal1 = np.abs(np.reshape(convolution_result_fft1, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n\nfft_wavelet2 = fft(np.exp(2 * 1j * np.pi * centerfreq2 * time) * np.exp(-time ** 2 / (2 * (wavelet_cycles / (2 * np.pi * centerfreq2)) ** 2)), n_convolution)\nconvolution_result_fft2 = ifft(fft_wavelet2 * fft_data2, n_convolution) * np.sqrt(wavelet_cycles / (2 * np.pi * centerfreq2))\nconvolution_result_fft2 = convolution_result_fft2[half_of_wavelet_size: -half_of_wavelet_size]\nanalyticsignal2 = np.abs(np.reshape(convolution_result_fft2, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n\n# Panel A: correlation in a specified window\ntfwindowdata1 = np.mean(analyticsignal1[timeidx1[0]:timeidx1[1] + 1, :], axis=0)\ntfwindowdata2 = np.mean(analyticsignal2[timeidx2[0]:timeidx2[1] + 1, :], axis=0)\n\nplt.figure(figsize=(12, 6))\nplt.subplot(121)\nplt.plot(tfwindowdata1, tfwindowdata2, '.')\nplt.title(f'TF window correlation, r_p={pearsonr(tfwindowdata1, tfwindowdata2)[0]:.4f}')\nplt.xlabel(f'{sensor1}: {timewin1[0]}-{timewin1[1]}; {centerfreq1} Hz')\nplt.ylabel(f'{sensor2}: {timewin2[0]}-{timewin2[1]}; {centerfreq2} Hz')\n\n# Also plot rank-transformed data\nplt.subplot(122)\nplt.plot(rankdata(tfwindowdata1), rankdata(tfwindowdata2), '.')\nplt.xlabel(f'{sensor1}: {timewin1[0]}-{timewin1[1]}; {centerfreq1} Hz')\nplt.ylabel(f'{sensor2}: {timewin2[0]}-{timewin2[1]}; {centerfreq2} Hz')\nplt.title(f'TF window correlation, r_p={spearmanr(tfwindowdata1, tfwindowdata2)[0]:.5f}')\n\nplt.tight_layout()\nplt.show()\n\n# Panel B: correlation over time\ncorr_ts = np.array([spearmanr(analyticsignal1[ti, :], analyticsignal2[ti, :])[0] for ti in range(EEG['pnts'][0, 0])])\n\nplt.figure()\nplt.plot(EEG['times'][0], corr_ts)\nplt.xlim([-200, 1200])\nplt.xlabel('Time (ms)')\nplt.ylabel(\"Spearman's rho\")\nplt.show()\n\n# Panel C: exploratory time-frequency power correlations\n\n# Define times and frequencies for exploration\ntimes2save = np.arange(-200, 1225, 25)  # in ms\nfrex = np.logspace(np.log10(2), np.log10(40), 20)\n\n# Convert times to indices\ntimes2save_idx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save])\n\n# Rank-transforming the data can happen outside the frequency loop\nseeddata_rank = rankdata(tfwindowdata2)\n\n# Initialize output correlation matrix\nexpl_corrs = np.zeros((len(frex), len(times2save)))\n\nfor fi, freq in enumerate(frex):\n    # Get power (via wavelet convolution) from signal1\n    fft_wavelet = fft(np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time ** 2 / (2 * (wavelet_cycles / (2 * np.pi * freq)) ** 2)), n_convolution)\n    convolution_result_fft = ifft(fft_wavelet * fft_data1, n_convolution) * np.sqrt(wavelet_cycles / (2 * np.pi * freq))\n    convolution_result_fft = convolution_result_fft[half_of_wavelet_size: -half_of_wavelet_size]\n    analyticsignal1 = np.abs(np.reshape(convolution_result_fft, (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n    \n    for ti, time_idx in enumerate(times2save_idx):\n        expl_corrs[fi, ti] = 1 - 6 * np.sum((seeddata_rank - rankdata(analyticsignal1[time_idx, :])) ** 2) / (EEG['trials'][0, 0] * (EEG['trials'][0, 0] ** 2 - 1))\n\n# Plot the exploratory time-frequency power correlations\nplt.figure()\nplt.contourf(times2save, frex, expl_corrs, 40, cmap='viridis', extend='both')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)), np.round(np.logspace(np.log10(frex[0]), np.log10(frex[-1]), 8)))\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.title(f'Correlation over trials from seed {sensor2}, {centerfreq2} Hz and {timewin2[0]}-{timewin2[1]} ms')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n# Figure 27.7\n\n# Define channels and parameters\nseed_chan = 'Fz'\ntarget_chan = 'F6'\ncontrol_chan = 'F1'\n\nclim = [0, 0.6]\n\n# Wavelet parameters\nmin_freq = 2\nmax_freq = 40\nnum_frex = 15\n\n# Downsampled times\ntimes2save = np.arange(-200, 850, 50)\n# times2save = EEG['times'][0]\n\n# Other wavelet parameters\nfrequencies = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])\nhalf_of_wavelet_size = (len(time) - 1) // 2\n\n# FFT parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0] * EEG['trials'][0, 0]\nn_convolution = n_wavelet + n_data - 1\nwavelet_cycles = 4.5\n\ntimes2saveidx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save])\n\n# FFT of data for seed, target, and control channels\nfft_data_seed = fft(EEG['data'][EEG['chanlocs'][0]['labels']==seed_chan, :, :].flatten('F'), n_convolution)\nfft_data_trgt = fft(EEG['data'][EEG['chanlocs'][0]['labels']==target_chan, :, :].flatten('F'), n_convolution)\nfft_data_ctrl = fft(EEG['data'][EEG['chanlocs'][0]['labels']==control_chan, :, :].flatten('F'), n_convolution)\n\n# Initialize output time-frequency data\ntf_corrdata = np.zeros((len(frequencies), len(times2save), 2))\n\nfor fi, freq in enumerate(frequencies):\n    # Create wavelet and get its FFT\n    fft_wavelet = fft(np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time ** 2 / (2 * (wavelet_cycles / (2 * np.pi * freq)) ** 2)) / freq, n_convolution)\n    \n    # Convolution for seed, target, and control sites (save only power)\n    conv_result_seed = np.abs(np.reshape(ifft(fft_wavelet * fft_data_seed, n_convolution)[half_of_wavelet_size: -half_of_wavelet_size], (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n    conv_result_trgt = np.abs(np.reshape(ifft(fft_wavelet * fft_data_trgt, n_convolution)[half_of_wavelet_size: -half_of_wavelet_size], (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n    conv_result_ctrl = np.abs(np.reshape(ifft(fft_wavelet * fft_data_ctrl, n_convolution)[half_of_wavelet_size: -half_of_wavelet_size], (EEG['pnts'][0, 0], EEG['trials'][0, 0]), 'F')) ** 2\n    \n    # Downsample and rank transform all data\n    conv_result_seed = rankdata(conv_result_seed[times2saveidx, :], axis=1)\n    conv_result_trgt = rankdata(conv_result_trgt[times2saveidx, :], axis=1)\n    conv_result_ctrl = rankdata(conv_result_ctrl[times2saveidx, :], axis=1)\n    \n    for ti, time_idx in enumerate(times2saveidx):\n\n        # Compute bivariate correlations\n        r_st = 1 - 6 * np.sum((conv_result_seed[ti, :] - conv_result_trgt[ti, :]) ** 2) / (EEG['trials'][0, 0] * (EEG['trials'][0, 0] ** 2 - 1))\n        r_sc = 1 - 6 * np.sum((conv_result_seed[ti, :] - conv_result_ctrl[ti, :]) ** 2) / (EEG['trials'][0, 0] * (EEG['trials'][0, 0] ** 2 - 1))\n        r_tc = 1 - 6 * np.sum((conv_result_ctrl[ti, :] - conv_result_trgt[ti, :]) ** 2) / (EEG['trials'][0, 0] * (EEG['trials'][0, 0] ** 2 - 1))\n        \n        # Bivariate correlation for comparison\n        tf_corrdata[fi, ti, 0] = r_st\n        \n        # Compute partial correlation and store in results matrix\n        tf_corrdata[fi, ti, 1] = (r_st - r_sc * r_tc) / (np.sqrt(1 - r_sc ** 2) * np.sqrt(1 - r_tc ** 2))\n\n# Plot\nplt.figure(figsize=(12, 6))\nfor i in range(2):\n    plt.subplot(1, 2, i + 1)\n    plt.contourf(times2save, frequencies, tf_corrdata[:, :, i], 40, cmap='viridis', extend='both')\n    plt.clim(clim)\n    plt.xlim([-200, 800])\n    plt.yscale('log')\n    plt.yticks(np.round(np.logspace(np.log10(frequencies[0]), np.log10(frequencies[-1]), 6), 1), np.round(np.logspace(np.log10(frequencies[0]), np.log10(frequencies[-1]), 6), 1))\n    if i == 0:\n        plt.title(f'Correlation between {seed_chan} and {target_chan}')\n    else:\n        plt.title(f'Partial correlation between {seed_chan} and {target_chan}')\n    plt.xlabel('Time (ms)')\n    plt.ylabel('Frequency (Hz)')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 27.8\n\n# Re-run the code for the previous figure but comment out the \n# following line towards the top:\n# times2save = EEG.times; % uncomment this line for figure 27.8\n# Then run this section of code.\n\n# Downsample the time series\nds_timesidx = np.array([np.argmin(np.abs(times2save - t)) for t in np.arange(-200, 850, 50)])  # Downsampled times\nlofreq = np.argmin(np.abs(frequencies - 4.7))\nhifreq = np.argmin(np.abs(frequencies - 32))\n\nplt.figure(figsize=(12, 12))\n\n# Original (256 Hz) time-frequency plot\nplt.subplot(221)\nplt.contourf(times2save, frequencies, tf_corrdata[:, :, 1], 40, cmap='viridis', extend='both')\nplt.plot(times2save, [frequencies[lofreq]] * len(times2save), 'k--')\nplt.plot(times2save, [frequencies[hifreq]] * len(times2save), 'k--')\nplt.clim(clim)\nplt.xlim([-200, 800])\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frequencies[0]), np.log10(frequencies[-1]), 6)), np.round(np.logspace(np.log10(frequencies[0]), np.log10(frequencies[-1]), 6)))\nplt.title('Original (256 Hz)')\n\n# Downsampled (20 Hz) time-frequency plot\nplt.subplot(222)\nplt.contourf(times2save[ds_timesidx], frequencies, tf_corrdata[:, ds_timesidx, 1], 40, cmap='viridis', extend='both')\nplt.plot(times2save[ds_timesidx], [frequencies[lofreq]] * len(times2save[ds_timesidx]), 'k--')\nplt.plot(times2save[ds_timesidx], [frequencies[hifreq]] * len(times2save[ds_timesidx]), 'k--')\nplt.clim(clim)\nplt.xlim([-200, 800])\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(frequencies[0]), np.log10(frequencies[-1]), 6)), np.round(np.logspace(np.log10(frequencies[0]), np.log10(frequencies[-1]), 6)))\nplt.title('Down-sampled (20 Hz)')\n\n# Effect of downsampling on low-frequency activity\nplt.subplot(223)\nplt.plot(times2save, tf_corrdata[lofreq, :, 1])\nplt.plot(times2save[ds_timesidx], tf_corrdata[lofreq, ds_timesidx, 1], 'ro-', markerfacecolor='w')\nplt.xlim([-200, 800])\nplt.ylim([0.25, 0.65])\nplt.title('Effect of downsampling on low-frequency activity')\n\n# Effect of downsampling on high-frequency activity\nplt.subplot(224)\nplt.plot(times2save, tf_corrdata[hifreq, :, 1])\nplt.plot(times2save[ds_timesidx], tf_corrdata[hifreq, ds_timesidx, 1], 'ro-', markerfacecolor='w')\nplt.xlim([-200, 800])\nplt.ylim([-0.1, 0.6])\nplt.title('Effect of downsampling on high-frequency activity')\nplt.legend(['Original (256 Hz)', 'Down-sampled (20 Hz)'])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter25.html",
    "href": "chapter25.html",
    "title": "Chapter 25",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 25 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.fftpack import fft, ifft\nfrom scipy.stats import pearsonr\n\n\n# Setup for figure 25.3\n\n# generate a random signal of 3 seconds\nsrate = 1000\n\nrandsig1 = np.random.randn(3*srate) # 3 seconds, with this sampling rate\nrandsig2 = np.random.randn(3*srate)\n\n# now filter at 5 Hz\nf = 5 # frequency of wavelet in Hz\ntime = np.arange(-1, 1+1/srate, 1/srate) # time for wavelet, from -1 to 1 second in steps of 1/sampling-rate\ns = 6/(2*np.pi*f) # width of Gaussian\nwavelet = np.exp(2*np.pi*1j*f*time) * np.exp(-time**2/(2*s**2))\n\n# FFT parameters\nn_wavelet = len(wavelet)\nn_data = len(randsig1)\nn_convolution = n_wavelet + n_data - 1\nhalf_of_wavelet_size = (len(wavelet) - 1) // 2\n\n# FFT of wavelet and EEG data\nconvolution_result_fft = ifft(fft(wavelet, n_convolution) * fft(randsig1, n_convolution), n_convolution) * np.sqrt(s)/10\nfiltsig1 = np.real(convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size])\nanglesig1 = np.angle(convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size])\n\nconvolution_result_fft = ifft(fft(wavelet, n_convolution) * fft(randsig2, n_convolution), n_convolution) * np.sqrt(s)/10\nfiltsig2 = np.real(convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size])\nanglesig2 = np.angle(convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size])\n\n# Plot the random signals and their filtered versions\nplt.figure(figsize=(12, 6))\n\nfor i in range(2):\n    plt.subplot(2, 1, i+1)\n    if i == 0:\n        plt.plot(randsig1, label='Random Signal 1')\n        plt.plot(filtsig1, 'r', label='Filtered Signal 1')\n        plt.xlim([0, 3000])\n        plt.ylim([-3, 4])\n    else:\n        plt.plot(randsig2, label='Random Signal 2')\n        plt.plot(filtsig2, 'r', label='Filtered Signal 2')\n        plt.xlim([0, 3000])\n        plt.ylim([-4, 6])\n    plt.legend()\n\nplt.show()\n\n\n\n\n\n# Figure 25.3\n\n# initialize output correlation matrix\ncorrelations = np.zeros((5, round(1000/f)))\n\nfor i in range(round(1000/f)):\n    \n    # correlation of unfiltered random signal\n    temp, _ = pearsonr(randsig1[:-i or None], randsig1[i:])\n    correlations[0, i] = temp\n    \n    # correlation of filtered signal\n    temp, _ = pearsonr(filtsig1[:-i or None], filtsig1[i:])\n    correlations[1, i] = temp\n    \n    # phase clustering\n    phase_diff1 = np.angle(anglesig1[:-i or None] - anglesig1[i:])\n    correlations[2, i] = np.abs(np.mean(np.exp(1j*phase_diff1)))\n    \n    # difference of correlations of filtered signal\n    temp, _ = pearsonr(filtsig2[:-i or None], filtsig2[i:])\n    correlations[3, i] = temp - correlations[1, i]\n    \n    # difference of phase clusterings\n    phase_diff2 = np.angle(anglesig2[:-i or None] - anglesig2[i:])\n    correlations[4, i] = np.abs(np.mean(np.exp(1j*phase_diff2))) - correlations[2, i]\n\n# Plot the correlations\nplt.figure(figsize=(12, 6))\nplt.plot(correlations.T)\nplt.xlim([0, 200])\nplt.ylim([-1, 1])\nplt.xlabel('Lag (ms)')\nplt.ylabel('Connectivity strength')\nplt.legend(['unfiltered', 'power corr', 'ISPC', 'corr diffs', 'ISPC diffs'])\nplt.show()"
  },
  {
    "objectID": "chapter04b.html",
    "href": "chapter04b.html",
    "title": "Chapter 4b",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 4 script B – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.signal import convolve2d\nfrom PIL import Image\n\n\n# Basic plotting\n\n# A library called matplotlib is often used for plotting\n# Note that the plots may function slightly differently in a Python script as compared to in IPython\n\n# Open a new figure and plot X by Y\nplt.figure()\nplt.plot(range(1, 11), np.power(range(1, 11), 2))\nplt.show()\n\n# Plots do not overwrite previous plots in IPython\nplt.plot(range(1, 11), np.log(range(1, 11)))\nplt.show()\n\n# Multiple plots in the same figure\nplt.plot(range(1, 11), np.power(range(1, 11), 2), linewidth=3)\nplt.plot(range(1, 11), np.log(range(1, 11)) * 30, 'r-d')\nplt.show()\n\n# Drawing lines\nplt.plot(range(1, 11), np.power(range(1, 11), 2), linewidth=3)\nplt.plot(range(1, 11), np.log(range(1, 11)) * 30, 'r-d')\n# Note that we have to plot the curves again unlike with MATLAB's `hold on`\nplt.plot([2, 9], [60, 60], 'k')\nplt.plot([1, 10], [0, 100], 'm:')\nplt.show()\n\n# Plot something else\nplt.plot(range(1, 11), np.multiply(range(1, 11), 3))\nplt.show()\n\n# Plot information in variables\nx = np.arange(0, 1.1, 0.1)\ny = np.exp(x)\nplt.plot(x, y, '.-')\nplt.show()\n\n# x and y need to be of equal length\nx = np.arange(0, 1.1, 0.1)\ny = np.array([0] + list(np.exp(x)))\ntry:\n    plt.plot(x, y, '.-')\n    plt.show()\nexcept ValueError as e:\n    print(e)\n\n# Plot multiple lines simultaneously\nplt.plot(range(100, 1001, 100), # You can add a break to continue the code on the next line. This is convenient for long lines of code that you want to be visible on a single screen without using the horizontal scrollbar.\n         np.random.rand(10, 3))\nplt.title('Random lines')\nplt.xlabel('x-axis label... maybe time? maybe space?')\nplt.ylabel('voltage (μV)')\nplt.legend(['line 1', 'line 2', 'line 3'])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx and y must have same first dimension, but have shapes (11,) and (12,)\n\n\n\n\n\n\n# Plotting lines in 3D space\n\n# Define data in 3 dimensions\nn = 10\ndataX = np.random.rand(n)\ndataY = np.random.randn(n)\ndataZ = np.random.rand(n) * 10\n\n# Plot a line in 3D space\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot(dataX, dataY, dataZ)\nax.grid(True)\n\n# Adding other features to the plot\nax.set_xlabel('X-axis')\nax.set_ylabel('Y-axis')\nax.set_zlabel('Z-axis')\nplt.show()\n\n# Plotting a 3D matrix\ndata3d = np.random.randn(3, 30)\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.plot(data3d[0, :], data3d[1, :], data3d[2, :], 'ko-', linewidth=3, markerfacecolor='m')\nax.axis('off')\nax.axis('square')\nplt.show()\n\n\n\n\n\n\n\n\n# Slightly more advanced: get and set\n\n# Plot and modify axis properties\nplt.plot(range(1, 11), np.random.rand(10, 3))\nax = plt.gca()\nax.set_xticks(range(1, 10, 2))\nax.set_xticklabels(['one', 'three', 'five', 'seven', 'nine'])\n\n# Get axis properties\naxis_ylim = ax.get_ylim()\n\n# Assign axis properties using variables\nthe_ylim_i_want = [-0.3, -np.cos(np.pi)]\nax.set_ylim(the_ylim_i_want)\nplt.show()\n\n# Change properties of figures\nplt.plot(range(1, 11), np.random.randn(10, 3))\nfig = plt.gcf() # Get current figure\nax = plt.gca() # Get current axis\nax.set_ylim([1, -1.5])\nax.set_xlim([5, 10])\nfig.patch.set_facecolor((0.6, 0, 0.8))\nplt.title('Hello there')\ntitleh = ax.title\ntitleh.set_fontsize(40)\ntitleh.set_text('LARGE TITLE')\n\n# Draw lines showing the 0 crossings\nplt.plot(ax.get_xlim(), [0, 0], 'k')\nplt.plot([6, 6], ax.get_ylim(), 'k:')\nplt.show()\n\n\n\n\n\n\n\n\n# Subplots\n\n# Use multiple plots in a figure\nplt.figure()\nplt.subplot(1, 2, 1)\nplt.plot(np.random.randn(10, 2))\nplt.subplot(1, 2, 2)\nplt.plot(np.random.randn(10, 2))\nplt.tight_layout()\nplt.show()\n\n# More subplots with different features\nedgecolors = ['r', 'g', 'm', 'k']\nplt.clf()\nfor subploti in range(1, 5):\n    plt.subplot(2, 2, subploti)\n    plt.plot(range(1, subploti + 1), np.multiply(range(1, subploti + 1), 2) + 1, 'm-p', linewidth=3, markeredgecolor=edgecolors[subploti - 1])\n    ax = plt.gca()\n    ax.set_xlim([0.5, 4.5])\n    ax.set_ylim([1, 10])\n    plt.title('Subplot {}{}'.format(subploti, '!' * subploti))\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Basic image plotting\n\n# Plot images in 2D\nplt.figure()\nplt.imshow(np.random.randn(100, 100))\nplt.show()\n\n# Imagesc with x, y, z inputs\nplt.imshow(np.random.randn(100, 100))\nplt.yticks(np.arange(0, 110, 10), np.round(np.arange(0, 1.1, 0.1), 1))\nplt.xticks(np.arange(0, 110, 10))\nplt.show()\n\n# Make the plot smoother with a 2D Gaussian convolution\nxyrange = np.arange(-1, 1.1, 0.1)\nX, Y = np.meshgrid(xyrange, xyrange)\ngaus2d = np.exp(-(X**2 + Y**2))\n\n# Look at the Gaussian\nplt.imshow(gaus2d)\nplt.show()\n\n# Convolve and plot\nplt.imshow(convolve2d(gaus2d, np.random.randn(100, 100), mode='same'))\nplt.yticks(np.arange(0, 22, 2), np.round(np.arange(-1, 1.1, 0.2), 1))\nplt.xticks(np.arange(0, 22, 2), np.round(np.arange(-1, 1.1, 0.2), 1))\nplt.colorbar()\nplt.show()\n\n# Change the colormap\nplt.imshow(convolve2d(gaus2d, np.random.randn(100, 100), mode='same'))\nplt.colorbar()\nplt.set_cmap('jet')\nplt.show()\n\n# Following plots will continue to use the 'jet' colormap unless we change it back to the default\nplt.set_cmap('viridis')\n\n# There are other functions you can use for 2D data, including:\nplt.figure()\ndata = convolve2d(gaus2d, np.random.randn(100, 100), mode='same')\nplt.subplot(221)\nplt.imshow(data, extent=(xyrange[0], xyrange[-1], xyrange[-1], xyrange[0]))\nplt.title('function: imshow')\n\nplt.subplot(222, projection='3d')\nX, Y = np.meshgrid(xyrange, xyrange)\nplt.gca().plot_surface(X, Y, data, cmap='viridis', edgecolor='none')\nplt.title('function: plot_surface')\n\nplt.subplot(223)\nplt.contourf(X, Y, data, cmap='viridis')\nplt.title('function: contourf')\n\nplt.subplot(224)\nplt.contourf(X, Y, data, 40, cmap='viridis')\nplt.gca().set_facecolor('none')  # Equivalent to 'linecolor','none' in MATLAB\nplt.title('function: contourf (with more parameters)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;Figure size 640x480 with 0 Axes&gt;\n\n\n\n\n\n\n# A bit more about images\n\n# Load an image\namsterdam = Image.open('../data/amsterdam.bmp')\nprint(np.shape(amsterdam))\n\n# Display the image\nplt.figure()\nplt.imshow(amsterdam)\nplt.axis('image')\nplt.axis('off')\nplt.set_cmap('viridis')\nplt.show()\n\n# Plot the individual color components\ntitle_color_components = 'RGB'\nfor subploti in range(1, 5):\n    plt.subplot(2, 2, subploti)\n    if subploti &lt; 4:\n        plt.imshow(np.array(amsterdam)[:, :, subploti - 1])\n        plt.title('Plotting just the {} dimension.'.format(title_color_components[subploti - 1]))\n    else:\n        plt.imshow(amsterdam)\n        plt.title('Plotting all colors')\nplt.tight_layout()\nplt.show()\n\n(734, 700, 3)"
  },
  {
    "objectID": "chapter20.html",
    "href": "chapter20.html",
    "title": "Chapter 20",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 20 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\n\n\n# Figure 20.1\n\n# Load sample EEG data\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Define channel to plot\nchan2plot = 'O1'\n\n# Wavelet parameters\nmin_freq = 2\nmax_freq = 30\nnum_frex = 20\n\n# Baseline time window\nbaseline_time = [-400, -100]\n\n# Other wavelet parameters\nfrequencies = np.logspace(np.log10(min_freq), np.log10(max_freq), num_frex)\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nhalf_of_wavelet_size = (len(time) - 1) // 2\n\n# FFT parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = [n_wavelet + n_data - 1, n_wavelet + n_data - 1, n_wavelet + EEG['pnts'][0][0] - 1]\n\n# Find sensor index\nsensoridx = EEG['chanlocs'][0]['labels']==chan2plot\n\n# Compute ERP\nerp = np.squeeze(np.mean(EEG['data'][sensoridx, :, :], axis=2))\n\n# Compute induced power by subtracting ERP from each trial\ninduced_EEG = np.squeeze(EEG['data'][sensoridx, :, :]) - erp[:, np.newaxis]\n\n# FFT of data\nfft_EEG = [\n    fft(EEG['data'][sensoridx, :, :].flatten('F'), n_convolution[0]),  # total\n    fft(induced_EEG.flatten('F'), n_convolution[1]),  # induced\n    fft(erp, n_convolution[2])  # evoked\n]\n\n# Convert baseline from ms to indices\nbaseline_idx = [np.argmin(np.abs(EEG['times'][0] - bt)) for bt in baseline_time]\n\n# Initialize output time-frequency data\ntf = np.zeros((4, len(frequencies), EEG['pnts'][0][0]))\n\nfor fi in range(len(frequencies)):\n    \n    # Create wavelet\n    wavelet = np.exp(2 * 1j * np.pi * frequencies[fi] * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * frequencies[fi]))**2)) / frequencies[fi]\n    \n    # Run convolution for each of total, induced, and evoked\n    for i in range(3):\n        \n        # Take FFT of wavelet\n        fft_wavelet = fft(wavelet, n_convolution[i])\n        \n        # Convolution\n        convolution_result_fft = ifft(fft_wavelet * fft_EEG[i], n_convolution[i])\n        convolution_result_fft = convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size]\n        \n        # Reshaping and trial averaging is done only on all trials\n        if i &lt; 2:\n            convolution_result_fft = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n            \n            # Compute power\n            tf[i, fi, :] = np.mean(np.abs(convolution_result_fft)**2, axis=1)\n        else:\n            # With only one trial-length, just compute power with no averaging\n            tf[i, fi, :] = np.abs(convolution_result_fft)**2\n        \n        # dB correct power\n        tf[i, fi, :] = 10 * np.log10(tf[i, fi, :] / np.mean(tf[i, fi, baseline_idx[0]:baseline_idx[1]+1]))\n        \n        # Inter-trial phase consistency on total EEG\n        if i == 0:\n            tf[3, fi, :] = np.abs(np.mean(np.exp(1j * np.angle(convolution_result_fft)), axis=1))\n\n# Analysis labels\nanalysis_labels = ['Total', 'Non-phase-locked', 'ERP power', 'ITPC']\n\n# Color limits\nclims = [[-3, 3], [-3, 3], [-12, 12], [0, 0.6]]\n\n# Scale ERP for plotting\nerpt = (erp - np.min(erp)) / np.max(erp - np.min(erp))\nerpt = erpt * (frequencies[-1] - frequencies[0]) + frequencies[0]\n\n# Plotting\nplt.figure(figsize=(12, 8))\nfor i in range(4):\n    plt.subplot(2, 3, i+1)\n    plt.contourf(EEG['times'][0], frequencies, tf[i, :, :], 40, cmap='viridis')\n    plt.clim(clims[i])\n    plt.xlim([-400, 1000])\n    plt.xticks(np.arange(-200, 1000, 200))\n    plt.xlabel('Time (ms)')\n    plt.ylabel('Frequency (Hz)')\n    plt.title(analysis_labels[i])\n    plt.plot(EEG['times'][0], erpt, 'k')\n\nplt.subplot(2, 3, 5)\nplt.contourf(EEG['times'][0], frequencies, tf[0, :, :] - tf[1, :, :], 40, cmap='viridis')\nplt.clim(clims[0])\nplt.xlim([-400, 1000])\nplt.xticks(np.arange(-200, 1000, 200))\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.title('Phase-locked')\nplt.plot(EEG['times'][0], erpt, 'k')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\nplt.figure(figsize=(10, 8))\nplt.subplot(221)\nplt.plot(tf[2, :, :].flatten(), tf[3, :, :].flatten(), '.')\nplt.xlabel('ERP power')\nplt.ylabel('ITPC')\n\nplt.subplot(222)\nplt.plot((tf[0, :, :] - tf[1, :, :]).flatten(), tf[3, :, :].flatten(), '.')\nplt.xlabel('Phase-locked power')\nplt.ylabel('ITPC')\nplt.xlim([-.3, 4])\n\nplt.subplot(223)\nplt.plot(tf[0, :, :].flatten(), tf[1, :, :].flatten(), '.')\nplt.xlabel('Total power')\nplt.ylabel('Non-phase-locked power')\nplt.xlim([-2, 6])\nplt.ylim([-2, 6])\n\nplt.subplot(224)\nplt.plot((tf[0, :, :] - tf[1, :, :]).flatten(), tf[2, :, :].flatten(), '.')\nplt.xlabel('Phase-locked power')\nplt.ylabel('ERP power')\nplt.xlim([-.3, 4])\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "chapter26.html",
    "href": "chapter26.html",
    "title": "Chapter 26",
    "section": "",
    "text": "Analyzing Neural Time Series Data\nPython code for Chapter 26 – converted from original Matlab by AE Studio (and ChatGPT)\nOriginal Matlab code by Mike X Cohen\nThis code accompanies the book, titled “Analyzing Neural Time Series Data” (MIT Press).\nUsing the code without following the book may lead to confusion, incorrect data analyses, and misinterpretations of results.\nMike X Cohen and AE Studio assume no responsibility for inappropriate or incorrect use of this code.\n\n\n# Import necessary libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nfrom scipy.io import loadmat\nfrom scipy.fft import fft, ifft\nfrom scipy.signal import hilbert\nfrom scipy.stats import norm\nfrom mne.filter import filter_data\n\n\n# Figure 26.1\n\n# Load sample EEG dataset\nEEG = loadmat('../data/sampleEEGdata.mat')['EEG'][0, 0]\n\n# Names of the channels you want to synchronize\nchannel1 = 'P1'\nchannel2 = 'Pz'\n\n# Create complex Morlet wavelet\ncenter_freq = 5  # in Hz\ntime = np.arange(-1, 1 + 1/EEG['srate'][0, 0], 1/EEG['srate'][0, 0])  # time for wavelet\nwavelet = np.exp(2 * 1j * np.pi * center_freq * time) * np.exp(-time**2 / (2 * (4 / (2 * np.pi * center_freq))**2)) / center_freq\nhalf_of_wavelet_size = (len(time) - 1) // 2\n\n# FFT parameters\nn_wavelet = len(time)\nn_data = EEG['pnts'][0, 0]\nn_convolution = n_wavelet + n_data - 1\n\n# FFT of wavelet\nfft_wavelet = fft(wavelet, n_convolution)\n\n# Initialize output time-frequency data\nphase_data = np.zeros((2, n_data))\nreal_data = np.zeros((2, n_data))\n\n# Find channel indices\nchanidx = [EEG['chanlocs'][0]['labels']==channel1, EEG['chanlocs'][0]['labels']==channel2]\n\n# Run convolution and extract filtered signal (real part) and phase\nfor chani in range(2):\n    fft_data = fft(np.squeeze(EEG['data'][chanidx[chani], :, 0]), n_convolution)\n    convolution_result_fft = ifft(fft_wavelet * fft_data, n_convolution) * np.sqrt(4 / (2 * np.pi * center_freq))\n    convolution_result_fft = convolution_result_fft[half_of_wavelet_size:-half_of_wavelet_size]\n    \n    # Collect real and phase data\n    phase_data[chani, :] = np.angle(convolution_result_fft)\n    real_data[chani, :] = np.real(convolution_result_fft)\n\n# Define the update function for the animation\ndef update(ti):\n    # Update filtered signals\n    filterplotH1.set_data(EEG['times'][0, :ti], real_data[0, :ti])\n    filterplotH2.set_data(EEG['times'][0, :ti], real_data[1, :ti])\n\n    # Update cartesian plot of phase angles\n    phaseanglesH1.set_data(EEG['times'][0, :ti], phase_data[0, :ti])\n    phaseanglesH2.set_data(EEG['times'][0, :ti], phase_data[1, :ti])\n\n    # Update cartesian plot of phase angles differences\n    phaseanglesDiffH1.set_data(EEG['times'][0, :ti], phase_data[0, :ti] - phase_data[1, :ti])\n    filterplotDiffH1.set_data(EEG['times'][0, :ti], real_data[0, :ti] - real_data[1, :ti])\n\n    # Update polar plot of phase angles\n    ax1.clear()\n    ax1.plot(np.tile(phase_data[0, :ti], 2), np.tile([0, 1], ti), 'b')\n    ax1.plot(np.tile(phase_data[1, :ti], 2), np.tile([0, 1], ti), 'm')\n\n    # Update polar plot of phase angle differences\n    ax2.clear()\n    ax2.plot(np.tile(phase_data[1, :ti] - phase_data[0, :ti], 2), np.tile([0, 1], ti), 'k')\n\n    return filterplotH1, filterplotH2, phaseanglesH1, phaseanglesH2, phaseanglesDiffH1, filterplotDiffH1, ax1, ax2\n\n# Create figure and axes\nfig = plt.figure(figsize=(12, 8))\ngs = fig.add_gridspec(3, 2)\nax1 = fig.add_subplot(gs[2, 0], polar=True)\nax2 = fig.add_subplot(gs[2, 1], polar=True)\nax3 = fig.add_subplot(gs[0, 0])\nax4 = fig.add_subplot(gs[0, 1])\nax5 = fig.add_subplot(gs[1, 0])\nax6 = fig.add_subplot(gs[1, 1])\nplt.suptitle('Movie magic minimizes the mystery.')\n\n# Initial plot setup\nfilterplotH1, = ax3.plot(EEG['times'][0], real_data[0, :], 'b')\nfilterplotH2, = ax3.plot(EEG['times'][0], real_data[1, :], 'm')\nax3.set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\nax3.set_ylim([real_data.min(), real_data.max()])\nax3.set_xlabel('Time (ms)')\nax3.set_ylabel('Voltage (μV)')\nax3.set_title(f'Filtered signal at {center_freq} Hz')\n\nphaseanglesH1, = ax4.plot(EEG['times'][0], phase_data[0, :], 'b')\nphaseanglesH2, = ax4.plot(EEG['times'][0], phase_data[1, :], 'm')\nax4.set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\nax4.set_ylim([-np.pi * 1.1, np.pi * 1.1])\nax4.set_yticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi])\nax4.set_xlabel('Time (ms)')\nax4.set_ylabel('Phase angle (radian)')\nax4.set_title('Phase angle time series')\n\nfilterplotDiffH1, = ax5.plot(EEG['times'][0], real_data[0, :] - real_data[1, :], 'b')\nax5.set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\nax5.set_ylim([-10, 10])\nax5.set_xlabel('Time (ms)')\nax5.set_ylabel('Voltage (μV)')\nax5.set_title(f'Filtered signal at {center_freq} Hz')\n\nphaseanglesDiffH1, = ax6.plot(EEG['times'][0], phase_data[0, :] - phase_data[1, :], 'b')\nax6.set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\nax6.set_ylim([-np.pi * 2.2, np.pi * 2.2])\nax6.set_yticks([-2*np.pi, -3*np.pi/2, -np.pi, -np.pi/2, 0, np.pi/2, np.pi, 3*np.pi/2, 2*np.pi])\nax6.set_xlabel('Time (ms)')\nax6.set_ylabel('Phase angle (radian)')\nax6.set_title('Phase angle time series')\n\n# Create the animation\nani = FuncAnimation(fig, update, frames=np.arange(0, EEG['pnts'][0][0], 10), interval=100, blit=False)\n\n# Display the animation in the Jupyter notebook\nHTML(ani.to_html5_video())\n\n\n  \n  Your browser does not support the video tag.\n\n\n\n\n\n\n\n# Figure 26.2\nfig, axs = plt.subplots(2, 2, subplot_kw=dict(polar=True))\n\n# Plot phase synchronization for the original data\naxs[0, 0].plot(np.tile(phase_data[1, :] - phase_data[0, :], 2), np.tile([0, 1], n_data), 'k')\naxs[0, 0].set_title('Phase synchronization: {:.5f}'.format(np.abs(np.mean(np.exp(1j * (phase_data[1, :] - phase_data[0, :]))))))\n\n# Generate new phase data with random phase offsets and plot\nfor i in range(1, 4):\n    new_phase_data = phase_data.copy()\n    new_phase_data[0, :] += np.random.rand() * np.pi  # add random phase offset\n    axs[i // 2, i % 2].plot(np.tile(new_phase_data[1, :] - new_phase_data[0, :], 2), np.tile([0, 1], n_data), 'k')\n    axs[i // 2, i % 2].set_title('Phase synchronization: {:.5f}'.format(np.abs(np.mean(np.exp(1j * (new_phase_data[1, :] - new_phase_data[0, :]))))))\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 26.3\n\n# Note: see commented line \"time_window_idx...\" below for panels C and D\n\n# Define channels and frequencies\nchannel1 = 'Fz'\nchannel2 = 'O1'\n\nfreqs2use = np.logspace(np.log10(4), np.log10(30), 15)  # 4-30 Hz in 15 steps\ntimes2save = np.arange(-400, 820, 20)  # Time points to save\ntimewindow = np.linspace(1.5, 3, len(freqs2use))  # Number of cycles on either end of the center point\nbaselinetm = [-400, -200]\n\n# Wavelet and FFT parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nhalf_wavelet = (len(time) - 1) // 2\nnum_cycles = np.logspace(np.log10(4), np.log10(8), len(freqs2use))\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\n\n# Time in indices\ntimes2saveidx = [np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save]\nbaselineidx = [np.argmin(np.abs(times2save - bt)) for bt in baselinetm]\n\n# Find channel indices\nchanidx = [EEG['chanlocs'][0]['labels']==channel1, EEG['chanlocs'][0]['labels']==channel2]\n\n# Initialize ISPC matrix\nispc = np.zeros((len(freqs2use), len(times2save)))\nps = np.zeros((len(freqs2use), len(times2save)))\n\n# Data FFTs\ndata_fft1 = fft(EEG['data'][chanidx[0], :, :].flatten('F'), n_convolution)\ndata_fft2 = fft(EEG['data'][chanidx[1], :, :].flatten('F'), n_convolution)\n\n# Loop over frequencies\nfor fi, freq in enumerate(freqs2use):\n    \n    # Create wavelet and take FFT\n    s = num_cycles[fi] / (2 * np.pi * freq)\n    wavelet_fft = fft(np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time**2 / (2 * (s**2))), n_convolution)\n    \n    # Phase angles from channel 1 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft1, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    phase_sig1 = np.angle(np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F'))\n    \n    # Phase angles from channel 2 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft2, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    phase_sig2 = np.angle(np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F'))\n    \n    # Phase angle differences\n    phase_diffs = phase_sig1 - phase_sig2\n\n    ps[fi, :] = np.abs(np.mean(np.exp(1j * phase_diffs[times2saveidx, :]), axis=1))\n    \n    # Define time window in indices for each frequency\n    time_window_idx = np.round((1000 / freq) * timewindow[fi] / (1000 / EEG['srate'][0][0])).astype(int)\n    # time_window_idx = np.round(300 / (1000/EEG['srate'][0][0])) # set 300 to 100 for figure 3c/d\n\n    # Compute ITPC over trials within the time window\n    for ti, time_idx in enumerate(times2saveidx):\n        phasesynch = np.abs(np.mean(np.exp(1j * phase_diffs[time_idx - time_window_idx:time_idx + time_window_idx + 1, :]), axis=0))\n\n        ispc[fi, ti] = np.mean(phasesynch)\n\n# Plotting\nplt.figure()\nplt.contourf(times2save, freqs2use, ispc - np.mean(ispc[:, baselineidx[0]:baselineidx[1]+1], axis=1)[:, None], 20, cmap='viridis', extend='both')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.show()\n\nplt.figure()\nplt.plot(freqs2use, (1000 / freqs2use) * timewindow * 2, 'o-', markerfacecolor='k', label='variable windows')\nplt.plot(freqs2use, (1000 / freqs2use) * timewindow[0] * 2, 'ro-', markerfacecolor='m', label='fixed 3*f window')\nplt.ylabel('Window width (ms)')\nplt.xlabel('Frequency (Hz)')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 26.4\n\nplt.figure(figsize=(10, 8))\n\n# Plot phase differences over time for the first 8 trials\nfor i in range(8):\n    plt.subplot(8, 1, i + 1)\n    plt.plot(phase_sig1[:200, i] - phase_sig2[:200, i])\n    plt.xlim([0, 200])\n\nplt.tight_layout()\nplt.show()\n\n# Plot phase angle differences over time for the first trial in polar coordinates\nplt.figure(figsize=(10, 4))\nplt.subplot(121, projection='polar')\nplt.plot(np.tile(phase_sig1[:200, 0] - phase_sig2[:200, 0], 2), np.tile([0, 1], 200), 'k')\nplt.title('Phase angle differences over time')\n\n# Plot phase angle differences over trials at a specific time point in polar coordinates\nplt.subplot(122, projection='polar')\nplt.plot(np.tile(phase_sig1[99, :8] - phase_sig2[99, :8], (2, 1)), np.tile([0, 1], (8, 1)).T, 'k')\nplt.title('Phase angle differences over trials')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n# Figure 26.5\n\n# Plotting\nplt.figure(figsize=(8, 6))\nplt.contourf(times2save, freqs2use, ps - np.mean(ps[:, baselineidx[0]:baselineidx[1]], axis=1, keepdims=True), 20, cmap='viridis', extend='both')\nplt.yscale('log')\nplt.yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\nplt.gca().set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\nplt.xlim([-300, 800])\nplt.xlabel('Time (ms)')\nplt.ylabel('Frequency (Hz)')\nplt.show()\n\n\n\n\n\n# Figure 26.6\n\n# Time to use for analysis\ntime2use = 300  # ms\nniterations = 50  # Number of iterations for random sampling\n\n# Initialize\nispcByNandF = np.zeros((len(freqs2use), EEG['trials'][0][0]))\ntime2useidx = np.argmin(np.abs(times2save - time2use))\n\n# Data FFTs\ndata_fft1 = fft(EEG['data'][chanidx[0], :, :].flatten('F'), n_convolution)\ndata_fft2 = fft(EEG['data'][chanidx[1], :, :].flatten('F'), n_convolution)\n\nfor fi, freq in enumerate(freqs2use):\n    \n    # Create wavelet and take FFT\n    s = num_cycles[fi] / (2 * np.pi * freq)\n    wavelet_fft = fft(np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time**2 / (2 * (s**2))), n_convolution)\n    \n    # Phase angles from channel 1 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft1, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    phase_sig1 = np.angle(np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F'))\n    \n    # Phase angles from channel 2 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft2, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    phase_sig2 = np.angle(np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F'))\n    \n    # Phase angle differences\n    phase_diffs = phase_sig1 - phase_sig2\n    \n    # Compute ISPC for different numbers of trials\n    for n in range(EEG['trials'][0][0]):\n        # Multiple iterations to select different random sets of trials\n        for iteri in range(niterations):\n            trials2use = np.random.choice(EEG['trials'][0][0], n+1, replace=False)\n            # Correctly index phase_diffs with trials2use\n            ispcByNandF[fi, n] += np.mean(np.abs(np.mean(np.exp(1j * phase_diffs[times2saveidx[time2useidx] - time_window_idx:times2saveidx[time2useidx] + time_window_idx + 1, trials2use]), axis=1)))\n\n# Plotting\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, EEG['trials'][0][0] + 1), ispcByNandF.T/niterations)\nplt.xlim([0, 100])\nplt.ylim([0.1, 1])\nplt.xlabel('Number of trials')\nplt.ylabel('ISPC')\nplt.title('ISPC as a function of number of trials')\nplt.show()\n\n\n\n\n\n# Figure 26.7\n\n# Initialize\ndata4test = np.zeros((2, EEG['pnts'][0][0], EEG['trials'][0][0]))\ndata4power = np.zeros((2, EEG['pnts'][0][0], EEG['trials'][0][0]))\n\namp_mod = 0.00001\n\nfor triali in range(EEG['trials'][0][0]):\n    # Each trial is a random channel and trial\n    trialdata1 = EEG['data'][chanidx[0], :, triali].astype(float)\n    trialdata2 = EEG['data'][chanidx[1], :, triali].astype(float)\n    \n    # Band-pass filtered data\n    trialdata1 = filter_data(trialdata1, EEG['srate'][0][0], 10, 20)\n    trialdata2 = filter_data(trialdata2, EEG['srate'][0][0], 10, 20)\n    \n    # Phase angle differences, with and without amplitude dampening\n    data4test[0, :, triali] = np.angle(hilbert(trialdata1)) - np.angle(hilbert(trialdata2))\n    data4test[1, :, triali] = np.angle(hilbert(trialdata1)) - np.angle(hilbert(trialdata2 * amp_mod))\n    \n    data4power[0, :, triali] = np.abs(hilbert(trialdata2))**2\n    data4power[1, :, triali] = np.abs(hilbert(trialdata2 * amp_mod))**2\n\n# Compute ITPC\nispc_nomod = np.abs(np.mean(np.exp(1j * data4test[0, :, :]), axis=1))\nispc_mod = np.abs(np.mean(np.exp(1j * data4test[1, :, :]), axis=1))\n\n# Compute power\npower = np.mean(data4power, axis=2)\n\n# Plot\nfig, axs = plt.subplots(3, 1, figsize=(10, 8))\n\n# Amplitude modulator\naxs[0].plot(EEG['times'][0], trialdata2[0, :])\naxs[0].plot(EEG['times'][0], trialdata2[0, :] * amp_mod, 'r')\naxs[0].set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\naxs[0].set_title('Amplitude modulator')\n\n# Example trials\naxs[1].plot(EEG['times'][0], data4test[0, :, 9])\naxs[1].plot(EEG['times'][0], data4test[1, :, 9], 'r')\naxs[1].set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\naxs[1].set_yticks([-2 * np.pi, -np.pi, 0, np.pi, 2 * np.pi])\naxs[1].set_title('Example trials')\n\n# ICPS\naxs[2].plot(EEG['times'][0], ispc_mod, 'ro')\naxs[2].plot(EEG['times'][0], ispc_nomod, 'b')\nax2 = axs[2].twinx()\nax2.plot(EEG['times'][0], np.mean(data4power[0, :, :], axis=1), 'k')\naxs[2].set_xlim([EEG['times'][0][0], EEG['times'][0][-1]])\naxs[2].set_ylim([0, 0.4])\naxs[2].set_xlabel('Time (ms)')\naxs[2].set_ylabel('ICPS')\naxs[2].set_title('ICPS')\n\nplt.tight_layout()\nplt.show()\n\n# Power vs. ICPS\nfig, axs = plt.subplots(1, 2, figsize=(10, 4))\n\n# Non-modulated power\naxs[0].plot(power[0, :], ispc_nomod, '.')\naxs[0].set_xlabel('Power')\naxs[0].set_ylabel('ICPS')\naxs[0].set_title('Non-modulated power')\n\n# Modulated power\naxs[1].plot(power[1, :], ispc_mod, '.')\naxs[1].set_xlabel('Power')\naxs[1].set_ylabel('ICPS')\naxs[1].set_title('Modulated power')\n\nplt.tight_layout()\nplt.show()\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\nSetting up band-pass filter from 10 - 20 Hz\n\nFIR filter parameters\n---------------------\nDesigning a one-pass, zero-phase, non-causal bandpass filter:\n- Windowed time-domain design (firwin) method\n- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n- Lower passband edge: 10.00\n- Lower transition bandwidth: 2.50 Hz (-6 dB cutoff frequency: 8.75 Hz)\n- Upper passband edge: 20.00 Hz\n- Upper transition bandwidth: 5.00 Hz (-6 dB cutoff frequency: 22.50 Hz)\n- Filter length: 339 samples (1.324 s)\n\n\n\n\n\n\n\n\n\n\n# Figure 26.8\n\n# Select channels\nchannel1 = 'Fz'\nchannel2 = 'O1'\n\n# Wavelet and FFT parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nhalf_wavelet = (len(time) - 1) // 2\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\n\n# Find channel indices\nchanidx = [EEG['chanlocs'][0]['labels']==channel1, EEG['chanlocs'][0]['labels']==channel2]\n\n# Data FFTs\ndata_fft1 = fft(EEG['data'][chanidx[0], :, :].flatten('F'), n_convolution)\ndata_fft2 = fft(EEG['data'][chanidx[1], :, :].flatten('F'), n_convolution)\n\n# Initialize spectral coherence matrix\nspectcoher = np.zeros((len(freqs2use), len(times2save)))\n\n# Loop over frequencies\nfor fi, freq in enumerate(freqs2use):\n    \n    # Create wavelet and take FFT\n    s = num_cycles[fi] / (2 * np.pi * freq)\n    wavelet_fft = fft(np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time**2 / (2 * (s**2))), n_convolution)\n    \n    # Phase angles from channel 1 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft1, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    sig1 = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Phase angles from channel 2 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft2, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    sig2 = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Compute power and cross-spectral power\n    spec1 = np.mean(sig1 * np.conj(sig1), axis=1)\n    spec2 = np.mean(sig2 * np.conj(sig2), axis=1)\n    specX = np.abs(np.mean(sig1 * np.conj(sig2), axis=1))**2\n    \n    # Compute spectral coherence, using only requested time points\n    spectcoher[fi, :] = np.abs(specX[times2saveidx]) / (np.abs(spec1[times2saveidx]) * np.abs(spec2[times2saveidx]))\n\n# Plotting\nfig, axs = plt.subplots(1, 2, figsize=(12, 8))\n\n# \"Raw\" spectral coherence\naxs[0].contourf(times2save, freqs2use, spectcoher, 20, cmap='viridis', extend='both')\naxs[0].set_yscale('log')\naxs[0].set_yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[0].set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[0].set_xlabel('Time (ms)')\naxs[0].set_ylabel('Frequency (Hz)')\naxs[0].set_title('\"Raw\" spectral coherence')\n\n# Baseline-subtracted spectral coherence\nbaselineidx = np.array([np.argmin(np.abs(times2save - bt)) for bt in baselinetm])\nspectcoher_baseline_subtracted = spectcoher - np.mean(spectcoher[:, baselineidx[0]:baselineidx[1]], axis=1)[:, None]\naxs[1].contourf(times2save, freqs2use, spectcoher_baseline_subtracted, 20, cmap='viridis', extend='both')\naxs[1].set_yscale('log')\naxs[1].set_yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[1].set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[1].set_xlabel('Time (ms)')\naxs[1].set_ylabel('Frequency (Hz)')\naxs[1].set_title('Baseline-subtracted spectral coherence')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 26.9\n\n# Number of \"trials\"\nn = 100\n\nplt.figure(figsize=(10, 10))\n\nplt.subplot(221, polar=True)\nphases = np.random.rand(n) * np.pi\nplt.polar(np.tile(phases, 2), np.tile([0, 1], n), 'k')\npli = abs(np.mean(np.sign(np.imag(np.exp(1j * phases)))))\nispc = abs(np.mean(np.exp(1j * phases)))\nplt.title(f'PLI={pli:.3f}, ISPC={ispc:.3f}')\n\nplt.subplot(222, polar=True)\nphases = phases - np.pi / 2\nplt.polar(np.tile(phases, 2), np.tile([0, 1], n), 'k')\npli = abs(np.mean(np.sign(np.imag(np.exp(1j * phases)))))\nispc = abs(np.mean(np.exp(1j * phases)))\nplt.title(f'PLI={pli:.3f}, ISPC={ispc:.3f}')\n\nplt.subplot(223, polar=True)\nphases = np.random.rand(n) / 2 + np.pi / 3 + 0.25\nplt.polar(np.tile(phases, 2), np.tile([0, 1], n), 'k')\npli = abs(np.mean(np.sign(np.imag(np.exp(1j * phases)))))\nispc = abs(np.mean(np.exp(1j * phases)))\nplt.title(f'PLI={pli:.3f}, ISPC={ispc:.3f}')\n\nplt.subplot(224, polar=True)\nphases = phases - np.pi / 2\nplt.polar(np.tile(phases, 2), np.tile([0, 1], n), 'k')\npli = abs(np.mean(np.sign(np.imag(np.exp(1j * phases)))))\nispc = abs(np.mean(np.exp(1j * phases)))\nplt.title(f'PLI={pli:.3f}, ISPC={ispc:.3f}')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 26.10\n\n# Select channels\nchannel1 = 'Fz'\nchannel2 = 'O1'\n\n# Specify some time-frequency parameters\nfreqs2use = np.logspace(np.log10(4), np.log10(30), 15)  # 4-30 Hz in 15 steps\ntimes2save = np.arange(-400, 810, 10)  # Time points to save\ntimewindow = np.linspace(1.5, 3, len(freqs2use))  # Number of cycles on either end of the center point\nbaselinetm = [-400, -200]\n\n# Wavelet and FFT parameters\ntime = np.arange(-1, 1 + 1/EEG['srate'][0][0], 1/EEG['srate'][0][0])\nhalf_wavelet = (len(time) - 1) // 2\nnum_cycles = np.logspace(np.log10(4), np.log10(8), len(freqs2use))\nn_wavelet = len(time)\nn_data = EEG['pnts'][0][0] * EEG['trials'][0][0]\nn_convolution = n_wavelet + n_data - 1\n\n# Time in indices\ntimes2saveidx = np.array([np.argmin(np.abs(EEG['times'][0] - t)) for t in times2save])\nbaselineidxF = np.array([np.argmin(np.abs(EEG['times'][0] - bt)) for bt in baselinetm])  # For the full temporal resolution data\nbaselineidx = np.array([np.argmin(np.abs(times2save - bt)) for bt in baselinetm])  # For the temporally downsampled data\n\n# Find channel indices\nchanidx = [EEG['chanlocs'][0]['labels']==channel1, EEG['chanlocs'][0]['labels']==channel2]\n\n# Data FFTs\ndata_fft1 = fft(EEG['data'][chanidx[0], :, :].flatten('F'), n_convolution)\ndata_fft2 = fft(EEG['data'][chanidx[1], :, :].flatten('F'), n_convolution)\n\n# Initialize\nispc = np.zeros((len(freqs2use), EEG['pnts'][0][0]))\npli = np.zeros((len(freqs2use), EEG['pnts'][0][0]))\nwpli = np.zeros((len(freqs2use), EEG['pnts'][0][0]))\ndwpli = np.zeros((len(freqs2use), EEG['pnts'][0][0]))\ndwpli_t = np.zeros((len(freqs2use), len(times2save)))\nispc_t = np.zeros((len(freqs2use), len(times2save)))\n\n# Loop over frequencies\nfor fi, freq in enumerate(freqs2use):\n    \n    # Create wavelet and take FFT\n    s = num_cycles[fi] / (2 * np.pi * freq)\n    wavelet_fft = fft(np.exp(2 * 1j * np.pi * freq * time) * np.exp(-time**2 / (2 * (s**2))), n_convolution)\n    \n    # Phase angles from channel 1 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft1, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    sig1 = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Phase angles from channel 2 via convolution\n    convolution_result_fft = ifft(wavelet_fft * data_fft2, n_convolution)\n    convolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\n    sig2 = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n    \n    # Cross-spectral density\n    cdd = sig1 * np.conj(sig2)\n    \n    # ISPC\n    ispc[fi, :] = np.abs(np.mean(np.exp(1j * np.angle(cdd)), axis=1))\n    \n    # Take imaginary part of signal only\n    cdi = np.imag(cdd)\n    \n    # Phase-lag index\n    pli[fi, :] = np.abs(np.mean(np.sign(cdi), axis=1))\n    \n    # Weighted phase-lag index\n    wpli[fi, :] = np.abs(np.mean(np.abs(cdi) * np.sign(cdi), axis=1)) / np.mean(np.abs(cdi), axis=1)\n    \n    # Debiased weighted phase-lag index\n    imagsum = np.sum(cdi, axis=1)\n    imagsumW = np.sum(np.abs(cdi), axis=1)\n    debiasfactor = np.sum(cdi**2, axis=1)\n    dwpli[fi, :] = (imagsum**2 - debiasfactor) / (imagsumW**2 - debiasfactor)\n    \n    # Compute time window in indices for this frequency\n    time_window_idx = round((1000 / freq) * timewindow[fi] / (1000 / EEG['srate'][0][0]))\n    \n    for ti, t in enumerate(times2save):\n        # Debiased weighted phase-lag index over time\n        imagsum = np.sum(cdi[times2saveidx[ti] - time_window_idx:times2saveidx[ti] + time_window_idx, :], axis=0)\n        imagsumW = np.sum(np.abs(cdi[times2saveidx[ti] - time_window_idx:times2saveidx[ti] + time_window_idx, :]), axis=0)\n        debiasfactor = np.sum(cdi[times2saveidx[ti] - time_window_idx:times2saveidx[ti] + time_window_idx, :]**2, axis=0)\n        dwpli_t[fi, ti] = np.mean((imagsum**2 - debiasfactor) / (imagsumW**2 - debiasfactor))\n        \n        # Compute phase synchronization\n        phasesynch = np.abs(np.mean(np.exp(1j * np.angle(cdd[times2saveidx[ti] - time_window_idx:times2saveidx[ti] + time_window_idx, :])), axis=0))\n        ispc_t[fi, ti] = np.mean(phasesynch)\n\n# Baseline subtraction from all measures\nispc = ispc - np.mean(ispc[:, baselineidxF[0]:baselineidxF[1]], axis=1)[:, None]\nispc_t = ispc_t - np.mean(ispc_t[:, baselineidx[0]:baselineidx[1]], axis=1)[:, None]\npli = pli - np.mean(pli[:, baselineidxF[0]:baselineidxF[1]], axis=1)[:, None]\ndwpli = dwpli - np.mean(dwpli[:, baselineidxF[0]:baselineidxF[1]], axis=1)[:, None]\ndwpli_t = dwpli_t - np.mean(dwpli_t[:, baselineidx[0]:baselineidx[1]], axis=1)[:, None]\n\n# Plotting\nfig, axs = plt.subplots(2, 2, figsize=(12, 10))\n\n# PLI over trials\naxs[0, 0].contourf(times2save, freqs2use, pli[:, times2saveidx], 40, cmap='viridis', extend='both')\naxs[0, 0].set_yscale('log')\naxs[0, 0].set_yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[0, 0].set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[0, 0].set_title('PLI over trials')\n\n# dWPLI over trials\naxs[0, 1].contourf(times2save, freqs2use, dwpli[:, times2saveidx], 40, cmap='viridis', extend='both')\naxs[0, 1].set_yscale('log')\naxs[0, 1].set_yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[0, 1].set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[0, 1].set_title('dWPLI over trials')\n\n# ICPS over time\naxs[1, 0].contourf(times2save, freqs2use, ispc_t, 40, cmap='viridis', extend='both')\naxs[1, 0].set_yscale('log')\naxs[1, 0].set_yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[1, 0].set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[1, 0].set_title('ICPS over time')\n\n# dWPLI over time\naxs[1, 1].contourf(times2save, freqs2use, dwpli_t, 40, cmap='viridis', extend='both')\naxs[1, 1].set_yscale('log')\naxs[1, 1].set_yticks(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[1, 1].set_yticklabels(np.round(np.logspace(np.log10(freqs2use[0]), np.log10(freqs2use[-1]), 8)))\naxs[1, 1].set_title('dWPLI over time')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n# Figure 26.11\n\n# Trial to plot\ntrial2plot = 10 - 1  # Any trial between 1 and 99 (book uses trial 10), subtrack 1 for Python indexing\ncenter_freq = 4.6  # Hz (book uses 4.6)\n\n# Create wavelet and take FFT\ns = 4.5 / (2 * np.pi * center_freq)\nwavelet_fft = fft(np.exp(2 * 1j * np.pi * center_freq * time) * np.exp(-time**2 / (2 * (s**2))), n_convolution)\n\n# Phase angles from channel 1 via convolution\nconvolution_result_fft = ifft(wavelet_fft * data_fft1, n_convolution)\nconvolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\nsig1 = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Phase angles from channel 2 via convolution\nconvolution_result_fft = ifft(wavelet_fft * data_fft2, n_convolution)\nconvolution_result_fft = convolution_result_fft[half_wavelet:-half_wavelet]\nsig2 = np.reshape(convolution_result_fft, (EEG['pnts'][0][0], EEG['trials'][0][0]), 'F')\n\n# Cross-spectral density\nxsd = sig1 * np.conj(sig2)\nxsdi = np.imag(xsd)\n\ndwpli = np.zeros(EEG['pnts'][0][0])\nispc = np.zeros(EEG['pnts'][0][0])\n\n# Animation start and stop times\nanimate_start = np.argmin(np.abs(EEG['times'][0] - 0))\nanimate_stop = np.argmin(np.abs(EEG['times'][0] - 1000))\n\n# Time window in indices\ntime_window_idx = round(100 * timewindow[0] / (1000 / EEG['srate'][0][0]))\n\n# Initialize figure for animation with polar subplot\nfig = plt.figure(figsize=(12, 6))\nax_polar = plt.subplot(121, polar=True)\nax_line = plt.subplot(122)\n\n# Initial plot setup\nhpol = ax_polar.plot([0, np.angle(xsd[animate_start, trial2plot])], [0, 1], 'k-o')[0]\nhplo1, = ax_line.plot(EEG['times'][0], ispc, 'b')\nhplo2, = ax_line.plot(EEG['times'][0], dwpli, 'r')\n\n# Function to update the animation\ndef update(idx):\n    # Update angles\n    angles = np.angle(xsd[idx:idx + time_window_idx, trial2plot])\n    hpol.set_data(np.tile(angles, 2), np.tile([0, 1], len(angles)).reshape(2, -1))\n\n    # Compute ICPS and dWPLI\n    ispc[idx] = np.abs(np.mean(np.exp(1j * np.angle(xsd[idx:idx + time_window_idx, trial2plot])), axis=0))\n    \n    imagsum = np.sum(xsdi[idx:idx + time_window_idx, trial2plot])\n    imagsumW = np.sum(np.abs(xsdi[idx:idx + time_window_idx, trial2plot]))\n    debiasfactor = np.sum(xsdi[idx:idx + time_window_idx, trial2plot]**2)\n    dwpli[idx] = (imagsum**2 - debiasfactor) / (imagsumW**2 - debiasfactor)\n    \n    # Update plots\n    hplo1.set_data(EEG['times'][0][:idx], ispc[:idx])\n    hplo2.set_data(EEG['times'][0][:idx], dwpli[:idx])\n    ax_line.set_xlim(EEG['times'][0][animate_start], EEG['times'][0][animate_stop + 1])\n    ax_line.set_ylim(-0.1, 1.1)\n    ax_line.set_title(f'{EEG[\"times\"][0][idx]:.0f}-{EEG[\"times\"][0][idx + time_window_idx]:.0f} ms')\n    \n    return hpol, hplo1, hplo2\n\n# Create the animation\nani = FuncAnimation(fig, update, frames=range(animate_start, animate_stop + 1), interval=200, blit=True)\n\n# Display the animation in the Jupyter notebook\nHTML(ani.to_html5_video())\n\n\n  \n  Your browser does not support the video tag.\n\n\n\n\n\n\n\n# Figure 26.12\n\n# This figure is generated in the code below.\n\n\n# Figure 26.13\n\n# Define inline functions for v-test and gv-test\ndef vtest(icpcmag, n, val):\n    return n * icpcmag * np.cos(val) * np.sqrt(2.0 / n)\n\ndef gvtest(icpcmag, n, val):\n    return n * (icpcmag * np.exp((-(val)**2) / (4.0 * np.pi / n)) * (np.sqrt(2.0 / n)))\n\nplt.figure(figsize=(10, 8))\n\n# Number of data points\nn = np.arange(2, 101)\n\n# Plot p-values for v-test and gv-test for different angles\nangles = [np.pi/10, np.pi/3]\nfor i, angle in enumerate(angles):\n    p_vtest = 1 - norm.cdf(vtest(0.3, n, angle))\n    p_gvtest = 1 - norm.cdf(gvtest(0.3, n, angle))\n    \n    ax = plt.subplot(2, 2, i + 1)\n    ax.plot(n, p_vtest, label='v-test')\n    ax.plot(n, p_gvtest, 'm', label='gv-test')\n    ax.legend()\n    ax.set_xlabel('Number of points')\n    ax.set_ylabel('P-value')\n    ax.set_xlim(0, 100)\n    ax.set_ylim(0, 0.6)\n    ax.set_title(f'angle = pi/{np.pi/angle:.0f}')\n\n# Plot p-values for different numbers of points on polar subplots\nx = np.linspace(-np.pi, np.pi, 50)\nn_values = [15, 600]\nfor i, n_val in enumerate(n_values):\n    p_vtest = 1 - norm.cdf(vtest(0.3, n_val, x - 0))\n    p_gvtest = 1 - norm.cdf(gvtest(0.3, n_val, x - 0))\n    \n    ax = plt.subplot(2, 2, i + 3, polar=True)\n    ax.plot(x, p_vtest, label='v-test')\n    ax.plot(x, p_gvtest, 'm', label='gv-test')\n    ax.set_title(f'N={n_val}')\n    ax.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Simulate data for false positive rates\nnumUsims = 10000\nu = np.zeros((2, numUsims))\n\nfor i in range(numUsims):\n    # Make some noise\n    fake_phase_data = np.random.rand(2, EEG['pnts'][0][0]) * 2 * np.pi - np.pi\n    \n    # Compute ISPC\n    ispc_mag = np.abs(np.mean(np.exp(1j * (np.diff(fake_phase_data, axis=0)))))\n    ispc_phs = np.angle(np.mean(np.exp(1j * (np.diff(fake_phase_data, axis=0)))))\n    \n    # Compute statistics\n    u[0, i] = vtest(ispc_mag, EEG['pnts'][0][0], ispc_phs - 0)\n    u[1, i] = gvtest(ispc_mag, EEG['pnts'][0][0], ispc_phs - 0)\n\n# # Plot histograms of u-values\n# fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n# for i in range(2):\n#     y, x = np.histogram(u[i, :], bins=100)\n#     # Add a small constant (e.g., 1e-10) to avoid log of zero\n#     y_log = np.log10(y + 1e-10)\n#     axs[i].bar(x[:-1], y_log, width=np.diff(x), align='edge', color='k')\n#     false_pos_rate = 100 * np.sum((1 - norm.cdf(u[i, :])) &lt; 0.05) / len(u[i, :])\n#     axs[i].set_title(f'{false_pos_rate:.1f}% false positive')\n\n# Plot histograms of u-values\nfig, axs = plt.subplots(1, 2, figsize=(10, 4))\nfor i in range(2):\n    y, x = np.histogram(u[i, :], bins=100)\n    # Replace log10(y) with np.maximum(log10(y), 0) to avoid negative values\n    y_log = np.log10(np.maximum(y, 1))  # Use 1 instead of 1e-10 to avoid negative bars\n    axs[i].bar(x[:-1], y_log, width=np.diff(x), align='edge', color='k')\n    false_pos_rate = 100 * np.sum((1 - norm.cdf(u[i, :])) &lt; 0.05) / len(u[i, :])\n    axs[i].set_title(f'{false_pos_rate:.1f}% false positive')\n\nplt.tight_layout()\nplt.show()\n\n# Create a matrix of p-values for different combinations of ISPC strength and number of data points\nnrange = np.arange(10, 301)\nispcrange = np.arange(0.05, 0.71, 0.01)\npvalmat = np.zeros((2, len(nrange), len(ispcrange)))\n\nfor ni, n_val in enumerate(nrange):\n    for mi, m_val in enumerate(ispcrange):\n        pvalmat[0, ni, mi] = 1 - norm.cdf(vtest(m_val, n_val, np.pi/5))\n        pvalmat[1, ni, mi] = 1 - norm.cdf(gvtest(m_val, n_val, np.pi/5))\n\n# Plotting the matrix of p-values\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\nfor i, title in enumerate(['v-test', 'gv-test']):\n    im = axs[i].imshow(pvalmat[i, :, :], extent=[ispcrange[0], ispcrange[-1], nrange[0], nrange[-1]], aspect='auto', origin='lower', cmap='viridis')\n    axs[i].set_xlabel('ICPS strength')\n    axs[i].set_ylabel('N')\n    axs[i].set_title(title)\n\nplt.tight_layout()\nplt.show()"
  }
]